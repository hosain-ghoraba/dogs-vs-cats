{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --------------------------------------------------------- install libraries\n",
        "# region\n",
        "# @title install libraries { display-mode: \"form\" }\n",
        "\n",
        "# %pip install --upgrade pillow pydrive2\n",
        "# endregion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "imports done\n"
          ]
        }
      ],
      "source": [
        "# --------------------------------------------------------- imports\n",
        "# region\n",
        "# @title imports { display-mode: \"form\" }\n",
        "\n",
        "import os\n",
        "import uuid\n",
        "import random\n",
        "import warnings\n",
        "import shutil\n",
        "import zipfile\n",
        "from os import makedirs\n",
        "from os import listdir\n",
        "from shutil import copyfile\n",
        "from random import seed\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,confusion_matrix,ConfusionMatrixDisplay\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense,MaxPooling2D,Dropout,Flatten,BatchNormalization,Conv2D\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping\n",
        "\n",
        "print(\"imports done\")\n",
        "\n",
        "# endregion\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "functions done\n"
          ]
        }
      ],
      "source": [
        "# --------------------------------------------------------- functions\n",
        "# region\n",
        "# @title functions {display-mode: \"form\"}\n",
        "\n",
        "def get_environment():\n",
        "    if 'COLAB_GPU' in os.environ:\n",
        "        return 'Google Colab'\n",
        "    elif 'KAGGLE_URL_BASE' in os.environ:\n",
        "        return 'Kaggle'\n",
        "    elif 'VSCODE_PID' in os.environ:\n",
        "        return 'VS Code'\n",
        "    else:\n",
        "        return 'Unknown environment'\n",
        "\n",
        "def do_colab_staff():\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "\n",
        "    kaggle_creds_path = '/content/gdrive/MyDrive/Bachelor/kaggle/kaggle.json'\n",
        "    kaggle_data_set_name = 'karakaggle/kaggle-cat-vs-dog-dataset' # modify per dataset name\n",
        "    extra_path_after_extraction = 'PetImages' # modify per dataset structure\n",
        "\n",
        "    # storing kaggle credentials\n",
        "    ! mkdir ~/.kaggle\n",
        "    ! cp {kaggle_creds_path} ~/.kaggle/\n",
        "    ! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "    !kaggle datasets download -d {kaggle_data_set_name}\n",
        "    \n",
        "    ! mkdir kaggle_data\n",
        "\n",
        "    downloaded_zip_name = f\"{kaggle_data_set_name.split('/')[-1]}.zip\" # the !kaggle datasets download command will download the zip file with the same name as the dataset name\n",
        "    with zipfile.ZipFile(downloaded_zip_name, 'r') as zip_ref:\n",
        "        zip_ref.extractall('kaggle_data')\n",
        "    \n",
        "    # get the name of the first directory in kaggle_data\n",
        "    extracted_folder_name = next(os.walk('kaggle_data'))[1][0] \n",
        "\n",
        "    extracted_folder_path = os.path.join('kaggle_data', extracted_folder_name)\n",
        "    \n",
        "    global all_entities_path\n",
        "    all_entities_path = os.path.join(extracted_folder_path, extra_path_after_extraction)\n",
        "\n",
        "def do_kaggle_staff():\n",
        "    kaggle_data_set_path = '/kaggle/input/kaggle-cat-vs-dog-dataset/kagglecatsanddogs_3367a/PetImages' # modify per dataset structure\n",
        "    new_path = '/writable'   # copy the data set a a writable location , for renaming to work\n",
        "    if os.path.exists(new_path):\n",
        "        shutil.rmtree(new_path)\n",
        "    shutil.copytree(kaggle_data_set_path, new_path)\n",
        "    global all_entities_path\n",
        "    all_entities_path = new_path\n",
        "\n",
        "def do_vscode_staff():\n",
        "    global all_entities_path\n",
        "    all_entities_path = '../dogs-vs-cats/data set 2/'  # modify per dataset structure\n",
        "\n",
        "def do_unknown_environment_staff():\n",
        "    print(\"This is an unknown environment, please enter the path to the data set folder:\")\n",
        "    global all_entities_path\n",
        "    all_entities_path = input()     \n",
        "\n",
        "def image_is_ok(image_path):\n",
        "    try:\n",
        "        with warnings.catch_warnings():\n",
        "            warnings.simplefilter('error')  # treat warnings as exceptions within this context\n",
        "            img = Image.open(image_path)\n",
        "            img.verify()\n",
        "        return True\n",
        "    except (IOError, SyntaxError, UserWarning):  # catch UserWarning along with other exceptions\n",
        "        return False\n",
        "\n",
        "def get_corrupted_files_paths(all_entities_path):\n",
        "    all_entities_names = os.listdir(all_entities_path)\n",
        "    corrupted_file_paths = set()\n",
        "    print(\"\\nVerifying all files are non-corrupted images...\")\n",
        "    for entity_name in all_entities_names:\n",
        "        entity_path = os.path.join(all_entities_path, entity_name)\n",
        "        for filename in os.listdir(entity_path):\n",
        "            file_path = os.path.join(entity_path, filename)\n",
        "            if not image_is_ok(file_path):\n",
        "                print(f\"File {file_path} is corrupted and will be skipped.\")\n",
        "                corrupted_file_paths.add(file_path)\n",
        "    print(\"Your data is ok.\" if not corrupted_file_paths else \"Done reporting error files.\")\n",
        "    return corrupted_file_paths\n",
        "        \n",
        "def rename_files(all_entities_path):\n",
        "    all_entities_names = os.listdir(all_entities_path)\n",
        "    print(\"giving temporary unique names...\")\n",
        "    for entity_name in all_entities_names:\n",
        "        entity_path = os.path.join(all_entities_path, entity_name)\n",
        "        for filename in os.listdir(entity_path):\n",
        "            temp_filename = str(uuid.uuid4()) + \".jpg\"  # generate a unique filename\n",
        "            source = os.path.join(entity_path, filename)\n",
        "            destination = os.path.join(entity_path, temp_filename)\n",
        "            os.rename(source, destination)\n",
        "    # ----------------------------------------------------------------------------------------------------\n",
        "    print(\"renaming...\")\n",
        "    # then rename every file in every folder in the given path\n",
        "\n",
        "    for entity_name in all_entities_names:\n",
        "        entity_path = os.path.join(all_entities_path, entity_name)\n",
        "        i = 1\n",
        "        for filename in os.listdir(entity_path):\n",
        "            entity_name = entity_name.lower()\n",
        "            new_filename = entity_name + '.' + str(i) + \".jpg\"\n",
        "            source = os.path.join(entity_path, filename)\n",
        "            destination = os.path.join(entity_path, new_filename)\n",
        "            os.rename(source, destination)\n",
        "            i += 1\n",
        "    print(\"done renaming !\")\n",
        "\n",
        "print(\"functions done\")  \n",
        "\n",
        "# endregion\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No GPU available, using CPU instead.\n",
            "Environment: VS Code\n",
            "data set path: ../dogs-vs-cats/data set 2/\n",
            "doing specific-environment things done\n"
          ]
        }
      ],
      "source": [
        "# --------------------------------------------------------- doing specific-environment things\n",
        "# region\n",
        "# @title doing specific-environment things {display-mode: \"form\"}\n",
        "\n",
        "# test if the GPU is available\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "print(gpus if gpus else \"No GPU available, using CPU instead.\")\n",
        "\n",
        "all_entities_path = None    \n",
        "environment_type = get_environment() \n",
        "print(f'Environment: {environment_type}')       \n",
        "if environment_type == 'Google Colab':\n",
        "    do_colab_staff()\n",
        "elif environment_type == 'Kaggle':\n",
        "    do_kaggle_staff()\n",
        "elif environment_type == 'VS Code':\n",
        "    do_vscode_staff()\n",
        "else:\n",
        "    do_unknown_environment_staff()\n",
        "\n",
        "print(\"data set path:\", all_entities_path)\n",
        "assert os.path.exists(all_entities_path), ' wrong path for data set !'   \n",
        "\n",
        "print(\"doing specific-environment things done\")\n",
        "\n",
        "# endregion\n",
        "\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Verifying all files are non-corrupted images...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File ../dogs-vs-cats/data set 2/Cat\\666.jpg is corrupted and will be skipped: cannot identify image file '../dogs-vs-cats/data set 2/Cat\\\\666.jpg'\n",
            "File ../dogs-vs-cats/data set 2/Cat\\Thumbs.db is corrupted and will be skipped: cannot identify image file '../dogs-vs-cats/data set 2/Cat\\\\Thumbs.db'\n",
            "File ../dogs-vs-cats/data set 2/Cats\\666.jpg is corrupted and will be skipped: cannot identify image file '../dogs-vs-cats/data set 2/Cats\\\\666.jpg'\n",
            "File ../dogs-vs-cats/data set 2/Dog\\11702.jpg is corrupted and will be skipped: cannot identify image file '../dogs-vs-cats/data set 2/Dog\\\\11702.jpg'\n",
            "File ../dogs-vs-cats/data set 2/Dog\\9041.jpg is corrupted and will be skipped: Truncated File Read\n",
            "File ../dogs-vs-cats/data set 2/Dog\\Thumbs.db is corrupted and will be skipped: cannot identify image file '../dogs-vs-cats/data set 2/Dog\\\\Thumbs.db'\n",
            "File ../dogs-vs-cats/data set 2/Dogs\\11702.jpg is corrupted and will be skipped: cannot identify image file '../dogs-vs-cats/data set 2/Dogs\\\\11702.jpg'\n",
            "File ../dogs-vs-cats/data set 2/Dogs\\9041.jpg is corrupted and will be skipped: Truncated File Read\n",
            "File ../dogs-vs-cats/data set 2/Dogs\\Thumbs.db is corrupted and will be skipped: cannot identify image file '../dogs-vs-cats/data set 2/Dogs\\\\Thumbs.db'\n",
            "giving temporary unique names...\n",
            "renaming...\n",
            "done renaming !\n",
            "data preparation done\n"
          ]
        }
      ],
      "source": [
        "# --------------------------------------------------------- data preparation\n",
        "# region\n",
        "# @title data preparation {display-mode: \"form\"}\n",
        "\n",
        "corrupted_file_paths = get_corrupted_files_paths(all_entities_path)\n",
        "rename_files(all_entities_path)\n",
        "data_percentage_to_use = 0.05 # percentage of the data to use\n",
        "\n",
        "print(\"data preparation done\")\n",
        "\n",
        "# endregion\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "E9g1mXLiOBTX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Images in a Dataframe done\n"
          ]
        }
      ],
      "source": [
        "# 1 --------------------------------------------------------- Loading Images in a Dataframe\n",
        "# region\n",
        "# @title 1 - Loading Images in a Dataframe { display-mode: \"form\" }\n",
        "\n",
        "all_entities_names = os.listdir(all_entities_path)\n",
        "filenames = []\n",
        "for entity_name in all_entities_names:\n",
        "    entity_path = os.path.join(all_entities_path, entity_name)\n",
        "    entity_filenames = [os.path.join(entity_path, file_name) for file_name in os.listdir(entity_path) if os.path.join(entity_path, file_name) not in corrupted_file_paths]\n",
        "    random.shuffle(entity_filenames)\n",
        "    entity_filenames = entity_filenames[:int(len(entity_filenames) * data_percentage_to_use)]\n",
        "    filenames.extend([os.path.join(entity_name, file_name) for file_name in entity_filenames])\n",
        "\n",
        "file_labels = [x.split(os.sep)[0] for x in filenames]\n",
        "data = pd.DataFrame({\"filename\": filenames, \"label\": file_labels})\n",
        "\n",
        "print(\"Loading Images in a Dataframe done\")\n",
        "# endregion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1t3k6egONtP",
        "outputId": "9150b61f-6e5e-4321-dcba-c16b3430fab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n",
            "The shape of train data (2000, 2)\n",
            "The shape of test data (250, 2)\n",
            "The shape of validation data (250, 2)\n",
            " \n"
          ]
        }
      ],
      "source": [
        "# 2 --------------------------------------------------------- Train Test Split\n",
        "# region\n",
        "# @title 2 - Train Test Split { display-mode: \"form\" }\n",
        "\n",
        "all_entities_names = data['label']\n",
        "X_train, X_temp = train_test_split(data, test_size=0.2, stratify=all_entities_names, random_state = 42)\n",
        "label_test_val = X_temp['label']\n",
        "X_test, X_val = train_test_split(X_temp, test_size=0.5, stratify=label_test_val, random_state = 42)\n",
        "\n",
        "print(\" \")\n",
        "print('The shape of train data',X_train.shape)\n",
        "print('The shape of test data',X_test.shape)\n",
        "print('The shape of validation data',X_val.shape)\n",
        "print(\" \")\n",
        "\n",
        "# endregion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96TshXPJOSrV",
        "outputId": "e82d25d8-db39-45be-d2b4-771d5d644a6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 0 validated image filenames belonging to 0 classes.\n",
            "tain generator indicise :  {}\n",
            "corrupted files :  {'../dogs-vs-cats/data set 2/Dog\\\\Thumbs.db', '../dogs-vs-cats/data set 2/Dogs\\\\9041.jpg', '../dogs-vs-cats/data set 2/Dogs\\\\Thumbs.db', '../dogs-vs-cats/data set 2/Cats\\\\666.jpg', '../dogs-vs-cats/data set 2/Cat\\\\666.jpg', '../dogs-vs-cats/data set 2/Dog\\\\9041.jpg', '../dogs-vs-cats/data set 2/Dogs\\\\11702.jpg', '../dogs-vs-cats/data set 2/Dog\\\\11702.jpg', '../dogs-vs-cats/data set 2/Cat\\\\Thumbs.db'}\n",
            "Found 0 validated image filenames belonging to 0 classes.\n",
            "Found 0 validated image filenames belonging to 0 classes.\n",
            "Creating Image Data Generator done\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Dell\\Desktop\\Bachelor\\dogs-vs-cats\\env\\Lib\\site-packages\\keras\\src\\preprocessing\\image.py:1137: UserWarning: Found 2000 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Dell\\Desktop\\Bachelor\\dogs-vs-cats\\env\\Lib\\site-packages\\keras\\src\\preprocessing\\image.py:1137: UserWarning: Found 250 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Dell\\Desktop\\Bachelor\\dogs-vs-cats\\env\\Lib\\site-packages\\keras\\src\\preprocessing\\image.py:1137: UserWarning: Found 250 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# 3 --------------------------------------------------------- Creating Image Data Generator\n",
        "# region\n",
        "# @title 3 - Creating Image Data Generator  { display-mode: \"form\" }\n",
        "\n",
        "image_size = 128\n",
        "image_channel = 3\n",
        "bat_size = 32\n",
        "\n",
        "# Creating image data generator\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                    rotation_range = 15,\n",
        "                                    horizontal_flip = True,\n",
        "                                    zoom_range = 0.2,\n",
        "                                    shear_range = 0.1,\n",
        "                                    fill_mode = 'reflect',\n",
        "                                    width_shift_range = 0.1,\n",
        "                                    height_shift_range = 0.1)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Applying image data gernerator to train and test data\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(X_train,\n",
        "                                                directory = all_entities_path ,\n",
        "                                                x_col= 'filename',\n",
        "                                                y_col= 'label',\n",
        "                                                batch_size = bat_size,\n",
        "                                                target_size = (image_size,image_size),\n",
        "                                                class_mode='categorical')\n",
        "print(\"tain generator indicise : \" ,train_generator.class_indices)\n",
        "print(\"corrupted files : \", corrupted_file_paths)\n",
        "val_generator = test_datagen.flow_from_dataframe(X_val,\n",
        "                                                directory = all_entities_path ,\n",
        "                                                x_col= 'filename',\n",
        "                                                y_col= 'label',\n",
        "                                                batch_size = bat_size,\n",
        "                                                target_size = (image_size,image_size),\n",
        "                                                shuffle=False,\n",
        "                                                class_mode='categorical')\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(X_test,\n",
        "                                                directory = all_entities_path ,\n",
        "                                                x_col= 'filename',\n",
        "                                                y_col= 'label',\n",
        "                                                batch_size = bat_size,\n",
        "                                                target_size = (image_size,image_size),\n",
        "                                                shuffle=False,\n",
        "                                                class_mode='categorical')\n",
        "\n",
        "print(\"Creating Image Data Generator done\")\n",
        "\n",
        "# endregion\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Fm1hLn5HOZt_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deep Learning Model done\n"
          ]
        }
      ],
      "source": [
        "# 4 --------------------------------------------------------- Deep Learning Model\n",
        "# region\n",
        "# @title 4 - Deep Learning Model { display-mode: \"form\" }\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Input Layer\n",
        "model.add(Conv2D(32,(3,3),activation='relu',input_shape = (image_size,image_size,image_channel)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Bloack 1\n",
        "model.add(Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "# Block 2\n",
        "model.add(Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "# Block 3\n",
        "model.add(Conv2D(256,(3,3),activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Fully Connected layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "# model.summary()\n",
        "\n",
        "print(\"Deep Learning Model done\")\n",
        "\n",
        "# endregion\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "TyQcgdqMOguE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Callbacks done\n"
          ]
        }
      ],
      "source": [
        "# 5 --------------------------------------------------------- Callbacks\n",
        "# region\n",
        "# @title 5 - Callbacks { display-mode: \"form\" }\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
        "                                            patience=2,\n",
        "                                            factor=0.5,\n",
        "                                            min_lr = 0.00001,\n",
        "                                            verbose = 1)\n",
        "\n",
        "early_stoping = EarlyStopping(monitor='val_loss',patience= 3,restore_best_weights=True,verbose=0)\n",
        "\n",
        "print(\"Callbacks done\")\n",
        "\n",
        "# endregion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "wAPVKdDFOiAM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Compilation done\n"
          ]
        }
      ],
      "source": [
        "# 6 --------------------------------------------------------- Model Compilation\n",
        "# region\n",
        "# @title 6 - Model Compilation { display-mode: \"form\" }\n",
        "\n",
        "model.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
        "\n",
        "print(\"Model Compilation done\")\n",
        "\n",
        "# endregion\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDbqrio3OjWh",
        "outputId": "7b04d037-eeb6-44a3-f65b-73c7bfb4d85c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train length:  2000\n",
            "x_test length:  250\n",
            "batch size:  32\n",
            "steps_per_epoch:  2000  //  32  =  62\n",
            "validation_steps:  250  //  32  =  7\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Asked to retrieve element 0, but the Sequence has length 0",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[36], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msteps_per_epoch: \u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;28mlen\u001b[39m(X_train) , \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m // \u001b[39m\u001b[38;5;124m\"\u001b[39m , bat_size , \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m = \u001b[39m\u001b[38;5;124m\"\u001b[39m , \u001b[38;5;28mlen\u001b[39m(X_train) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m bat_size)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_steps: \u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;28mlen\u001b[39m(X_test) , \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m // \u001b[39m\u001b[38;5;124m\"\u001b[39m , bat_size , \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m = \u001b[39m\u001b[38;5;124m\"\u001b[39m , \u001b[38;5;28mlen\u001b[39m(X_test) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m bat_size)\n\u001b[1;32m---> 10\u001b[0m cat_dog \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stoping\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlearning_rate_reduction\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;66;43;03m# data generator must generate at least steps_per_epochs * epochs batches\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbat_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbat_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m                   \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Fitting done\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# endregion\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\Bachelor\\dogs-vs-cats\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\Bachelor\\dogs-vs-cats\\env\\Lib\\site-packages\\keras\\src\\preprocessing\\image.py:103\u001b[0m, in \u001b[0;36mIterator.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 103\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    104\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to retrieve element \u001b[39m\u001b[38;5;132;01m{idx}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    105\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut the Sequence \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    106\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas length \u001b[39m\u001b[38;5;132;01m{length}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(idx\u001b[38;5;241m=\u001b[39midx, length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n\u001b[0;32m    107\u001b[0m         )\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    109\u001b[0m         np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_batches_seen)\n",
            "\u001b[1;31mValueError\u001b[0m: Asked to retrieve element 0, but the Sequence has length 0"
          ]
        }
      ],
      "source": [
        "# 7 --------------------------------------------------------- Model Fitting\n",
        "# region\n",
        "# @title 7 - Model Fitting { display-mode: \"form\" }\n",
        "\n",
        "print(\"x_train length: \",len(X_train))\n",
        "print(\"x_test length: \",len(X_test))\n",
        "print(\"batch size: \",bat_size)\n",
        "print(\"steps_per_epoch: \",len(X_train) , \" // \" , bat_size , \" = \" , len(X_train) // bat_size)\n",
        "print(\"validation_steps: \",len(X_test) , \" // \" , bat_size , \" = \" , len(X_test) // bat_size)\n",
        "cat_dog = model.fit(train_generator,\n",
        "                    validation_data = val_generator,\n",
        "                    callbacks=[early_stoping,learning_rate_reduction],\n",
        "                    epochs = 30,\n",
        "                    # data generator must generate at least steps_per_epochs * epochs batches\n",
        "\n",
        "                    steps_per_epoch = len(X_train) // bat_size,\n",
        "                    validation_steps = len(X_test) // bat_size,\n",
        "                   )\n",
        "\n",
        "print(\"Model Fitting done\")\n",
        "# endregion\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9VvirSWOk0v"
      },
      "outputs": [],
      "source": [
        "# 8 --------------------------------------------------------- Plot the results\n",
        "# region\n",
        "# @title 8 - Plot the results { display-mode: \"form\" }\n",
        "# plots for accuracy and Loss with epochs\n",
        "\n",
        "error = pd.DataFrame(cat_dog.history)\n",
        "\n",
        "plt.figure(figsize=(18,5),dpi=200)\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.title('Cross Entropy Loss',fontsize=15)\n",
        "plt.xlabel('Epochs',fontsize=12)\n",
        "plt.ylabel('Loss',fontsize=12)\n",
        "plt.plot(error['loss'])\n",
        "plt.plot(error['val_loss'])\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.title('Classification Accuracy',fontsize=15)\n",
        "plt.xlabel('Epochs',fontsize=12)\n",
        "plt.ylabel('Accuracy',fontsize=12)\n",
        "plt.plot(error['accuracy'])\n",
        "plt.plot(error['val_accuracy'])\n",
        "\n",
        "plt.show(block=False)  # hosain : prevent the popup\n",
        "\n",
        "print(\"Plot the results done\")\n",
        "\n",
        "# endregion\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VV3c2l1ROmpD"
      },
      "outputs": [],
      "source": [
        "# 9 --------------------------------------------------------- Evaluation\n",
        "# region\n",
        "# @title 9 - Evaluation { display-mode: \"form\" }\n",
        "# Evaluvate for train generator\n",
        "loss,acc = model.evaluate(train_generator,batch_size = bat_size, verbose = 0)\n",
        "\n",
        "print('The accuracy of the model for training data is:',acc*100)\n",
        "print('The Loss of the model for training data is:',loss)\n",
        "\n",
        "# Evaluvate for validation generator\n",
        "loss,acc = model.evaluate(val_generator,batch_size = bat_size, verbose = 0)\n",
        "\n",
        "print('The accuracy of the model for validation data is:',acc*100)\n",
        "print('The Loss of the model for validation data is:',loss)\n",
        "\n",
        "#  endregion\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRWnjhtoOoVd"
      },
      "outputs": [],
      "source": [
        "# 10 --------------------------------------------------------- save the model\n",
        "# region\n",
        "# @title 10 - save the model { display-mode: \"form\" }\n",
        "model.save(\"model.keras\")\n",
        "\n",
        "print(\"Model saved\")\n",
        "# endregion\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlpmx-GlOp3M"
      },
      "outputs": [],
      "source": [
        "# 11 --------------------------------------------------------- Prediction\n",
        "# region\n",
        "# @title 11 - Prediction { display-mode: \"form\" }\n",
        "result = model.predict(test_generator,batch_size = bat_size,verbose = 0)\n",
        "\n",
        "y_pred = np.argmax(result, axis = 1)\n",
        "\n",
        "y_true = test_generator.labels\n",
        "\n",
        "# Evaluvate\n",
        "loss,acc = model.evaluate(test_generator, batch_size = bat_size, verbose = 0)\n",
        "\n",
        "print('The accuracy of the model for testing data is:',acc*100)\n",
        "print('The Loss of the model for testing data is:',loss)\n",
        "\n",
        "# endregion\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSFPmSxjOrNe"
      },
      "outputs": [],
      "source": [
        "# 12 --------------------------------------------------------- Classification Report\n",
        "# region\n",
        "# @title 12 - Classification Report { display-mode: \"form\" }\n",
        "all_entities_names =['Cat','Dog']\n",
        "print(classification_report(y_true, y_pred,target_names=all_entities_names))\n",
        "\n",
        "# endregion\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4g02--rOspL"
      },
      "outputs": [],
      "source": [
        "# 13 --------------------------------------------------------- Confusion Matrix\n",
        "# region\n",
        "# @title 13 - Confusion Matrix { display-mode: \"form\" }\n",
        "\n",
        "# Normalize the confusion matrix\n",
        "confusion_mtx = confusion_matrix(y_true, y_pred)\n",
        "confusion_mtx = confusion_mtx.astype('float') / confusion_mtx.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "print(\"Normalized Confusion Matrix: \\n\", confusion_mtx)\n",
        "\n",
        "f, ax = plt.subplots(figsize=(8, 4), dpi=200)\n",
        "sns.heatmap(confusion_mtx, annot=True, linewidths=0.1, cmap=\"gist_yarg_r\", linecolor=\"black\", fmt='.2%', ax=ax, cbar=False, xticklabels=all_entities_names, yticklabels=all_entities_names)\n",
        "\n",
        "plt.xlabel(\"Predicted Label\", fontsize=10)\n",
        "plt.ylabel(\"True Label\", fontsize=10)\n",
        "plt.title(\"Confusion Matrix\", fontsize=13)\n",
        "\n",
        "plt.show()\n",
        "# endregion\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --------------------------------------------------------- reference codes\n",
        "# region\n",
        "#  @title  reference codes { display-mode: \"form\" }\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "\n",
        "# import zipfile\n",
        "# import os\n",
        "# extract_source = \"/content/gdrive/My Drive/GUC Bachelor : Arabic Image-to-Letters Script Recognition/data set/data set 2.zip\"\n",
        "# extract_destination = \"/content/extracted_from_drive\"\n",
        "# zip_ref = zipfile.ZipFile(extract_source, 'r')\n",
        "# print(\"extracting...\")\n",
        "# zip_ref.extractall(extract_destination)\n",
        "# extracted_folder_name = os.listdir(extract_destination)[0]\n",
        "# zip_ref.close()\n",
        "# print(\"extracted files from drive to colab successfully !\")\n",
        "# all_entities_path = os.path.join(extract_destination, extracted_folder_name)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
