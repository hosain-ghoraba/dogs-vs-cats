{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# extracting from drive ---------------------------------------------------------\n",
        "# region\n",
        "# @title  Colab_specific { display-mode: \"form\" }\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "extract_source = \"/content/gdrive/My Drive/GUC Bachelor : Arabic Image-to-Letters Script Recognition/data set/data set 2.zip\"\n",
        "extract_destination = \"/content/extracted_from_drive\"\n",
        "zip_ref = zipfile.ZipFile(extract_source, 'r')\n",
        "print(\"extracting...\")\n",
        "zip_ref.extractall(extract_destination)\n",
        "extracted_folder_name = os.listdir(extract_destination)[0]\n",
        "zip_ref.close()\n",
        "print(\"extracted files from drive to colab successfully !\")\n",
        "all_entities_path = os.path.join(extract_destination, extracted_folder_name)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LnEqe8p0hiS",
        "outputId": "73526d7f-83d7-4762-ca1f-84eb97876ec5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Verifying all files are non-corrupted images...\n",
            "your data is ok.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# checking corrupted files ---------------------------------------------------------\n",
        "# region\n",
        "# @title Checking corrupted files { display-mode: \"form\" }\n",
        "import os\n",
        "from PIL import Image\n",
        "import warnings\n",
        "\n",
        "# ----------------------------------------------------------------------------------------------------\n",
        "# all_entities_path = './data set 2/' uncomment if working on local machine\n",
        "all_entities_names = os.listdir(all_entities_path)\n",
        "\n",
        "# Verify all files are non-corrupted images\n",
        "invalid_files = set()\n",
        "print(\"\\nVerifying all files are non-corrupted images...\")\n",
        "for entity_name in all_entities_names:\n",
        "    entity_path = os.path.join(all_entities_path, entity_name)\n",
        "    for filename in os.listdir(entity_path):\n",
        "        file_path = os.path.join(entity_path, filename)\n",
        "        try:\n",
        "            with warnings.catch_warnings():\n",
        "                warnings.simplefilter('error')  # treat warnings as exceptions within this context\n",
        "                img = Image.open(file_path)\n",
        "                img.verify()\n",
        "        except (IOError, SyntaxError, UserWarning) as e:  # catch UserWarning along with other exceptions\n",
        "            print(f\"File {file_path} is corrupted and will be skipped: {e}\")\n",
        "            invalid_files.add(file_path)\n",
        "\n",
        "print(\"Your data is ok.\" if not invalid_files else \"Done reporting error files.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Nm1lCwWx0F-",
        "outputId": "f10145f9-8596-469a-dbae-1703093e6f34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "giving temporary unique names...\n",
            "renaming...\n",
            "done\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# extracting from drive ---------------------------------------------------------\n",
        "# region\n",
        "# @title Renaming { display-mode: \"form\" }\n",
        "\n",
        "import uuid\n",
        "\n",
        "# ----------------------------------------------------------------------------------------------------\n",
        "# First pass to rename all files to a temporary unique name to avoid renaming a file with a name that belongs to another file in the same folder\n",
        "print(\"giving temporary unique names...\")\n",
        "for entity_name in all_entities_names:\n",
        "    entity_path = os.path.join(all_entities_path, entity_name)\n",
        "    for filename in os.listdir(entity_path):\n",
        "        temp_filename = str(uuid.uuid4()) + \".jpg\"  # generate a unique filename\n",
        "        source = os.path.join(entity_path, filename)\n",
        "        destination = os.path.join(entity_path, temp_filename)\n",
        "        os.rename(source, destination)\n",
        "# ----------------------------------------------------------------------------------------------------\n",
        "print(\"renaming...\")\n",
        "# then rename every file in every folder in the given path\n",
        "\n",
        "for entity_name in all_entities_names:\n",
        "    entity_path = os.path.join(all_entities_path, entity_name)\n",
        "    i = 1\n",
        "    for filename in os.listdir(entity_path):\n",
        "        entity_name = entity_name.lower()\n",
        "        new_filename = entity_name + '.' + str(i) + \".jpg\"\n",
        "        source = os.path.join(entity_path, filename)\n",
        "        destination = os.path.join(entity_path, new_filename)\n",
        "        os.rename(source, destination)\n",
        "        i += 1\n",
        "\n",
        "print(\"done\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JbFiYivN4Qd",
        "outputId": "babaf8e4-1864-4147-f7f3-fbb77e5b71a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No GPU available, using CPU instead.\n"
          ]
        }
      ],
      "source": [
        "# 0 ---------------------------------------------------------imports\n",
        "# region\n",
        "\n",
        "# @title 0 - imports { display-mode: \"form\" }\n",
        "import os\n",
        "import random\n",
        "from os import makedirs\n",
        "from os import listdir\n",
        "from shutil import copyfile\n",
        "from random import seed\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,confusion_matrix,ConfusionMatrixDisplay\n",
        "import tensorflow as tf\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense,MaxPooling2D,Dropout,Flatten,BatchNormalization,Conv2D\n",
        "from keras.callbacks import ReduceLROnPlateau,EarlyStopping\n",
        "\n",
        "# test if the GPU is available\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "print(gpus if gpus else \"No GPU available, using CPU instead.\")\n",
        "\n",
        "# endregion\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "E9g1mXLiOBTX"
      },
      "outputs": [],
      "source": [
        "# 1 ---------------------------------------------------------Loading Images in a Dataframe\n",
        "# region\n",
        "# @title 1 - Loading Images in a Dataframe { display-mode: \"form\" }\n",
        "\n",
        "# all_entities_path = \"../dogs-vs-cats/data set 2/\" # uncomment this if running on local machine\n",
        "all_entities_names = os.listdir(all_entities_path)\n",
        "\n",
        "filenames = []\n",
        "for entity_name in all_entities_names:\n",
        "    entity_path = os.path.join(all_entities_path, entity_name)\n",
        "    entity_filenames = [os.path.join(entity_path, file_name) for file_name in os.listdir(entity_path) if os.path.join(entity_path, file_name) not in invalid_files]\n",
        "    random.shuffle(entity_filenames)\n",
        "    percentage = 1  # Use only a percentage of the data to speed up the process\n",
        "    entity_filenames = entity_filenames[:int(len(entity_filenames) * percentage)]\n",
        "    filenames.extend([os.path.join(entity_name, file_name) for file_name in entity_filenames])\n",
        "\n",
        "file_labels = [x.split(os.sep)[0] for x in filenames]\n",
        "data = pd.DataFrame({\"filename\": filenames, \"label\": file_labels})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1t3k6egONtP",
        "outputId": "9150b61f-6e5e-4321-dcba-c16b3430fab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n",
            "The shape of train data (19997, 2)\n",
            "The shape of test data (2500, 2)\n",
            "The shape of validation data (2500, 2)\n",
            " \n"
          ]
        }
      ],
      "source": [
        "# 2 --------------------------------------------------------- Train Test Split\n",
        "# region\n",
        "# @title 2 - Train Test Split { display-mode: \"form\" }\n",
        "\n",
        "all_entities_names = data['label']\n",
        "X_train, X_temp = train_test_split(data, test_size=0.2, stratify=all_entities_names, random_state = 42)\n",
        "label_test_val = X_temp['label']\n",
        "X_test, X_val = train_test_split(X_temp, test_size=0.5, stratify=label_test_val, random_state = 42)\n",
        "\n",
        "print(\" \")\n",
        "print('The shape of train data',X_train.shape)\n",
        "print('The shape of test data',X_test.shape)\n",
        "print('The shape of validation data',X_val.shape)\n",
        "print(\" \")\n",
        "\n",
        "# endregion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96TshXPJOSrV",
        "outputId": "e82d25d8-db39-45be-d2b4-771d5d644a6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 19997 validated image filenames belonging to 2 classes.\n",
            "Found 2500 validated image filenames belonging to 2 classes.\n",
            "Found 2500 validated image filenames belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# 3 --------------------------------------------------------- Data Preparation\n",
        "# region\n",
        "# @title 3 - Data Preparation { display-mode: \"form\" }\n",
        "\n",
        "image_size = 128\n",
        "image_channel = 3\n",
        "bat_size = 32\n",
        "\n",
        "# Creating image data generator\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                    rotation_range = 15,\n",
        "                                    horizontal_flip = True,\n",
        "                                    zoom_range = 0.2,\n",
        "                                    shear_range = 0.1,\n",
        "                                    fill_mode = 'reflect',\n",
        "                                    width_shift_range = 0.1,\n",
        "                                    height_shift_range = 0.1)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Applying image data gernerator to train and test data\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(X_train,\n",
        "                                                directory = all_entities_path ,\n",
        "                                                x_col= 'filename',\n",
        "                                                y_col= 'label',\n",
        "                                                batch_size = bat_size,\n",
        "                                                target_size = (image_size,image_size),\n",
        "                                                class_mode='categorical')\n",
        "val_generator = test_datagen.flow_from_dataframe(X_val,\n",
        "                                                directory = all_entities_path ,\n",
        "                                                x_col= 'filename',\n",
        "                                                y_col= 'label',\n",
        "                                                batch_size = bat_size,\n",
        "                                                target_size = (image_size,image_size),\n",
        "                                                shuffle=False,\n",
        "                                                class_mode='categorical')\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(X_test,\n",
        "                                                directory = all_entities_path ,\n",
        "                                                x_col= 'filename',\n",
        "                                                y_col= 'label',\n",
        "                                                batch_size = bat_size,\n",
        "                                                target_size = (image_size,image_size),\n",
        "                                                shuffle=False,\n",
        "                                                class_mode='categorical')\n",
        "\n",
        "# endregion\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Fm1hLn5HOZt_"
      },
      "outputs": [],
      "source": [
        "# 4 --------------------------------------------------------- Deep Learning Model\n",
        "# region\n",
        "# @title 4 - Deep Learning Model { display-mode: \"form\" }\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Input Layer\n",
        "model.add(Conv2D(32,(3,3),activation='relu',input_shape = (image_size,image_size,image_channel)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Bloack 1\n",
        "model.add(Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "# Block 2\n",
        "model.add(Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "# Block 3\n",
        "model.add(Conv2D(256,(3,3),activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Fully Connected layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "# model.summary()\n",
        "\n",
        "# endregion\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "SueU8bBbOdiv"
      },
      "outputs": [],
      "source": [
        "# 4 --------------------------------------------------------- Deep Learning Model\n",
        "# region\n",
        "# @title 4 - Deep Learning Model { display-mode: \"form\" }\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Input Layer\n",
        "model.add(Conv2D(32,(3,3),activation='relu',input_shape = (image_size,image_size,image_channel)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Bloack 1\n",
        "model.add(Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "# Block 2\n",
        "model.add(Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "# Block 3\n",
        "model.add(Conv2D(256,(3,3),activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Fully Connected layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "# model.summary()\n",
        "\n",
        "# endregion\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "TyQcgdqMOguE"
      },
      "outputs": [],
      "source": [
        "# 5 --------------------------------------------------------- Callbacks\n",
        "# region\n",
        "# @title 5 - Callbacks { display-mode: \"form\" }\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
        "                                            patience=2,\n",
        "                                            factor=0.5,\n",
        "                                            min_lr = 0.00001,\n",
        "                                            verbose = 1)\n",
        "\n",
        "early_stoping = EarlyStopping(monitor='val_loss',patience= 3,restore_best_weights=True,verbose=0)\n",
        "\n",
        "# endregion\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "wAPVKdDFOiAM"
      },
      "outputs": [],
      "source": [
        "# 6 --------------------------------------------------------- Model Compilation\n",
        "# region\n",
        "# @title 6 - Model Compilation { display-mode: \"form\" }\n",
        "model.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
        "\n",
        "# endregion\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDbqrio3OjWh",
        "outputId": "7b04d037-eeb6-44a3-f65b-73c7bfb4d85c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train length:  19997\n",
            "x_test length:  2500\n",
            "batch size:  32\n",
            "steps_per_epoch:  19997  //  32  =  624\n",
            "validation_steps:  2500  //  32  =  78\n",
            "Epoch 1/30\n",
            "624/624 [==============================] - 1229s 2s/step - loss: 0.6840 - accuracy: 0.6649 - val_loss: 0.7208 - val_accuracy: 0.6474 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "624/624 [==============================] - 1221s 2s/step - loss: 0.5117 - accuracy: 0.7512 - val_loss: 0.6312 - val_accuracy: 0.7308 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "624/624 [==============================] - 1215s 2s/step - loss: 0.4450 - accuracy: 0.7927 - val_loss: 0.4967 - val_accuracy: 0.7865 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "624/624 [==============================] - 1216s 2s/step - loss: 0.3928 - accuracy: 0.8214 - val_loss: 0.9280 - val_accuracy: 0.6859 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "624/624 [==============================] - 1200s 2s/step - loss: 0.3545 - accuracy: 0.8429 - val_loss: 0.3129 - val_accuracy: 0.8610 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "624/624 [==============================] - 1200s 2s/step - loss: 0.3290 - accuracy: 0.8550 - val_loss: 0.3702 - val_accuracy: 0.8365 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "624/624 [==============================] - 1213s 2s/step - loss: 0.3040 - accuracy: 0.8686 - val_loss: 0.2650 - val_accuracy: 0.8866 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "624/624 [==============================] - 1219s 2s/step - loss: 0.2924 - accuracy: 0.8744 - val_loss: 0.2389 - val_accuracy: 0.8938 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "624/624 [==============================] - 1213s 2s/step - loss: 0.2859 - accuracy: 0.8776 - val_loss: 0.5894 - val_accuracy: 0.7708 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "624/624 [==============================] - 1199s 2s/step - loss: 0.2639 - accuracy: 0.8893 - val_loss: 0.1939 - val_accuracy: 0.9175 - lr: 0.0010\n",
            "Epoch 11/30\n",
            "624/624 [==============================] - 1194s 2s/step - loss: 0.2564 - accuracy: 0.8921 - val_loss: 0.2578 - val_accuracy: 0.8906 - lr: 0.0010\n",
            "Epoch 12/30\n",
            "624/624 [==============================] - ETA: 0s - loss: 0.2509 - accuracy: 0.8933\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "624/624 [==============================] - 1205s 2s/step - loss: 0.2509 - accuracy: 0.8933 - val_loss: 0.2118 - val_accuracy: 0.9147 - lr: 0.0010\n",
            "Epoch 13/30\n",
            "430/624 [===================>..........] - ETA: 6:10 - loss: 0.2197 - accuracy: 0.9086"
          ]
        }
      ],
      "source": [
        "# 7 --------------------------------------------------------- Model Fitting\n",
        "# region\n",
        "# @title 7 - Model Fitting { display-mode: \"form\" }\n",
        "\n",
        "print(\"x_train length: \",len(X_train))\n",
        "print(\"x_test length: \",len(X_test))\n",
        "print(\"batch size: \",bat_size)\n",
        "print(\"steps_per_epoch: \",len(X_train) , \" // \" , bat_size , \" = \" , len(X_train) // bat_size)\n",
        "print(\"validation_steps: \",len(X_test) , \" // \" , bat_size , \" = \" , len(X_test) // bat_size)\n",
        "cat_dog = model.fit(train_generator,\n",
        "                    validation_data = val_generator,\n",
        "                    callbacks=[early_stoping,learning_rate_reduction],\n",
        "                    epochs = 30,\n",
        "                    # data generator must generate at least steps_per_epochs * epochs batches\n",
        "\n",
        "                    steps_per_epoch = len(X_train) // bat_size,\n",
        "                    validation_steps = len(X_test) // bat_size,\n",
        "                   )\n",
        "\n",
        "# endregion\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9VvirSWOk0v"
      },
      "outputs": [],
      "source": [
        "# 8 --------------------------------------------------------- Plot the results\n",
        "# region\n",
        "# @title 8 - Plot the results { display-mode: \"form\" }\n",
        "# plots for accuracy and Loss with epochs\n",
        "\n",
        "error = pd.DataFrame(cat_dog.history)\n",
        "\n",
        "plt.figure(figsize=(18,5),dpi=200)\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.title('Cross Entropy Loss',fontsize=15)\n",
        "plt.xlabel('Epochs',fontsize=12)\n",
        "plt.ylabel('Loss',fontsize=12)\n",
        "plt.plot(error['loss'])\n",
        "plt.plot(error['val_loss'])\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.title('Classification Accuracy',fontsize=15)\n",
        "plt.xlabel('Epochs',fontsize=12)\n",
        "plt.ylabel('Accuracy',fontsize=12)\n",
        "plt.plot(error['accuracy'])\n",
        "plt.plot(error['val_accuracy'])\n",
        "\n",
        "plt.show(block=False)  # hosain : prevent the popup\n",
        "\n",
        "\n",
        "# endregion\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VV3c2l1ROmpD"
      },
      "outputs": [],
      "source": [
        "# 9 --------------------------------------------------------- Evaluation\n",
        "# region\n",
        "# @title 9 - Evaluation { display-mode: \"form\" }\n",
        "# Evaluvate for train generator\n",
        "loss,acc = model.evaluate(train_generator,batch_size = bat_size, verbose = 0)\n",
        "\n",
        "print('The accuracy of the model for training data is:',acc*100)\n",
        "print('The Loss of the model for training data is:',loss)\n",
        "\n",
        "# Evaluvate for validation generator\n",
        "loss,acc = model.evaluate(val_generator,batch_size = bat_size, verbose = 0)\n",
        "\n",
        "print('The accuracy of the model for validation data is:',acc*100)\n",
        "print('The Loss of the model for validation data is:',loss)\n",
        "\n",
        "#  endregion\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRWnjhtoOoVd"
      },
      "outputs": [],
      "source": [
        "# 10 --------------------------------------------------------- save the model\n",
        "# region\n",
        "# @title 10 - save the model { display-mode: \"form\" }\n",
        "model.save(\"model.keras\")\n",
        "# endregion\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlpmx-GlOp3M"
      },
      "outputs": [],
      "source": [
        "# 11 --------------------------------------------------------- Prediction\n",
        "# region\n",
        "# @title 11 - Prediction { display-mode: \"form\" }\n",
        "result = model.predict(test_generator,batch_size = bat_size,verbose = 0)\n",
        "\n",
        "y_pred = np.argmax(result, axis = 1)\n",
        "\n",
        "y_true = test_generator.labels\n",
        "\n",
        "# Evaluvate\n",
        "loss,acc = model.evaluate(test_generator, batch_size = bat_size, verbose = 0)\n",
        "\n",
        "print('The accuracy of the model for testing data is:',acc*100)\n",
        "print('The Loss of the model for testing data is:',loss)\n",
        "\n",
        "# endregion\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSFPmSxjOrNe"
      },
      "outputs": [],
      "source": [
        "# 12 --------------------------------------------------------- Classification Report\n",
        "# region\n",
        "# @title 12 - Classification Report { display-mode: \"form\" }\n",
        "all_entities_names =['Cat','Dog']\n",
        "print(classification_report(y_true, y_pred,target_names=all_entities_names))\n",
        "\n",
        "# endregion\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4g02--rOspL"
      },
      "outputs": [],
      "source": [
        "# 13 --------------------------------------------------- Confusion Matrix\n",
        "# region\n",
        "# @title 13 - Confusion Matrix { display-mode: \"form\" }\n",
        "confusion_mtx = confusion_matrix(y_true,y_pred)\n",
        "print(\"Confusion Matrix: \\n\",confusion_mtx)\n",
        "\n",
        "f,ax = plt.subplots(figsize = (8,4),dpi=200)\n",
        "sns.heatmap(confusion_mtx, annot=True, linewidths=0.1, cmap = \"gist_yarg_r\", linecolor=\"black\", fmt='.0f', ax=ax,cbar=False, xticklabels=all_entities_names, yticklabels=all_entities_names)\n",
        "\n",
        "plt.xlabel(\"Predicted Label\",fontsize=10)\n",
        "plt.ylabel(\"True Label\",fontsize=10)\n",
        "plt.title(\"Confusion Matrix\",fontsize=13)\n",
        "\n",
        "plt.show()\n",
        "# endregion\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
