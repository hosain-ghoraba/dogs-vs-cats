{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> Global Variables & Paths <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --------------------------------------------------------- Global Variables & Paths\n",
        "# region\n",
        "# @title Global Variables & Paths { display-mode: \"form\" }\n",
        "import os\n",
        "\n",
        "# --------------- vscode\n",
        "VS_CODE_RAW_DATA_SET_PATH = '../image_classification/data/extracted_using_python/Dataset' # modify per data set\n",
        "VS_CODE_CLEAN_DATA_SET_PATH = '../dimage_classification/data/clean_data'\n",
        "\n",
        "# --------------- kaggle\n",
        "KAGGLE_RAW_DATA_SET_PATH = '/kaggle/input/arabic-letters-numbers-ocr/Dataset' # put (dataset name immediately after /input), and any extra folders modify per data set\n",
        "KAGGLE_CLEAN_DATA_SET_PATH = '/kaggle/working/clean_data'\n",
        "\n",
        "\n",
        "# --------------- colab\n",
        "KAGGLE_CRED_PATH = '/content/gdrive/MyDrive/Bachelor/kaggle'\n",
        "KAGGLE_DATA_SET_NAME = 'mahmoudreda55/arabic-letters-numbers-ocr'  # username/dataset name..t modify per data set\n",
        "COLAB_RAW_DATA_SET_PATH = '/content/kaggle_data/Dataset' # put (dataset_name) after (kaggle_data) , then put any extra folders... modify the part after (kaggle_data) per data set\n",
        "COLAB_CLAEN_DATA_SET_PATH = '/content/clean_data'\n",
        "\n",
        "# ----------------- global variables\n",
        "EPOCHS = 100\n",
        "DATA_PERCENTAGE_TO_USE = 100\n",
        "\n",
        "# only use raw data if inside vscode\n",
        "# USE_RAW_DATA = 'VSCODE_PID' in os.environ\n",
        "USE_RAW_DATA = False\n",
        "RENAME_CLEAN_DATA = False\n",
        "\n",
        "\n",
        "\n",
        "print('Global Variables & Paths are set successfully.')\n",
        "# endregion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> time calculation function <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --------------------------------------------------------- time calculation function\n",
        "# region\n",
        "# @title time calculation function { display-mode: \"form\" }\n",
        "\n",
        "\n",
        "import time\n",
        "\n",
        "global_start_time = time.time() # to calculate time taken for the whole notebook to run\n",
        "def calculate_and_print_time(start_time , section_name):\n",
        "    end_time = time.time()\n",
        "    time_taken = end_time - start_time\n",
        "    hours = int(time_taken // 3600)\n",
        "    minutes = int((time_taken % 3600) // 60)\n",
        "    seconds = int((time_taken % 3600) % 60)\n",
        "    print(f'\\n{section_name} done in : {hours} h, {minutes} m, {seconds} s')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> install libraries <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --------------------------------------------------------- install libraries\n",
        "# region\n",
        "# @title install libraries { display-mode: \"form\" }\n",
        "\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "import pkg_resources\n",
        "REQUIRED_PACKAGES = ['seaborn', 'tensorflow']\n",
        "\n",
        "for package in REQUIRED_PACKAGES:\n",
        "    try:\n",
        "        dist = pkg_resources.get_distribution(package)\n",
        "        print('{} ({}) is installed'.format(dist.key, dist.version))\n",
        "    except pkg_resources.DistributionNotFound:\n",
        "        print('{} is NOT installed'.format(package))\n",
        "        %pip install {package} \n",
        "# uninstall the standalone keras package to force using the one installed with tensorflow\n",
        "# %pip uninstall keras -y\n",
        "\n",
        "\n",
        "calculate_and_print_time(start_time, 'installing required packages')\n",
        "# print(\"installing required packages done\")\n",
        "# endregion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> imports <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --------------------------------------------------------- imports\n",
        "# region\n",
        "# @title imports { display-mode: \"form\" }\n",
        "start_time = time.time()\n",
        "\n",
        "import os\n",
        "import uuid\n",
        "import time\n",
        "import json\n",
        "import random\n",
        "import warnings\n",
        "import shutil\n",
        "import zipfile\n",
        "from os import makedirs\n",
        "from os import listdir\n",
        "from tqdm import tqdm\n",
        "from shutil import copyfile\n",
        "from random import seed\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,confusion_matrix,ConfusionMatrixDisplay\n",
        "import tensorflow as tf\n",
        "# import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense,MaxPooling2D,Dropout,Flatten,BatchNormalization,Conv2D\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping\n",
        "\n",
        "calculate_and_print_time(start_time, 'imports')\n",
        "# print(\"imports done\")\n",
        "\n",
        "# endregion\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> detect Hardware <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --------------------------------------------------------- detect Hardware\n",
        "# region\n",
        "# @title detect Hardware {display-mode: \"form\"}\n",
        "start_time = time.time()\n",
        "\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "    print(\"Running on TPU\")\n",
        "    print('TPU details: ', tpu.cluster_spec().as_dict())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    if(gpus):\n",
        "        print(\"Running on \", len(gpus), \" GPU(s) \")\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        strategy = tf.distribute.MirroredStrategy(devices=[\"GPU:{}\".format(i) for i in range(len(gpus))])\n",
        "    else:        \n",
        "        print(\"Running on CPU\")\n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
        "calculate_and_print_time(start_time,'detecting hardware')\n",
        "# extra\n",
        "# endregion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> functions <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --------------------------------------------------------- functions\n",
        "# region\n",
        "# @title functions {display-mode: \"form\"}\n",
        "start_time = time.time()\n",
        "\n",
        "raw_data_path = None\n",
        "clean_data_path = None\n",
        "\n",
        "def get_environment():\n",
        "    if 'COLAB_GPU' in os.environ:\n",
        "        return 'Google Colab'\n",
        "    elif 'KAGGLE_URL_BASE' in os.environ:\n",
        "        return 'Kaggle'\n",
        "    elif 'VSCODE_PID' in os.environ:\n",
        "        return 'VS Code'\n",
        "    else:\n",
        "        return 'Unknown environment'\n",
        "\n",
        "def do_colab_staff():\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "\n",
        "    # storing kaggle credentials\n",
        "    os.environ['KAGGLE_CONFIG_DIR'] = KAGGLE_CRED_PATH\n",
        "\n",
        "    !kaggle datasets download -d {KAGGLE_DATA_SET_NAME}\n",
        "    print(\"downloaded dataset\" ,KAGGLE_DATA_SET_NAME )\n",
        "    \n",
        "    \n",
        "    ! mkdir kaggle_data\n",
        "    downloaded_zip_name = f\"{KAGGLE_DATA_SET_NAME.split('/')[-1]}.zip\" # the !kaggle datasets download command will download the zip file with the same name as the dataset name\n",
        "    extract_folder_path = 'kaggle_data'\n",
        "    extract_zip(downloaded_zip_name, extract_folder_path)\n",
        "\n",
        "    global raw_data_path\n",
        "    raw_data_path = COLAB_RAW_DATA_SET_PATH\n",
        "    global clean_data_path\n",
        "    clean_data_path = COLAB_CLAEN_DATA_SET_PATH\n",
        "\n",
        "\n",
        "def do_kaggle_staff():\n",
        "    global raw_data_path\n",
        "    raw_data_path = KAGGLE_RAW_DATA_SET_PATH\n",
        "    global clean_data_path\n",
        "    clean_data_path = KAGGLE_CLEAN_DATA_SET_PATH\n",
        "    \n",
        "def do_vscode_staff():\n",
        "    global raw_data_path\n",
        "    raw_data_path = VS_CODE_RAW_DATA_SET_PATH\n",
        "    global clean_data_path\n",
        "    clean_data_path = VS_CODE_CLEAN_DATA_SET_PATH\n",
        "\n",
        "def do_unknown_environment_staff():\n",
        "    print(\"This is an unknown environment, please enter the path to the data set folder:\")\n",
        "    global raw_data_path\n",
        "    raw_data_path = input()     \n",
        "\n",
        "def image_is_ok(image_path):\n",
        "    with warnings.catch_warnings(record=True) as w:\n",
        "        try:\n",
        "            img = Image.open(image_path)\n",
        "            img.verify()\n",
        "            if len(w) > 0:  # if any warnings were issued\n",
        "                return False\n",
        "            return True\n",
        "        except (IOError, SyntaxError):\n",
        "            return False\n",
        "\n",
        "def copy_clean_files(dirty_dataset_path, destination_folder_path):\n",
        "    print(\"copying clean files...\")\n",
        "    # If the destination directory already exists, remove it and all its contents\n",
        "    if os.path.exists(destination_folder_path):\n",
        "        shutil.rmtree(destination_folder_path)\n",
        "        print(f\"removed {destination_folder_path} directory to create a new one...\")\n",
        "    os.makedirs(destination_folder_path)\n",
        "    for root, dirs, files in os.walk(dirty_dataset_path):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            if image_is_ok(file_path):\n",
        "                new_file_path = os.path.join(destination_folder_path, os.path.relpath(file_path, dirty_dataset_path))\n",
        "                os.makedirs(os.path.dirname(new_file_path) , exist_ok=True)\n",
        "                shutil.copyfile(file_path, new_file_path)\n",
        "            else:\n",
        "                # print(f\"file: {file_path} is corrupted & skipped from dataset while copying \")    \n",
        "                 print(f\"file: {os.path.relpath(file_path, dirty_dataset_path)} is corrupted & skipped from dataset while copying \")\n",
        "    print(f\"copied files from {dirty_dataset_path} to {destination_folder_path} successfully\")             \n",
        "\n",
        "def rename_files(data_set_path):\n",
        "    all_entities_names = sorted(os.listdir(data_set_path))\n",
        "    print(\"giving temporary unique names...\")\n",
        "    for entity_name in all_entities_names:\n",
        "        entity_path = os.path.join(data_set_path, entity_name)\n",
        "        for filename in os.listdir(entity_path):\n",
        "            temp_filename = str(uuid.uuid4()) + \".jpg\"  # generate a unique filename\n",
        "            source = os.path.join(entity_path, filename)\n",
        "            destination = os.path.join(entity_path, temp_filename)\n",
        "            os.rename(source, destination)\n",
        "    # ----------------------------------------------------------------------------------------------------\n",
        "    print(\"renaming...\")\n",
        "    # then rename every file in every folder in the given path\n",
        "\n",
        "    for entity_name in all_entities_names:\n",
        "        entity_path = os.path.join(data_set_path, entity_name)\n",
        "        i = 1\n",
        "        for filename in os.listdir(entity_path):\n",
        "            entity_name = os.fsdecode(entity_name.lower())\n",
        "            new_filename = entity_name + '.' + str(i) + \".jpg\"\n",
        "            source = os.path.join(entity_path, filename)\n",
        "            destination = os.path.join(entity_path, new_filename)\n",
        "            os.rename(source, destination)\n",
        "            i += 1\n",
        "    print(\"done renaming !\")\n",
        "\n",
        "def find_image_folder_after_extracting_zip(extracted_folder_path):\n",
        "    for root, dirs, files in os.walk(extracted_folder_path):\n",
        "        # check if the current directory contains image files\n",
        "        if any(fname.lower().endswith(('.png', '.jpg', '.jpeg')) for fname in files):\n",
        "            return os.path.dirname(root)\n",
        "    return None\n",
        "\n",
        "def extract_zip(source_path, destination_path):\n",
        "    # delete the destination folder if it exists\n",
        "    if os.path.exists(destination_path):\n",
        "        print('Deleting the existing destination folder...')\n",
        "        shutil.rmtree(destination_path)\n",
        "\n",
        "    print(\"Extracting files...\") \n",
        "    with zipfile.ZipFile(source_path, 'r') as zip_ref:\n",
        "        files = zip_ref.infolist()\n",
        "        for file in tqdm(files, desc=\"Extracting files\", unit=\"file\"):\n",
        "            try:\n",
        "                file.filename = file.filename.encode('cp437').decode('utf-8')  # try 'cp437' encoding first\n",
        "            except UnicodeDecodeError:\n",
        "                file.filename = file.filename.encode('utf-8').decode('utf-8')  # fallback to 'utf-8' if 'cp437' fails\n",
        "            zip_ref.extract(file, path=destination_path)\n",
        "\n",
        "    print(\"Extraction complete.\")\n",
        "\n",
        "\n",
        "calculate_and_print_time(start_time, 'functions')\n",
        "# print(\"functions done\")\n",
        "# endregion\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> doing specific-environment things <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --------------------------------------------------------- doing specific-environment things\n",
        "# region\n",
        "# @title doing specific-environment things {display-mode: \"form\"}\n",
        "start_time = time.time()\n",
        "\n",
        "# test if the tpu & GPU is available\n",
        "\n",
        "raw_data_path = None    \n",
        "environment_type = get_environment() \n",
        "print(f'Environment: {environment_type}')     \n",
        "\n",
        "print(\"tensowflow version:\", tf.__version__)\n",
        "if environment_type == 'Google Colab':\n",
        "    do_colab_staff()\n",
        "elif environment_type == 'Kaggle':\n",
        "    do_kaggle_staff()\n",
        "elif environment_type == 'VS Code':\n",
        "    do_vscode_staff()\n",
        "else:\n",
        "    do_unknown_environment_staff()\n",
        "\n",
        "print(\"raw data set path:\", raw_data_path)\n",
        "assert os.path.exists(raw_data_path), ' wrong path for data set !' \n",
        "print(\"clean data set path:\", clean_data_path)\n",
        "  \n",
        "calculate_and_print_time(start_time, 'doing specific-environment things')\n",
        "# print(\"doing specific-environment things done\")\n",
        "\n",
        "# endregion\n",
        "\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> data preparation <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --------------------------------------------------------- data preparation\n",
        "# region\n",
        "# @title data preparation {display-mode: \"form\"}\n",
        "start_time = time.time()\n",
        "\n",
        "print(\"raw data path:\", raw_data_path)\n",
        "parent_dir = os.path.dirname(raw_data_path)\n",
        "print(\"raw data parent dir:\", parent_dir)\n",
        "print(\"clean data path:\", clean_data_path)\n",
        "\n",
        "if USE_RAW_DATA:\n",
        "    ready_data_path = raw_data_path\n",
        "    print(\"we will use raw data directly\")\n",
        "else :\n",
        "    if os.path.exists('data_is_clean.txt'):\n",
        "        print(\"data was previously copied and cleaned\")\n",
        "    else:\n",
        "        print(\"data_is_clean.txt file does not exist, assuming data is not clean.\")\n",
        "        copy_clean_files(raw_data_path, clean_data_path)\n",
        "        if RENAME_CLEAN_DATA:\n",
        "            rename_files(clean_data_path)\n",
        "        with open('data_is_clean.txt', 'w') as f:\n",
        "            f.write('the existance of this file means the data is claen, that is all !')\n",
        "    ready_data_path = clean_data_path        \n",
        "\n",
        "# ----------------------------\n",
        "\n",
        "\n",
        "print(\"we will use \", DATA_PERCENTAGE_TO_USE, \"% of the data\")\n",
        "calculate_and_print_time(start_time, 'data preparation')\n",
        "# print(\"data preparation done\")\n",
        "\n",
        "\n",
        "# endregion\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1 > 1 - Loading Images in a Dataframe <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9g1mXLiOBTX"
      },
      "outputs": [],
      "source": [
        "# 1 --------------------------------------------------------- Loading Images in a Dataframe\n",
        "# region\n",
        "# @title 1 - Loading Images in a Dataframe { display-mode: \"form\" }\n",
        "start_time = time.time()\n",
        "\n",
        "all_entities_names = sorted(os.listdir(ready_data_path))\n",
        "print(\"all entities names:\", sorted(all_entities_names))\n",
        "filenames = []\n",
        "original_data_set_size = 0\n",
        "for entity_name in all_entities_names:\n",
        "    entity_path = os.path.join(ready_data_path, entity_name)\n",
        "    entity_filenames = [file_name for file_name in os.listdir(entity_path)]\n",
        "    original_data_set_size += len(entity_filenames)\n",
        "    random.shuffle(entity_filenames)\n",
        "    entity_filenames = entity_filenames[:int(len(entity_filenames) * (DATA_PERCENTAGE_TO_USE / 100))]\n",
        "    filenames.extend([os.path.join(entity_name, file_name) for file_name in entity_filenames])\n",
        "\n",
        "print(f\"selected data set size = {DATA_PERCENTAGE_TO_USE / 100} * {original_data_set_size} = {len(filenames)}\") \n",
        "file_labels = [x.split(os.sep)[0] for x in filenames] \n",
        "data = pd.DataFrame({\"filename\": filenames, \"label\": file_labels})\n",
        "data = data.sort_values('label', kind='mergesort')\n",
        "print(\"data head :\", data.head())\n",
        "print(\"data tail :\", data.tail())                                   \n",
        "\n",
        "\n",
        "\n",
        "calculate_and_print_time(start_time, 'Loading Images in a Dataframe')\n",
        "# print(\"Loading Images in a Dataframe done\")\n",
        "# endregion\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> 2 - Train Test Split <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1t3k6egONtP",
        "outputId": "9150b61f-6e5e-4321-dcba-c16b3430fab5"
      },
      "outputs": [],
      "source": [
        "# 2 --------------------------------------------------------- Train Test Split\n",
        "# region\n",
        "# @title 2 - Train Test Split { display-mode: \"form\" }\n",
        "start_time = time.time()\n",
        "\n",
        "lables = data['label']\n",
        "X_train, X_temp = train_test_split(data, test_size=0.2, stratify=lables, random_state = 42)\n",
        "label_test_val = X_temp['label']\n",
        "X_test, X_val = train_test_split(X_temp, test_size=0.5, stratify=label_test_val, random_state = 42)\n",
        "\n",
        "print(\" \")\n",
        "print('The shape of train data',X_train.shape)\n",
        "print('The shape of test data',X_test.shape)\n",
        "print('The shape of validation data',X_val.shape)\n",
        "print(\" \")\n",
        "\n",
        "calculate_and_print_time(start_time, 'Train Test Split')\n",
        "\n",
        "# endregion\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> 3 - Creating Image Data Generator <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96TshXPJOSrV",
        "outputId": "e82d25d8-db39-45be-d2b4-771d5d644a6c"
      },
      "outputs": [],
      "source": [
        "# 3 --------------------------------------------------------- Creating Image Data Generator\n",
        "# region\n",
        "# @title 3 - Creating Image Data Generator  { display-mode: \"form\" }\n",
        "start_time = time.time()\n",
        "\n",
        "image_size = 128\n",
        "image_channel = 3\n",
        "if tpu:\n",
        "    bat_size = 128 * strategy.num_replicas_in_sync\n",
        "else:    \n",
        "    bat_size = 32\n",
        "\n",
        "# Creating image data generator\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                    rotation_range = 15,\n",
        "                                    horizontal_flip = True,\n",
        "                                    zoom_range = 0.2,\n",
        "                                    shear_range = 0.1,\n",
        "                                    fill_mode = 'reflect',\n",
        "                                    width_shift_range = 0.1,\n",
        "                                    height_shift_range = 0.1)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Applying image data gernerator to train and test data\n",
        "\n",
        "# print(\"all entities path : \", all_entities_path)\n",
        "# print (\"X_train head: \", X_train.head())\n",
        "# print (\"X_val head: \", X_val.head())\n",
        "# print (\"X_test head: \", X_test.head())\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(X_train,\n",
        "                                                directory = ready_data_path ,\n",
        "                                                x_col= 'filename',\n",
        "                                                y_col= 'label',\n",
        "                                                batch_size = bat_size,\n",
        "                                                target_size = (image_size,image_size),\n",
        "                                                class_mode='categorical')\n",
        "# print(\"tain generator indicise : \" ,train_generator.class_indices)\n",
        "# print(\"corrupted files : \", corrupted_file_paths)\n",
        "val_generator = test_datagen.flow_from_dataframe(X_val,\n",
        "                                                directory = ready_data_path ,\n",
        "                                                x_col= 'filename',\n",
        "                                                y_col= 'label',\n",
        "                                                batch_size = bat_size,\n",
        "                                                target_size = (image_size,image_size),\n",
        "                                                shuffle=False,\n",
        "                                                class_mode='categorical')\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(X_test,\n",
        "                                                directory = ready_data_path ,\n",
        "                                                x_col= 'filename',\n",
        "                                                y_col= 'label',\n",
        "                                                batch_size = bat_size,\n",
        "                                                target_size = (image_size,image_size),\n",
        "                                                shuffle=False,\n",
        "                                                class_mode='categorical')\n",
        "\n",
        "calculate_and_print_time(start_time, 'Creating Image Data Generator')\n",
        "# print(\"Creating Image Data Generator done\")\n",
        "\n",
        "# endregion\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> 4 - Deep Learning Model <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fm1hLn5HOZt_"
      },
      "outputs": [],
      "source": [
        "# 4 --------------------------------------------------------- Deep Learning Model\n",
        "# region\n",
        "# @title 4 - Deep Learning Model { display-mode: \"form\" }\n",
        "start_time = time.time()\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input Layer\n",
        "    model.add(Conv2D(32,(3,3),activation='relu',input_shape = (image_size,image_size,image_channel)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # Bloack 1\n",
        "    model.add(Conv2D(64,(3,3),activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    # Block 2\n",
        "    model.add(Conv2D(128,(3,3),activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    # Block 3\n",
        "    model.add(Conv2D(256,(3,3),activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # Fully Connected layers\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512,activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # Output layer\n",
        "    # get the number of classes\n",
        "    num_classes = len(train_generator.class_indices)\n",
        "    model.add(Dense(num_classes,activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "with strategy.scope():\n",
        "    model = create_model()\n",
        "# model.summary()\n",
        "\n",
        "calculate_and_print_time(start_time, 'Deep Learning Model')\n",
        "# print(\"Deep Learning Model done\")\n",
        "\n",
        "# endregion\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> 5 - Callbacks <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyQcgdqMOguE"
      },
      "outputs": [],
      "source": [
        "# 5 --------------------------------------------------------- Callbacks\n",
        "# region\n",
        "# @title 5 - Callbacks { display-mode: \"form\" }\n",
        "start_time = time.time()\n",
        "\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
        "                                            patience=2,\n",
        "                                            factor=0.5,\n",
        "                                            min_lr = 0.00001,\n",
        "                                            verbose = 1)\n",
        "\n",
        "early_stoping = EarlyStopping(monitor='val_loss',patience= 3,restore_best_weights=True,verbose=0)\n",
        "\n",
        "calculate_and_print_time(start_time, 'Callbacks')\n",
        "# print(\"Callbacks done\")\n",
        "\n",
        "# endregion\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> 6 - Model Compilation <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAPVKdDFOiAM"
      },
      "outputs": [],
      "source": [
        "# 6 --------------------------------------------------------- Model Compilation\n",
        "# region\n",
        "# @title 6 - Model Compilation { display-mode: \"form\" }\n",
        "start_time = time.time()\n",
        "\n",
        "with strategy.scope():\n",
        "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "calculate_and_print_time(start_time, 'Model Compilation')\n",
        "# print(\"Model Compilation done\")\n",
        "\n",
        "# endregion\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> 7 - Model Fitting <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDbqrio3OjWh",
        "outputId": "7b04d037-eeb6-44a3-f65b-73c7bfb4d85c"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_steps: \u001b[39m\u001b[38;5;124m\"\u001b[39m, validation_steps)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m strategy\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m---> 17\u001b[0m     training_history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stoping\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlearning_rate_reduction\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                   \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m calculate_and_print_time(start_time, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel Fitting\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# print(\"Model Fitting done\")\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# endregion\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\Bachelor\\image_classification\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\Bachelor\\image_classification\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:325\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    324\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 325\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[0;32m    327\u001b[0m         step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    328\u001b[0m     )\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
            "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\Bachelor\\image_classification\\env\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\Bachelor\\image_classification\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\Bachelor\\image_classification\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\Bachelor\\image_classification\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\Bachelor\\image_classification\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\Bachelor\\image_classification\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
            "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\Bachelor\\image_classification\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\Bachelor\\image_classification\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
            "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\Bachelor\\image_classification\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 7 --------------------------------------------------------- Model Fitting\n",
        "# region\n",
        "# @title 7 - Model Fitting { display-mode: \"form\" }\n",
        "start_time = time.time()\n",
        "\n",
        "print(\"number of samples in train generator: \", train_generator.samples)\n",
        "print(\"number of samples in test generator: \", test_generator.samples)\n",
        "print(\"batch size: \", bat_size)\n",
        "\n",
        "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
        "validation_steps = val_generator.samples // val_generator.batch_size\n",
        "\n",
        "print(\"steps_per_epoch: \", steps_per_epoch)\n",
        "print(\"validation_steps: \", validation_steps)\n",
        "\n",
        "with strategy.scope():\n",
        "    training_history = model.fit(train_generator,\n",
        "                    validation_data = val_generator,\n",
        "                    callbacks=[early_stoping,learning_rate_reduction],\n",
        "                    epochs = EPOCHS,\n",
        "                    steps_per_epoch = steps_per_epoch,\n",
        "                    validation_steps = validation_steps,\n",
        "                   )\n",
        "\n",
        "calculate_and_print_time(start_time, 'Model Fitting')\n",
        "# print(\"Model Fitting done\")\n",
        "# endregion\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> 8 - Plot the results <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9VvirSWOk0v"
      },
      "outputs": [],
      "source": [
        "# 8 --------------------------------------------------------- Plot the results\n",
        "# region\n",
        "# @title 8 - Plot the results { display-mode: \"form\" }\n",
        "# plots for accuracy and Loss with epochs\n",
        "start_time = time.time()\n",
        "\n",
        "error = pd.DataFrame(training_history.history)\n",
        "\n",
        "plt.figure(figsize=(18,5),dpi=200)\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.title('Cross Entropy Loss',fontsize=15)\n",
        "plt.xlabel('Epochs',fontsize=12)\n",
        "plt.ylabel('Loss',fontsize=12)\n",
        "plt.plot(error['loss'])\n",
        "plt.plot(error['val_loss'])\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.title('Classification Accuracy',fontsize=15)\n",
        "plt.xlabel('Epochs',fontsize=12)\n",
        "plt.ylabel('Accuracy',fontsize=12)\n",
        "plt.plot(error['accuracy'])\n",
        "plt.plot(error['val_accuracy'])\n",
        "\n",
        "plt.show(block=False)  # hosain : prevent the popup\n",
        "\n",
        "calculate_and_print_time(start_time, 'Plot the results')\n",
        "# print(\"Plot the results done\")\n",
        "\n",
        "# endregion\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> 9 - Evaluation <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VV3c2l1ROmpD"
      },
      "outputs": [],
      "source": [
        "# 9 --------------------------------------------------------- Evaluation\n",
        "# region\n",
        "# @title 9 - Evaluation { display-mode: \"form\" }\n",
        "# Evaluvate for train generator\n",
        "start_time = time.time()\n",
        "\n",
        "loss,acc = model.evaluate(train_generator,batch_size = bat_size, verbose = 0)\n",
        "\n",
        "print('The accuracy of the model for training data is:',acc*100)\n",
        "print('The Loss of the model for training data is:',loss)\n",
        "\n",
        "# Evaluvate for validation generator\n",
        "loss,acc = model.evaluate(val_generator,batch_size = bat_size, verbose = 0)\n",
        "\n",
        "print('The accuracy of the model for validation data is:',acc*100)\n",
        "print('The Loss of the model for validation data is:',loss)\n",
        "\n",
        "calculate_and_print_time(start_time, 'Evaluation')\n",
        "# print(\"Evaluation done\")\n",
        "\n",
        "#  endregion\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> 10 - save the model <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRWnjhtoOoVd"
      },
      "outputs": [],
      "source": [
        "# 10 --------------------------------------------------------- save the model\n",
        "# region\n",
        "# @title 10 - save the model { display-mode: \"form\" }\n",
        "start_time = time.time()\n",
        "\n",
        "model.save(\"model.keras\")\n",
        "# save the labels of the classes ,with same order they appear in confusion matrix,\n",
        "#  to print the label of the predicted class when using the model\n",
        "\n",
        "class_indices = train_generator.class_indices\n",
        "index_to_label = {index: label for label, index in class_indices.items()}\n",
        "with open('index_to_label.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(index_to_label, f, ensure_ascii=False)\n",
        "\n",
        "\n",
        "calculate_and_print_time(start_time, 'saving the model')\n",
        "# print(\"Model saved\")\n",
        "# endregion\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> 11 - Prediction <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlpmx-GlOp3M"
      },
      "outputs": [],
      "source": [
        "# 11 --------------------------------------------------------- Prediction\n",
        "# region\n",
        "# @title 11 - Prediction { display-mode: \"form\" }\n",
        "start_time = time.time()\n",
        "result = model.predict(test_generator,batch_size = bat_size,verbose = 0)\n",
        "\n",
        "y_pred = np.argmax(result, axis = 1)\n",
        "\n",
        "y_true = test_generator.labels\n",
        "\n",
        "# Evaluvate\n",
        "loss,acc = model.evaluate(test_generator, batch_size = bat_size, verbose = 0)\n",
        "\n",
        "print('The accuracy of the model for testing data is:',acc*100)\n",
        "print('The Loss of the model for testing data is:',loss)\n",
        "\n",
        "calculate_and_print_time(start_time, 'Prediction')\n",
        "# print(\"Prediction done\")\n",
        "\n",
        "# endregion\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> 12 - Classification Report <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSFPmSxjOrNe"
      },
      "outputs": [],
      "source": [
        "# 12 --------------------------------------------------------- Classification Report\n",
        "# region\n",
        "# @title 12 - Classification Report { display-mode: \"form\" }\n",
        "start_time = time.time()\n",
        "\n",
        "print(\"all entities names:\", all_entities_names)\n",
        "print(classification_report(y_true, y_pred,target_names=all_entities_names))\n",
        "\n",
        "calculate_and_print_time(start_time , 'Classification Report')\n",
        "# print(\"Classification Report done\")\n",
        "\n",
        "# endregion\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> 13 - Confusion Matrix <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4g02--rOspL"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 13 --------------------------------------------------------- Confusion Matrix\n",
        "# Normalize the confusion matrix\n",
        "# region\n",
        "# @title 13 - Confusion Matrix { display-mode: \"form\" }\n",
        "start_time = time.time()\n",
        "\n",
        "confusion_mtx = confusion_matrix(y_true, y_pred)\n",
        "confusion_mtx = confusion_mtx.astype('float') / confusion_mtx.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "num_classes = confusion_mtx.shape[0]\n",
        "figsize = 40  # adjust as needed\n",
        "\n",
        "f, ax = plt.subplots(figsize=(figsize, figsize), dpi=200)\n",
        "sns.heatmap(confusion_mtx, annot=True, linewidths=0.1, cmap=\"gist_yarg_r\", linecolor=\"black\", fmt='.2%', ax=ax, cbar=False, xticklabels=all_entities_names, yticklabels=all_entities_names)\n",
        "\n",
        "plt.xlabel(\"Predicted Label\", fontsize=10)\n",
        "plt.ylabel(\"True Label\", fontsize=10)\n",
        "plt.title(\"Confusion Matrix\", fontsize=13)\n",
        "\n",
        "# plt.savefig('confusion_matrix.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Print accuracy for each class\n",
        "for i in range(num_classes):\n",
        "    true_positives = confusion_mtx[i, i]\n",
        "    accuracy = true_positives * 100  # convert to percentage\n",
        "    print(f\"Accuracy for class ( {all_entities_names[i]} ) : {accuracy:.2f}%\")\n",
        "\n",
        "    # Print confusion with other classes\n",
        "    for j in range(num_classes):\n",
        "        if i != j and confusion_mtx[i, j] > 0:\n",
        "            confusion = confusion_mtx[i, j] * 100  # convert to percentage\n",
        "            print(f\"Class ({all_entities_names[i]}) was wrongly seen as class ({all_entities_names[j]}) in {confusion:.2f}% of cases\")\n",
        "    print()        \n",
        "\n",
        "calculate_and_print_time(start_time , 'Confusion Matrix')\n",
        "# print(\"Confusion Matrix done\")\n",
        "\n",
        "# endregion "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> 14 - Execution Time <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 14 --------------------------------------------------------- Execution Time\n",
        "# region\n",
        "# @title 14 - Execution time  { display-mode: \"form\" }\n",
        "\n",
        "calculate_and_print_time(global_start_time , 'Whole notebook execution time')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> 15 - reference codes <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --------------------------------------------------------- reference codes\n",
        "# region\n",
        "#  @title  reference codes { display-mode: \"form\" }\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "\n",
        "# import zipfile\n",
        "# import os\n",
        "# extract_source = \"/content/gdrive/My Drive/GUC Bachelor : Arabic Image-to-Letters Script Recognition/data set/data set 2.zip\"\n",
        "# extract_destination = \"/content/extracted_from_drive\"\n",
        "# zip_ref = zipfile.ZipFile(extract_source, 'r')\n",
        "# print(\"extracting...\")\n",
        "# zip_ref.extractall(extract_destination)\n",
        "# extracted_folder_name = os.listdir(extract_destination)[0]\n",
        "# zip_ref.close()\n",
        "# print(\"extracted files from drive to colab successfully !\")\n",
        "# all_entities_path = os.path.join(extract_destination, extracted_folder_name)\n",
        "\n",
        "\n",
        "# def get_corrupted_files_paths(all_entities_path):\n",
        "#     all_entities_names = os.listdir(all_entities_path)\n",
        "#     corrupted_file_paths = set()\n",
        "#     print(\"\\nVerifying all files are non-corrupted images...\")\n",
        "#     for entity_name in all_entities_names:\n",
        "#         entity_path = os.path.join(all_entities_path, entity_name)\n",
        "#         for filename in os.listdir(entity_path):\n",
        "#             file_path = os.path.join(entity_path, filename)\n",
        "#             if not image_is_ok(file_path):\n",
        "#                 print(f\"File {file_path} is corrupted and will be skipped.\")\n",
        "#                 corrupted_file_paths.add(file_path)\n",
        "#     print(\"Your data is ok.\" if not corrupted_file_paths else \"Done reporting error files.\")\n",
        "#     return corrupted_file_paths\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
