{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ece101dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T18:29:20.962756Z",
     "iopub.status.busy": "2024-05-05T18:29:20.962367Z",
     "iopub.status.idle": "2024-05-05T18:29:20.967129Z",
     "shell.execute_reply": "2024-05-05T18:29:20.966353Z"
    },
    "papermill": {
     "duration": 0.010713,
     "end_time": "2024-05-05T18:29:20.969005",
     "exception": false,
     "start_time": "2024-05-05T18:29:20.958292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# def clear_directory(dir_path):\n",
    "#     for filename in os.listdir(dir_path):\n",
    "#         file_path = os.path.join(dir_path, filename)\n",
    "#         if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "#             os.unlink(file_path)  # remove file or symlink\n",
    "#         elif os.path.isdir(file_path):\n",
    "#             shutil.rmtree(file_path)  # remove directory\n",
    "\n",
    "# # Usage:\n",
    "# dir_path = \"/kaggle/working/\"\n",
    "# clear_directory(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9844afc",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-05T18:29:20.974357Z",
     "iopub.status.busy": "2024-05-05T18:29:20.974106Z",
     "iopub.status.idle": "2024-05-05T19:16:39.162319Z",
     "shell.execute_reply": "2024-05-05T19:16:39.161386Z"
    },
    "papermill": {
     "duration": 2838.193137,
     "end_time": "2024-05-05T19:16:39.164254",
     "exception": false,
     "start_time": "2024-05-05T18:29:20.971117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 18:29:22.717789: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-05 18:29:22.717923: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-05 18:29:22.852253: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying models to kaggle...\n",
      "loading models in RAM...\n",
      "loading model in : /kaggle/working/models/model_imagesPerEntity_918_imgSize_16_dataPercentage_100_batchSize_32_epochs_100.keras ...\n",
      "loading model in : /kaggle/working/models/model_imagesPerEntity_918_imgSize_32_dataPercentage_100_batchSize_32_epochs_100.keras ...\n",
      "loading model in : /kaggle/working/models/model_imagesPerEntity_918_imgSize_64_dataPercentage_100_batchSize_32_epochs_100.keras ...\n",
      "loading model in : /kaggle/working/models/model_imagesPerEntity_918_imgSize_128_dataPercentage_100_batchSize_32_epochs_100.keras ...\n",
      "loading model in : /kaggle/working/models/model_imagesPerEntity_918_imgSize_256_dataPercentage_100_batchSize_32_epochs_100.keras ...\n",
      "loading model in : /kaggle/working/models/model_imagesPerEntity_918_imgSize_300_dataPercentage_100_batchSize_32_epochs_100.keras ...\n",
      "loading model in : /kaggle/working/models/model_imagesPerEntity_1048_imgSize_16_dataPercentage_100_batchSize_32_epochs_100.keras ...\n",
      "loading model in : /kaggle/working/models/model_imagesPerEntity_1048_imgSize_32_dataPercentage_100_batchSize_32_epochs_100.keras ...\n",
      "loading model in : /kaggle/working/models/model_imagesPerEntity_1048_imgSize_64_dataPercentage_100_batchSize_32_epochs_100.keras ...\n",
      "loading model in : /kaggle/working/models/model_imagesPerEntity_1048_imgSize_128_dataPercentage_100_batchSize_32_epochs_100.keras ...\n",
      "loading model in : /kaggle/working/models/model_imagesPerEntity_1048_imgSize_256_dataPercentage_100_batchSize_32_epochs_100.keras ...\n",
      "loading model in : /kaggle/working/models/model_imagesPerEntity_1048_imgSize_300_dataPercentage_100_batchSize_32_epochs_100.keras ...\n",
      "loading model in : /kaggle/working/models/model_imagesPerEntity_2481_imgSize_16_dataPercentage_100_batchSize_32_epochs_100.keras ...\n",
      "loading model in : /kaggle/working/models/model_imagesPerEntity_2481_imgSize_32_dataPercentage_100_batchSize_32_epochs_100.keras ...\n",
      "loading model in : /kaggle/working/models/model_imagesPerEntity_2481_imgSize_64_dataPercentage_100_batchSize_32_epochs_100.keras ...\n",
      "loading model in : /kaggle/working/models/model_imagesPerEntity_2481_imgSize_128_dataPercentage_100_batchSize_32_epochs_100.keras ...\n",
      "loading model in : /kaggle/working/models/model_imagesPerEntity_2481_imgSize_256_dataPercentage_100_batchSize_32_epochs_100.keras ...\n",
      "loading model in : /kaggle/working/models/model_imagesPerEntity_2481_imgSize_300_dataPercentage_100_batchSize_32_epochs_100.keras ...\n",
      "Testing dataset : /kaggle/input/arabic-letters-900-images-per-letter ...\n",
      "trained_data_size : 918, img_size : 16, model_name : model_imagesPerEntity_918_imgSize_16 ...\n",
      "Found 25704 images belonging to 28 classes.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 146ms/step\n",
      "Accuracy of model model_imagesPerEntity_918_imgSize_16 on dataset arabic-letters-900-images-per-letter : 0.273\n",
      "trained_data_size : 918, img_size : 32, model_name : model_imagesPerEntity_918_imgSize_32 ...\n",
      "Found 25704 images belonging to 28 classes.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 31ms/step\n",
      "Accuracy of model model_imagesPerEntity_918_imgSize_32 on dataset arabic-letters-900-images-per-letter : 0.681\n",
      "trained_data_size : 918, img_size : 64, model_name : model_imagesPerEntity_918_imgSize_64 ...\n",
      "Found 25704 images belonging to 28 classes.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 31ms/step\n",
      "Accuracy of model model_imagesPerEntity_918_imgSize_64 on dataset arabic-letters-900-images-per-letter : 0.904\n",
      "trained_data_size : 918, img_size : 128, model_name : model_imagesPerEntity_918_imgSize_128 ...\n",
      "Found 25704 images belonging to 28 classes.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 35ms/step\n",
      "Accuracy of model model_imagesPerEntity_918_imgSize_128 on dataset arabic-letters-900-images-per-letter : 0.719\n",
      "trained_data_size : 918, img_size : 256, model_name : model_imagesPerEntity_918_imgSize_256 ...\n",
      "Found 25704 images belonging to 28 classes.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 38ms/step\n",
      "Accuracy of model model_imagesPerEntity_918_imgSize_256 on dataset arabic-letters-900-images-per-letter : 0.586\n",
      "trained_data_size : 918, img_size : 300, model_name : model_imagesPerEntity_918_imgSize_300 ...\n",
      "Found 25704 images belonging to 28 classes.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 42ms/step\n",
      "Accuracy of model model_imagesPerEntity_918_imgSize_300 on dataset arabic-letters-900-images-per-letter : 0.09\n",
      "trained_data_size : 1048, img_size : 16, model_name : model_imagesPerEntity_1048_imgSize_16 ...\n",
      "Found 25704 images belonging to 28 classes.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 31ms/step\n",
      "Accuracy of model model_imagesPerEntity_1048_imgSize_16 on dataset arabic-letters-900-images-per-letter : 0.216\n",
      "trained_data_size : 1048, img_size : 32, model_name : model_imagesPerEntity_1048_imgSize_32 ...\n",
      "Found 25704 images belonging to 28 classes.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 32ms/step\n",
      "Accuracy of model model_imagesPerEntity_1048_imgSize_32 on dataset arabic-letters-900-images-per-letter : 0.477\n",
      "trained_data_size : 1048, img_size : 64, model_name : model_imagesPerEntity_1048_imgSize_64 ...\n",
      "Found 25704 images belonging to 28 classes.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 30ms/step\n",
      "Accuracy of model model_imagesPerEntity_1048_imgSize_64 on dataset arabic-letters-900-images-per-letter : 0.641\n",
      "trained_data_size : 1048, img_size : 128, model_name : model_imagesPerEntity_1048_imgSize_128 ...\n",
      "Found 25704 images belonging to 28 classes.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 32ms/step\n",
      "Accuracy of model model_imagesPerEntity_1048_imgSize_128 on dataset arabic-letters-900-images-per-letter : 0.474\n",
      "trained_data_size : 1048, img_size : 256, model_name : model_imagesPerEntity_1048_imgSize_256 ...\n",
      "Found 25704 images belonging to 28 classes.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 36ms/step\n",
      "Accuracy of model model_imagesPerEntity_1048_imgSize_256 on dataset arabic-letters-900-images-per-letter : 0.223\n",
      "trained_data_size : 1048, img_size : 300, model_name : model_imagesPerEntity_1048_imgSize_300 ...\n",
      "Found 25704 images belonging to 28 classes.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 40ms/step\n",
      "Accuracy of model model_imagesPerEntity_1048_imgSize_300 on dataset arabic-letters-900-images-per-letter : 0.471\n",
      "trained_data_size : 2481, img_size : 16, model_name : model_imagesPerEntity_2481_imgSize_16 ...\n",
      "Found 25704 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m  1/804\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:56\u001b[0m 220ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 30ms/step\n",
      "Accuracy of model model_imagesPerEntity_2481_imgSize_16 on dataset arabic-letters-900-images-per-letter : 0.076\n",
      "trained_data_size : 2481, img_size : 32, model_name : model_imagesPerEntity_2481_imgSize_32 ...\n",
      "Found 25704 images belonging to 28 classes.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 32ms/step\n",
      "Accuracy of model model_imagesPerEntity_2481_imgSize_32 on dataset arabic-letters-900-images-per-letter : 0.104\n",
      "trained_data_size : 2481, img_size : 64, model_name : model_imagesPerEntity_2481_imgSize_64 ...\n",
      "Found 25704 images belonging to 28 classes.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 31ms/step\n",
      "Accuracy of model model_imagesPerEntity_2481_imgSize_64 on dataset arabic-letters-900-images-per-letter : 0.079\n",
      "trained_data_size : 2481, img_size : 128, model_name : model_imagesPerEntity_2481_imgSize_128 ...\n",
      "Found 25704 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m  1/804\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:56\u001b[0m 219ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 33ms/step\n",
      "Accuracy of model model_imagesPerEntity_2481_imgSize_128 on dataset arabic-letters-900-images-per-letter : 0.104\n",
      "trained_data_size : 2481, img_size : 256, model_name : model_imagesPerEntity_2481_imgSize_256 ...\n",
      "Found 25704 images belonging to 28 classes.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 37ms/step\n",
      "Accuracy of model model_imagesPerEntity_2481_imgSize_256 on dataset arabic-letters-900-images-per-letter : 0.091\n",
      "trained_data_size : 2481, img_size : 300, model_name : model_imagesPerEntity_2481_imgSize_300 ...\n",
      "Found 25704 images belonging to 28 classes.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 38ms/step\n",
      "Accuracy of model model_imagesPerEntity_2481_imgSize_300 on dataset arabic-letters-900-images-per-letter : 0.077\n",
      "Testing dataset : /kaggle/input/arabic-letters-1000-images-per-letter ...\n",
      "trained_data_size : 918, img_size : 16, model_name : model_imagesPerEntity_918_imgSize_16 ...\n",
      "Found 29344 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m  4/917\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m51s\u001b[0m 56ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 71ms/step\n",
      "Accuracy of model model_imagesPerEntity_918_imgSize_16 on dataset arabic-letters-1000-images-per-letter : 0.255\n",
      "trained_data_size : 918, img_size : 32, model_name : model_imagesPerEntity_918_imgSize_32 ...\n",
      "Found 29344 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m  7/917\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 24ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 25ms/step\n",
      "Accuracy of model model_imagesPerEntity_918_imgSize_32 on dataset arabic-letters-1000-images-per-letter : 0.428\n",
      "trained_data_size : 918, img_size : 64, model_name : model_imagesPerEntity_918_imgSize_64 ...\n",
      "Found 29344 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m  6/917\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 25ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 28ms/step\n",
      "Accuracy of model model_imagesPerEntity_918_imgSize_64 on dataset arabic-letters-1000-images-per-letter : 0.496\n",
      "trained_data_size : 918, img_size : 128, model_name : model_imagesPerEntity_918_imgSize_128 ...\n",
      "Found 29344 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m  7/917\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 26ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 28ms/step\n",
      "Accuracy of model model_imagesPerEntity_918_imgSize_128 on dataset arabic-letters-1000-images-per-letter : 0.259\n",
      "trained_data_size : 918, img_size : 256, model_name : model_imagesPerEntity_918_imgSize_256 ...\n",
      "Found 29344 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m  5/917\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 35ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 36ms/step\n",
      "Accuracy of model model_imagesPerEntity_918_imgSize_256 on dataset arabic-letters-1000-images-per-letter : 0.18\n",
      "trained_data_size : 918, img_size : 300, model_name : model_imagesPerEntity_918_imgSize_300 ...\n",
      "Found 29344 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m  3/917\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 39ms/step "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 38ms/step\n",
      "Accuracy of model model_imagesPerEntity_918_imgSize_300 on dataset arabic-letters-1000-images-per-letter : 0.088\n",
      "trained_data_size : 1048, img_size : 16, model_name : model_imagesPerEntity_1048_imgSize_16 ...\n",
      "Found 29344 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m  7/917\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 27ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 28ms/step\n",
      "Accuracy of model model_imagesPerEntity_1048_imgSize_16 on dataset arabic-letters-1000-images-per-letter : 0.698\n",
      "trained_data_size : 1048, img_size : 32, model_name : model_imagesPerEntity_1048_imgSize_32 ...\n",
      "Found 29344 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m  7/917\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 24ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 25ms/step\n",
      "Accuracy of model model_imagesPerEntity_1048_imgSize_32 on dataset arabic-letters-1000-images-per-letter : 0.782\n",
      "trained_data_size : 1048, img_size : 64, model_name : model_imagesPerEntity_1048_imgSize_64 ...\n",
      "Found 29344 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m  7/917\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 23ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 26ms/step\n",
      "Accuracy of model model_imagesPerEntity_1048_imgSize_64 on dataset arabic-letters-1000-images-per-letter : 0.933\n",
      "trained_data_size : 1048, img_size : 128, model_name : model_imagesPerEntity_1048_imgSize_128 ...\n",
      "Found 29344 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m  5/917\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 30ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 27ms/step\n",
      "Accuracy of model model_imagesPerEntity_1048_imgSize_128 on dataset arabic-letters-1000-images-per-letter : 0.802\n",
      "trained_data_size : 1048, img_size : 256, model_name : model_imagesPerEntity_1048_imgSize_256 ...\n",
      "Found 29344 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m  5/917\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 34ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 32ms/step\n",
      "Accuracy of model model_imagesPerEntity_1048_imgSize_256 on dataset arabic-letters-1000-images-per-letter : 0.555\n",
      "trained_data_size : 1048, img_size : 300, model_name : model_imagesPerEntity_1048_imgSize_300 ...\n",
      "Found 29344 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m  3/917\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m45s\u001b[0m 50ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 36ms/step\n",
      "Accuracy of model model_imagesPerEntity_1048_imgSize_300 on dataset arabic-letters-1000-images-per-letter : 0.898\n",
      "trained_data_size : 2481, img_size : 16, model_name : model_imagesPerEntity_2481_imgSize_16 ...\n",
      "Found 29344 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m  7/917\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 25ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 25ms/step\n",
      "Accuracy of model model_imagesPerEntity_2481_imgSize_16 on dataset arabic-letters-1000-images-per-letter : 0.169\n",
      "trained_data_size : 2481, img_size : 32, model_name : model_imagesPerEntity_2481_imgSize_32 ...\n",
      "Found 29344 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m  5/917\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 33ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 24ms/step\n",
      "Accuracy of model model_imagesPerEntity_2481_imgSize_32 on dataset arabic-letters-1000-images-per-letter : 0.183\n",
      "trained_data_size : 2481, img_size : 64, model_name : model_imagesPerEntity_2481_imgSize_64 ...\n",
      "Found 29344 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m  7/917\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 25ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 25ms/step\n",
      "Accuracy of model model_imagesPerEntity_2481_imgSize_64 on dataset arabic-letters-1000-images-per-letter : 0.199\n",
      "trained_data_size : 2481, img_size : 128, model_name : model_imagesPerEntity_2481_imgSize_128 ...\n",
      "Found 29344 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m  5/917\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 30ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 28ms/step\n",
      "Accuracy of model model_imagesPerEntity_2481_imgSize_128 on dataset arabic-letters-1000-images-per-letter : 0.171\n",
      "trained_data_size : 2481, img_size : 256, model_name : model_imagesPerEntity_2481_imgSize_256 ...\n",
      "Found 29344 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m  5/917\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 35ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 32ms/step\n",
      "Accuracy of model model_imagesPerEntity_2481_imgSize_256 on dataset arabic-letters-1000-images-per-letter : 0.137\n",
      "trained_data_size : 2481, img_size : 300, model_name : model_imagesPerEntity_2481_imgSize_300 ...\n",
      "Found 29344 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m  4/917\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 47ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 37ms/step\n",
      "Accuracy of model model_imagesPerEntity_2481_imgSize_300 on dataset arabic-letters-1000-images-per-letter : 0.093\n",
      "Testing dataset : /kaggle/input/clean-2500-letters-only ...\n",
      "trained_data_size : 918, img_size : 16, model_name : model_imagesPerEntity_918_imgSize_16 ...\n",
      "Found 69468 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m   3/2171\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:49\u001b[0m 78ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2171/2171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 142ms/step\n",
      "Accuracy of model model_imagesPerEntity_918_imgSize_16 on dataset clean-2500-letters-only : 0.178\n",
      "trained_data_size : 918, img_size : 32, model_name : model_imagesPerEntity_918_imgSize_32 ...\n",
      "Found 69468 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m   7/2171\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:00\u001b[0m 28ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2171/2171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 27ms/step\n",
      "Accuracy of model model_imagesPerEntity_918_imgSize_32 on dataset clean-2500-letters-only : 0.274\n",
      "trained_data_size : 918, img_size : 64, model_name : model_imagesPerEntity_918_imgSize_64 ...\n",
      "Found 69468 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m   5/2171\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:14\u001b[0m 34ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2171/2171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 29ms/step\n",
      "Accuracy of model model_imagesPerEntity_918_imgSize_64 on dataset clean-2500-letters-only : 0.222\n",
      "trained_data_size : 918, img_size : 128, model_name : model_imagesPerEntity_918_imgSize_128 ...\n",
      "Found 69468 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m   7/2171\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m58s\u001b[0m 27ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2171/2171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 30ms/step\n",
      "Accuracy of model model_imagesPerEntity_918_imgSize_128 on dataset clean-2500-letters-only : 0.083\n",
      "trained_data_size : 918, img_size : 256, model_name : model_imagesPerEntity_918_imgSize_256 ...\n",
      "Found 69468 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m   5/2171\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:18\u001b[0m 36ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2171/2171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 35ms/step\n",
      "Accuracy of model model_imagesPerEntity_918_imgSize_256 on dataset clean-2500-letters-only : 0.068\n",
      "trained_data_size : 918, img_size : 300, model_name : model_imagesPerEntity_918_imgSize_300 ...\n",
      "Found 69468 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m   3/2171\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:25\u001b[0m 39ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2171/2171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 38ms/step\n",
      "Accuracy of model model_imagesPerEntity_918_imgSize_300 on dataset clean-2500-letters-only : 0.071\n",
      "trained_data_size : 1048, img_size : 16, model_name : model_imagesPerEntity_1048_imgSize_16 ...\n",
      "Found 69468 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m   7/2171\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m52s\u001b[0m 24ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2171/2171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 26ms/step\n",
      "Accuracy of model model_imagesPerEntity_1048_imgSize_16 on dataset clean-2500-letters-only : 0.279\n",
      "trained_data_size : 1048, img_size : 32, model_name : model_imagesPerEntity_1048_imgSize_32 ...\n",
      "Found 69468 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m   7/2171\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m59s\u001b[0m 27ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2171/2171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 26ms/step\n",
      "Accuracy of model model_imagesPerEntity_1048_imgSize_32 on dataset clean-2500-letters-only : 0.327\n",
      "trained_data_size : 1048, img_size : 64, model_name : model_imagesPerEntity_1048_imgSize_64 ...\n",
      "Found 69468 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m   7/2171\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:00\u001b[0m 28ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2171/2171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 27ms/step\n",
      "Accuracy of model model_imagesPerEntity_1048_imgSize_64 on dataset clean-2500-letters-only : 0.388\n",
      "trained_data_size : 1048, img_size : 128, model_name : model_imagesPerEntity_1048_imgSize_128 ...\n",
      "Found 69468 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m   5/2171\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23\u001b[0m 39ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2171/2171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 26ms/step\n",
      "Accuracy of model model_imagesPerEntity_1048_imgSize_128 on dataset clean-2500-letters-only : 0.234\n",
      "trained_data_size : 1048, img_size : 256, model_name : model_imagesPerEntity_1048_imgSize_256 ...\n",
      "Found 69468 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m   5/2171\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:16\u001b[0m 36ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2171/2171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 31ms/step\n",
      "Accuracy of model model_imagesPerEntity_1048_imgSize_256 on dataset clean-2500-letters-only : 0.064\n",
      "trained_data_size : 1048, img_size : 300, model_name : model_imagesPerEntity_1048_imgSize_300 ...\n",
      "Found 69468 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m   3/2171\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:29\u001b[0m 41ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2171/2171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 36ms/step\n",
      "Accuracy of model model_imagesPerEntity_1048_imgSize_300 on dataset clean-2500-letters-only : 0.122\n",
      "trained_data_size : 2481, img_size : 16, model_name : model_imagesPerEntity_2481_imgSize_16 ...\n",
      "Found 69468 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m   7/2171\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m59s\u001b[0m 28ms/step "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2171/2171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 26ms/step\n",
      "Accuracy of model model_imagesPerEntity_2481_imgSize_16 on dataset clean-2500-letters-only : 0.975\n",
      "trained_data_size : 2481, img_size : 32, model_name : model_imagesPerEntity_2481_imgSize_32 ...\n",
      "Found 69468 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m   5/2171\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 25ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2171/2171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 26ms/step\n",
      "Accuracy of model model_imagesPerEntity_2481_imgSize_32 on dataset clean-2500-letters-only : 0.981\n",
      "trained_data_size : 2481, img_size : 64, model_name : model_imagesPerEntity_2481_imgSize_64 ...\n",
      "Found 69468 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m   5/2171\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:05\u001b[0m 30ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2171/2171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 25ms/step\n",
      "Accuracy of model model_imagesPerEntity_2481_imgSize_64 on dataset clean-2500-letters-only : 0.999\n",
      "trained_data_size : 2481, img_size : 128, model_name : model_imagesPerEntity_2481_imgSize_128 ...\n",
      "Found 69468 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m   6/2171\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 25ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2171/2171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 26ms/step\n",
      "Accuracy of model model_imagesPerEntity_2481_imgSize_128 on dataset clean-2500-letters-only : 0.999\n",
      "trained_data_size : 2481, img_size : 256, model_name : model_imagesPerEntity_2481_imgSize_256 ...\n",
      "Found 69468 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m   5/2171\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22\u001b[0m 38ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2171/2171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 32ms/step\n",
      "Accuracy of model model_imagesPerEntity_2481_imgSize_256 on dataset clean-2500-letters-only : 0.998\n",
      "trained_data_size : 2481, img_size : 300, model_name : model_imagesPerEntity_2481_imgSize_300 ...\n",
      "Found 69468 images belonging to 28 classes.\n",
      "\n",
      "\u001b[1m   5/2171\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:19\u001b[0m 37ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2171/2171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 36ms/step\n",
      "Accuracy of model model_imagesPerEntity_2481_imgSize_300 on dataset clean-2500-letters-only : 0.979\n",
      "all datasets accuracies : {'arabic-letters-900-images-per-letter': {'model_imagesPerEntity_918_imgSize_16': 0.273, 'model_imagesPerEntity_918_imgSize_32': 0.681, 'model_imagesPerEntity_918_imgSize_64': 0.904, 'model_imagesPerEntity_918_imgSize_128': 0.719, 'model_imagesPerEntity_918_imgSize_256': 0.586, 'model_imagesPerEntity_918_imgSize_300': 0.09, 'model_imagesPerEntity_1048_imgSize_16': 0.216, 'model_imagesPerEntity_1048_imgSize_32': 0.477, 'model_imagesPerEntity_1048_imgSize_64': 0.641, 'model_imagesPerEntity_1048_imgSize_128': 0.474, 'model_imagesPerEntity_1048_imgSize_256': 0.223, 'model_imagesPerEntity_1048_imgSize_300': 0.471, 'model_imagesPerEntity_2481_imgSize_16': 0.076, 'model_imagesPerEntity_2481_imgSize_32': 0.104, 'model_imagesPerEntity_2481_imgSize_64': 0.079, 'model_imagesPerEntity_2481_imgSize_128': 0.104, 'model_imagesPerEntity_2481_imgSize_256': 0.091, 'model_imagesPerEntity_2481_imgSize_300': 0.077}, 'arabic-letters-1000-images-per-letter': {'model_imagesPerEntity_918_imgSize_16': 0.255, 'model_imagesPerEntity_918_imgSize_32': 0.428, 'model_imagesPerEntity_918_imgSize_64': 0.496, 'model_imagesPerEntity_918_imgSize_128': 0.259, 'model_imagesPerEntity_918_imgSize_256': 0.18, 'model_imagesPerEntity_918_imgSize_300': 0.088, 'model_imagesPerEntity_1048_imgSize_16': 0.698, 'model_imagesPerEntity_1048_imgSize_32': 0.782, 'model_imagesPerEntity_1048_imgSize_64': 0.933, 'model_imagesPerEntity_1048_imgSize_128': 0.802, 'model_imagesPerEntity_1048_imgSize_256': 0.555, 'model_imagesPerEntity_1048_imgSize_300': 0.898, 'model_imagesPerEntity_2481_imgSize_16': 0.169, 'model_imagesPerEntity_2481_imgSize_32': 0.183, 'model_imagesPerEntity_2481_imgSize_64': 0.199, 'model_imagesPerEntity_2481_imgSize_128': 0.171, 'model_imagesPerEntity_2481_imgSize_256': 0.137, 'model_imagesPerEntity_2481_imgSize_300': 0.093}, 'clean-2500-letters-only': {'model_imagesPerEntity_918_imgSize_16': 0.178, 'model_imagesPerEntity_918_imgSize_32': 0.274, 'model_imagesPerEntity_918_imgSize_64': 0.222, 'model_imagesPerEntity_918_imgSize_128': 0.083, 'model_imagesPerEntity_918_imgSize_256': 0.068, 'model_imagesPerEntity_918_imgSize_300': 0.071, 'model_imagesPerEntity_1048_imgSize_16': 0.279, 'model_imagesPerEntity_1048_imgSize_32': 0.327, 'model_imagesPerEntity_1048_imgSize_64': 0.388, 'model_imagesPerEntity_1048_imgSize_128': 0.234, 'model_imagesPerEntity_1048_imgSize_256': 0.064, 'model_imagesPerEntity_1048_imgSize_300': 0.122, 'model_imagesPerEntity_2481_imgSize_16': 0.975, 'model_imagesPerEntity_2481_imgSize_32': 0.981, 'model_imagesPerEntity_2481_imgSize_64': 0.999, 'model_imagesPerEntity_2481_imgSize_128': 0.999, 'model_imagesPerEntity_2481_imgSize_256': 0.998, 'model_imagesPerEntity_2481_imgSize_300': 0.979}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_68596 th {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_68596_row0_col0, #T_68596_row0_col1, #T_68596_row0_col2, #T_68596_row0_col3, #T_68596_row0_col4, #T_68596_row0_col5, #T_68596_row1_col6, #T_68596_row1_col7, #T_68596_row1_col8, #T_68596_row1_col9, #T_68596_row1_col10, #T_68596_row1_col11, #T_68596_row2_col12, #T_68596_row2_col13, #T_68596_row2_col14, #T_68596_row2_col15, #T_68596_row2_col16, #T_68596_row2_col17 {\n",
       "  background-color: #1f77b4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_68596_row0_col6, #T_68596_row0_col12, #T_68596_row0_col13, #T_68596_row0_col14, #T_68596_row0_col15, #T_68596_row0_col16, #T_68596_row0_col17, #T_68596_row1_col17, #T_68596_row2_col0, #T_68596_row2_col1, #T_68596_row2_col2, #T_68596_row2_col3, #T_68596_row2_col4, #T_68596_row2_col5, #T_68596_row2_col7, #T_68596_row2_col8, #T_68596_row2_col9, #T_68596_row2_col10, #T_68596_row2_col11 {\n",
       "  background-color: #9edae5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_68596_row0_col7, #T_68596_row0_col10 {\n",
       "  background-color: #f7b6d2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_68596_row0_col8 {\n",
       "  background-color: #8c564b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_68596_row0_col9, #T_68596_row0_col11, #T_68596_row1_col2 {\n",
       "  background-color: #c49c94;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_68596_row1_col0 {\n",
       "  background-color: #ffbb78;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_68596_row1_col1 {\n",
       "  background-color: #e377c2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_68596_row1_col3 {\n",
       "  background-color: #7f7f7f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_68596_row1_col4 {\n",
       "  background-color: #c7c7c7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_68596_row1_col5 {\n",
       "  background-color: #ff7f0e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_68596_row1_col12, #T_68596_row1_col14, #T_68596_row2_col6 {\n",
       "  background-color: #dbdb8d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_68596_row1_col13, #T_68596_row1_col15, #T_68596_row1_col16 {\n",
       "  background-color: #17becf;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_68596\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_68596_level0_col0\" class=\"col_heading level0 col0\" >model_imagesPerEntity_918_imgSize_16</th>\n",
       "      <th id=\"T_68596_level0_col1\" class=\"col_heading level0 col1\" >model_imagesPerEntity_918_imgSize_32</th>\n",
       "      <th id=\"T_68596_level0_col2\" class=\"col_heading level0 col2\" >model_imagesPerEntity_918_imgSize_64</th>\n",
       "      <th id=\"T_68596_level0_col3\" class=\"col_heading level0 col3\" >model_imagesPerEntity_918_imgSize_128</th>\n",
       "      <th id=\"T_68596_level0_col4\" class=\"col_heading level0 col4\" >model_imagesPerEntity_918_imgSize_256</th>\n",
       "      <th id=\"T_68596_level0_col5\" class=\"col_heading level0 col5\" >model_imagesPerEntity_918_imgSize_300</th>\n",
       "      <th id=\"T_68596_level0_col6\" class=\"col_heading level0 col6\" >model_imagesPerEntity_1048_imgSize_16</th>\n",
       "      <th id=\"T_68596_level0_col7\" class=\"col_heading level0 col7\" >model_imagesPerEntity_1048_imgSize_32</th>\n",
       "      <th id=\"T_68596_level0_col8\" class=\"col_heading level0 col8\" >model_imagesPerEntity_1048_imgSize_64</th>\n",
       "      <th id=\"T_68596_level0_col9\" class=\"col_heading level0 col9\" >model_imagesPerEntity_1048_imgSize_128</th>\n",
       "      <th id=\"T_68596_level0_col10\" class=\"col_heading level0 col10\" >model_imagesPerEntity_1048_imgSize_256</th>\n",
       "      <th id=\"T_68596_level0_col11\" class=\"col_heading level0 col11\" >model_imagesPerEntity_1048_imgSize_300</th>\n",
       "      <th id=\"T_68596_level0_col12\" class=\"col_heading level0 col12\" >model_imagesPerEntity_2481_imgSize_16</th>\n",
       "      <th id=\"T_68596_level0_col13\" class=\"col_heading level0 col13\" >model_imagesPerEntity_2481_imgSize_32</th>\n",
       "      <th id=\"T_68596_level0_col14\" class=\"col_heading level0 col14\" >model_imagesPerEntity_2481_imgSize_64</th>\n",
       "      <th id=\"T_68596_level0_col15\" class=\"col_heading level0 col15\" >model_imagesPerEntity_2481_imgSize_128</th>\n",
       "      <th id=\"T_68596_level0_col16\" class=\"col_heading level0 col16\" >model_imagesPerEntity_2481_imgSize_256</th>\n",
       "      <th id=\"T_68596_level0_col17\" class=\"col_heading level0 col17\" >model_imagesPerEntity_2481_imgSize_300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_68596_level0_row0\" class=\"row_heading level0 row0\" >arabic-letters-900-images-per-letter</th>\n",
       "      <td id=\"T_68596_row0_col0\" class=\"data row0 col0\" >0.273000</td>\n",
       "      <td id=\"T_68596_row0_col1\" class=\"data row0 col1\" >0.681000</td>\n",
       "      <td id=\"T_68596_row0_col2\" class=\"data row0 col2\" >0.904000</td>\n",
       "      <td id=\"T_68596_row0_col3\" class=\"data row0 col3\" >0.719000</td>\n",
       "      <td id=\"T_68596_row0_col4\" class=\"data row0 col4\" >0.586000</td>\n",
       "      <td id=\"T_68596_row0_col5\" class=\"data row0 col5\" >0.090000</td>\n",
       "      <td id=\"T_68596_row0_col6\" class=\"data row0 col6\" >0.216000</td>\n",
       "      <td id=\"T_68596_row0_col7\" class=\"data row0 col7\" >0.477000</td>\n",
       "      <td id=\"T_68596_row0_col8\" class=\"data row0 col8\" >0.641000</td>\n",
       "      <td id=\"T_68596_row0_col9\" class=\"data row0 col9\" >0.474000</td>\n",
       "      <td id=\"T_68596_row0_col10\" class=\"data row0 col10\" >0.223000</td>\n",
       "      <td id=\"T_68596_row0_col11\" class=\"data row0 col11\" >0.471000</td>\n",
       "      <td id=\"T_68596_row0_col12\" class=\"data row0 col12\" >0.076000</td>\n",
       "      <td id=\"T_68596_row0_col13\" class=\"data row0 col13\" >0.104000</td>\n",
       "      <td id=\"T_68596_row0_col14\" class=\"data row0 col14\" >0.079000</td>\n",
       "      <td id=\"T_68596_row0_col15\" class=\"data row0 col15\" >0.104000</td>\n",
       "      <td id=\"T_68596_row0_col16\" class=\"data row0 col16\" >0.091000</td>\n",
       "      <td id=\"T_68596_row0_col17\" class=\"data row0 col17\" >0.077000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68596_level0_row1\" class=\"row_heading level0 row1\" >arabic-letters-1000-images-per-letter</th>\n",
       "      <td id=\"T_68596_row1_col0\" class=\"data row1 col0\" >0.255000</td>\n",
       "      <td id=\"T_68596_row1_col1\" class=\"data row1 col1\" >0.428000</td>\n",
       "      <td id=\"T_68596_row1_col2\" class=\"data row1 col2\" >0.496000</td>\n",
       "      <td id=\"T_68596_row1_col3\" class=\"data row1 col3\" >0.259000</td>\n",
       "      <td id=\"T_68596_row1_col4\" class=\"data row1 col4\" >0.180000</td>\n",
       "      <td id=\"T_68596_row1_col5\" class=\"data row1 col5\" >0.088000</td>\n",
       "      <td id=\"T_68596_row1_col6\" class=\"data row1 col6\" >0.698000</td>\n",
       "      <td id=\"T_68596_row1_col7\" class=\"data row1 col7\" >0.782000</td>\n",
       "      <td id=\"T_68596_row1_col8\" class=\"data row1 col8\" >0.933000</td>\n",
       "      <td id=\"T_68596_row1_col9\" class=\"data row1 col9\" >0.802000</td>\n",
       "      <td id=\"T_68596_row1_col10\" class=\"data row1 col10\" >0.555000</td>\n",
       "      <td id=\"T_68596_row1_col11\" class=\"data row1 col11\" >0.898000</td>\n",
       "      <td id=\"T_68596_row1_col12\" class=\"data row1 col12\" >0.169000</td>\n",
       "      <td id=\"T_68596_row1_col13\" class=\"data row1 col13\" >0.183000</td>\n",
       "      <td id=\"T_68596_row1_col14\" class=\"data row1 col14\" >0.199000</td>\n",
       "      <td id=\"T_68596_row1_col15\" class=\"data row1 col15\" >0.171000</td>\n",
       "      <td id=\"T_68596_row1_col16\" class=\"data row1 col16\" >0.137000</td>\n",
       "      <td id=\"T_68596_row1_col17\" class=\"data row1 col17\" >0.093000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68596_level0_row2\" class=\"row_heading level0 row2\" >clean-2500-letters-only</th>\n",
       "      <td id=\"T_68596_row2_col0\" class=\"data row2 col0\" >0.178000</td>\n",
       "      <td id=\"T_68596_row2_col1\" class=\"data row2 col1\" >0.274000</td>\n",
       "      <td id=\"T_68596_row2_col2\" class=\"data row2 col2\" >0.222000</td>\n",
       "      <td id=\"T_68596_row2_col3\" class=\"data row2 col3\" >0.083000</td>\n",
       "      <td id=\"T_68596_row2_col4\" class=\"data row2 col4\" >0.068000</td>\n",
       "      <td id=\"T_68596_row2_col5\" class=\"data row2 col5\" >0.071000</td>\n",
       "      <td id=\"T_68596_row2_col6\" class=\"data row2 col6\" >0.279000</td>\n",
       "      <td id=\"T_68596_row2_col7\" class=\"data row2 col7\" >0.327000</td>\n",
       "      <td id=\"T_68596_row2_col8\" class=\"data row2 col8\" >0.388000</td>\n",
       "      <td id=\"T_68596_row2_col9\" class=\"data row2 col9\" >0.234000</td>\n",
       "      <td id=\"T_68596_row2_col10\" class=\"data row2 col10\" >0.064000</td>\n",
       "      <td id=\"T_68596_row2_col11\" class=\"data row2 col11\" >0.122000</td>\n",
       "      <td id=\"T_68596_row2_col12\" class=\"data row2 col12\" >0.975000</td>\n",
       "      <td id=\"T_68596_row2_col13\" class=\"data row2 col13\" >0.981000</td>\n",
       "      <td id=\"T_68596_row2_col14\" class=\"data row2 col14\" >0.999000</td>\n",
       "      <td id=\"T_68596_row2_col15\" class=\"data row2 col15\" >0.999000</td>\n",
       "      <td id=\"T_68596_row2_col16\" class=\"data row2 col16\" >0.998000</td>\n",
       "      <td id=\"T_68596_row2_col17\" class=\"data row2 col17\" >0.979000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7d820b1ef5e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %pip install --upgrade tensorflow keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# example of model file names : \n",
    "# model_imagesPerEntity_1647_imgSize_16_dataPercentage_100_batchSize_32_epochs_100.keras\n",
    "# model_imagesPerEntity_2481_imgSize_64_dataPercentage_100_batchSize_32_epochs_100.keras\n",
    "\n",
    "def copy_models_to_kaggle(model_paths):\n",
    "    os.makedirs('/kaggle/working/models', exist_ok=True)\n",
    "    new_paths = []\n",
    "    for model_path in model_paths:\n",
    "        model_file_name = model_path.split(\"/\")[-1]        \n",
    "        new_model_path = '/kaggle/working/models/' + model_file_name\n",
    "        new_paths.append(new_model_path)\n",
    "        if os.path.exists(new_model_path):\n",
    "            print(f\"model already exists at {new_model_path}\")\n",
    "        shutil.copy(model_path, new_model_path)\n",
    "    return new_paths\n",
    " \n",
    "\n",
    "batch_size = 32\n",
    "test_dataset_paths = [\n",
    "    r\"/kaggle/input/arabic-letters-900-images-per-letter\",\n",
    "    r\"/kaggle/input/arabic-letters-1000-images-per-letter\",\n",
    "    r\"/kaggle/input/clean-2500-letters-only\"\n",
    "]\n",
    "models_paths = [\n",
    "        r\"/kaggle/input/900-model/keras/no-augmentaton/1/model_imagesPerEntity_918_imgSize_16_dataPercentage_100_batchSize_32_epochs_100.keras\",\n",
    "        r\"/kaggle/input/900-model/keras/no-augmentaton/1/model_imagesPerEntity_918_imgSize_32_dataPercentage_100_batchSize_32_epochs_100.keras\",\n",
    "        r\"/kaggle/input/900-model/keras/no-augmentaton/1/model_imagesPerEntity_918_imgSize_64_dataPercentage_100_batchSize_32_epochs_100.keras\",\n",
    "        r\"/kaggle/input/900-model/keras/no-augmentaton/1/model_imagesPerEntity_918_imgSize_128_dataPercentage_100_batchSize_32_epochs_100.keras\",\n",
    "        r\"/kaggle/input/900-model/keras/no-augmentaton/1/model_imagesPerEntity_918_imgSize_256_dataPercentage_100_batchSize_32_epochs_100.keras\",\n",
    "        r\"/kaggle/input/900-model/keras/no-augmentaton/1/model_imagesPerEntity_918_imgSize_300_dataPercentage_100_batchSize_32_epochs_100.keras\",\n",
    "\n",
    "        r\"/kaggle/input/1000-model/keras/no-augmentation/1/model_imagesPerEntity_1048_imgSize_16_dataPercentage_100_batchSize_32_epochs_100.keras\",\n",
    "        r\"/kaggle/input/1000-model/keras/no-augmentation/1/model_imagesPerEntity_1048_imgSize_32_dataPercentage_100_batchSize_32_epochs_100.keras\",\n",
    "        r\"/kaggle/input/1000-model/keras/no-augmentation/1/model_imagesPerEntity_1048_imgSize_64_dataPercentage_100_batchSize_32_epochs_100.keras\",\n",
    "        r\"/kaggle/input/1000-model/keras/no-augmentation/1/model_imagesPerEntity_1048_imgSize_128_dataPercentage_100_batchSize_32_epochs_100.keras\",\n",
    "        r\"/kaggle/input/1000-model/keras/no-augmentation/1/model_imagesPerEntity_1048_imgSize_256_dataPercentage_100_batchSize_32_epochs_100.keras\",\n",
    "        r\"/kaggle/input/1000-model/keras/no-augmentation/1/model_imagesPerEntity_1048_imgSize_300_dataPercentage_100_batchSize_32_epochs_100.keras\",\n",
    "\n",
    "        r\"/kaggle/input/2500-model/keras/no-augmentation/1/model_imagesPerEntity_2481_imgSize_16_dataPercentage_100_batchSize_32_epochs_100.keras\",\n",
    "        r\"/kaggle/input/2500-model/keras/no-augmentation/1/model_imagesPerEntity_2481_imgSize_32_dataPercentage_100_batchSize_32_epochs_100.keras\",\n",
    "        r\"/kaggle/input/2500-model/keras/no-augmentation/1/model_imagesPerEntity_2481_imgSize_64_dataPercentage_100_batchSize_32_epochs_100.keras\",\n",
    "        r\"/kaggle/input/2500-model/keras/no-augmentation/1/model_imagesPerEntity_2481_imgSize_128_dataPercentage_100_batchSize_32_epochs_100.keras\",\n",
    "        r\"/kaggle/input/2500-model/keras/no-augmentation/1/model_imagesPerEntity_2481_imgSize_256_dataPercentage_100_batchSize_32_epochs_100.keras\",\n",
    "        r\"/kaggle/input/2500-model/keras/no-augmentation/1/model_imagesPerEntity_2481_imgSize_300_dataPercentage_100_batchSize_32_epochs_100.keras\"\n",
    "]\n",
    "\n",
    "print(\"copying models to kaggle...\")\n",
    "copied_models_paths = copy_models_to_kaggle(models_paths)\n",
    "print(f\"loading models in RAM...\")\n",
    "model_path_to_model = {}\n",
    "for model_path in copied_models_paths:\n",
    "    print(f\"loading model in : {model_path} ...\")\n",
    "    model = load_model(model_path)\n",
    "    model_path_to_model[model_path] = model\n",
    "\n",
    "all_datasets_accuracies = {}\n",
    "for dataset_path in test_dataset_paths:\n",
    "    dataset_name  = dataset_path.split(\"/\")[-1]\n",
    "    print(f\"Testing dataset : {dataset_path} ...\")\n",
    "    dataset_test_accuracies = {}\n",
    "    for model_path in copied_models_paths:\n",
    "        model_file_name_parts = model_path.split(\"/\")[-1].split(\".\")[0].split(\"_\")\n",
    "        trained_data_size = model_file_name_parts[2]\n",
    "        img_size = model_file_name_parts[4]\n",
    "        current_model_name =  f\"model_imagesPerEntity_{trained_data_size}_imgSize_{img_size}\"\n",
    "        model = model_path_to_model[model_path]\n",
    "        print(f\"trained_data_size : {trained_data_size}, img_size : {img_size}, model_name : {current_model_name} ...\")\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        test_generator = test_datagen.flow_from_directory(\n",
    "            dataset_path,\n",
    "            target_size=(int(img_size), int(img_size)),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical',\n",
    "            color_mode='grayscale',\n",
    "            shuffle=False)\n",
    "        print()\n",
    "\n",
    "        # Predict the output\n",
    "        steps = int(np.ceil(test_generator.samples / test_generator.batch_size))\n",
    "        predictions = model.predict(test_generator, steps=steps)\n",
    "        predictions = predictions.argmax(axis=-1)                    \n",
    "        true_classes = test_generator.classes\n",
    "        accuracy =  round(accuracy_score(true_classes, predictions), 3)\n",
    "        dataset_test_accuracies[current_model_name] = accuracy\n",
    "        print(f\"Accuracy of model {current_model_name} on dataset {dataset_name} : {accuracy}\")\n",
    "    all_datasets_accuracies[dataset_name] = dataset_test_accuracies\n",
    "\n",
    "print(f\"all datasets accuracies : {all_datasets_accuracies}\")\n",
    "accuracies_df = pd.DataFrame(all_datasets_accuracies).transpose()\n",
    "accuracies_df = accuracies_df.style.background_gradient(cmap='tab20_r').set_table_styles([dict(selector=\"th\", props=[(\"text-align\", \"center\")])])\n",
    "display(accuracies_df)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4819728,
     "sourceId": 8299014,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4939702,
     "sourceId": 8315807,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4939635,
     "sourceId": 8315725,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 36885,
     "sourceId": 43921,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 36884,
     "sourceId": 43919,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 36888,
     "sourceId": 43924,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2847.418435,
   "end_time": "2024-05-05T19:16:45.602566",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-05T18:29:18.184131",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
