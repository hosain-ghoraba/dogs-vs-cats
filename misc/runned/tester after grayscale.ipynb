{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8299014,"sourceType":"datasetVersion","datasetId":4819728},{"sourceId":8299107,"sourceType":"datasetVersion","datasetId":4819790},{"sourceId":43022,"sourceType":"modelInstanceVersion","modelInstanceId":36139},{"sourceId":43024,"sourceType":"modelInstanceVersion","modelInstanceId":36141},{"sourceId":43027,"sourceType":"modelInstanceVersion","modelInstanceId":36144},{"sourceId":43068,"sourceType":"modelInstanceVersion","modelInstanceId":36175},{"sourceId":43071,"sourceType":"modelInstanceVersion","modelInstanceId":36178},{"sourceId":43326,"sourceType":"modelInstanceVersion","modelInstanceId":36376},{"sourceId":43327,"sourceType":"modelInstanceVersion","modelInstanceId":36377},{"sourceId":43328,"sourceType":"modelInstanceVersion","modelInstanceId":36378},{"sourceId":43331,"sourceType":"modelInstanceVersion","modelInstanceId":36381},{"sourceId":43340,"sourceType":"modelInstanceVersion","modelInstanceId":36390},{"sourceId":43342,"sourceType":"modelInstanceVersion","modelInstanceId":36392},{"sourceId":43398,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":36151}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":3097.361741,"end_time":"2024-04-22T16:08:33.965837","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-04-22T15:16:56.604096","version":"2.5.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import load_model\nfrom sklearn.metrics import accuracy_score\nimport pandas as pd\nimport shutil\nimport os\nimport numpy as np\n\n# example of model file names : \n# model_imagesPerEntity_1647_imgSize_16_dataPercentage_100_batchSize_32_epochs_100.keras\n# model_imagesPerEntity_2481_imgSize_64_dataPercentage_100_batchSize_32_epochs_100.keras\n\ndef copy_models_to_kaggle(model_paths):\n    os.makedirs('/kaggle/working/models', exist_ok=True)\n    new_paths = []\n    for model_path in model_paths:\n        model_file_name = model_path.split(\"/\")[-1]        \n        new_model_path = '/kaggle/working/models/' + model_file_name\n        new_paths.append(new_model_path)\n        if os.path.exists(new_model_path):\n            print(f\"model already exists at {new_model_path}\")\n        shutil.copy(model_path, new_model_path)\n    return new_paths\n \n\nbatch_size = 32\ntest_dataset_paths = [\n    '/kaggle/input/clean-2500-letters-only',\n    '/kaggle/input/clean-1800-letters-only'\n]\nmodels_paths = [\n    r'/kaggle/input/1800-model/keras/16/1/model_imagesPerEntity_1647_imgSize_16_dataPercentage_100_batchSize_32_epochs_100.keras',\n    r'/kaggle/input/1800-model/keras/32/1/model_imagesPerEntity_1647_imgSize_32_dataPercentage_100_batchSize_32_epochs_100.keras',\n    r'/kaggle/input/1800-model/keras/64/1/model_imagesPerEntity_1647_imgSize_64_dataPercentage_100_batchSize_32_epochs_100.keras',\n    r'/kaggle/input/1800-model/keras/128/2/model_imagesPerEntity_1647_imgSize_128_dataPercentage_100_batchSize_32_epochs_100.keras',\n    r'/kaggle/input/1800-model/keras/256/1/model_imagesPerEntity_1647_imgSize_256_dataPercentage_100_batchSize_32_epochs_100.keras',\n    r'/kaggle/input/1800-model/keras/300/1/model_imagesPerEntity_1647_imgSize_300_dataPercentage_100_batchSize_32_epochs_100.keras',\n\n    r'/kaggle/input/2500-model/keras/model-grayscale-16/1/model_imagesPerEntity_2481_imgSize_16_dataPercentage_100_batchSize_32_epochs_100.keras',\n    r'/kaggle/input/2500-model/keras/model-grayscale-32/1/model_imagesPerEntity_2481_imgSize_32_dataPercentage_100_batchSize_32_epochs_100.keras',\n    r'/kaggle/input/2500-model/keras/model-grayscale-64/1/model_imagesPerEntity_2481_imgSize_64_dataPercentage_100_batchSize_32_epochs_100.keras',\n    r'/kaggle/input/2500-model/keras/model-grayscale-128/1/model_imagesPerEntity_2481_imgSize_128_dataPercentage_100_batchSize_32_epochs_100.keras',\n    r'/kaggle/input/2500-model/keras/model-grayscale-256/1/model_imagesPerEntity_2481_imgSize_256_dataPercentage_100_batchSize_32_epochs_100.keras',\n    r'/kaggle/input/2500-model/keras/model-grayscale-300/1/model_imagesPerEntity_2481_imgSize_300_dataPercentage_100_batchSize_32_epochs_100.keras'\n\n]\n\nprint(\"copying models to kaggle...\")\ncopied_models_paths = copy_models_to_kaggle(models_paths)\nprint(f\"loading models in RAM...\")\nmodel_path_to_model = {}\nfor model_path in copied_models_paths:\n    print(f\"loading model in : {model_path} ...\")\n    model = load_model(model_path)\n    model_path_to_model[model_path] = model\n\nall_datasets_accuracies = {}\nfor dataset_path in test_dataset_paths:\n    dataset_name  = dataset_path.split(\"/\")[-1]\n    print(f\"Testing dataset : {dataset_path} ...\")\n    dataset_test_accuracies = {}\n    for model_path in copied_models_paths:\n        model_file_name_parts = model_path.split(\"/\")[-1].split(\".\")[0].split(\"_\")\n        trained_data_size = model_file_name_parts[2]\n        img_size = model_file_name_parts[4]\n        current_model_name =  f\"{trained_data_size}_dataset_{img_size}_img_size\"\n        model = model_path_to_model[model_path]\n        print(f\"trained_data_size : {trained_data_size}, img_size : {img_size}, model_name : {current_model_name} ...\")\n        test_datagen = ImageDataGenerator(rescale=1./255)\n        test_generator = test_datagen.flow_from_directory(\n            dataset_path,\n            target_size=(int(img_size), int(img_size)),\n            batch_size=batch_size,\n            class_mode='categorical',\n            color_mode='grayscale',\n            shuffle=False)\n        print()\n\n        # Predict the output\n        steps = int(np.ceil(test_generator.samples / test_generator.batch_size))\n        predictions = model.predict(test_generator, steps=steps)\n        predictions = predictions.argmax(axis=-1)                    \n        true_classes = test_generator.classes\n        accuracy =  round(accuracy_score(true_classes, predictions), 3)\n        dataset_test_accuracies[current_model_name] = accuracy\n        print(f\"Accuracy of model {current_model_name} on dataset {dataset_name} : {accuracy}\")\n    all_datasets_accuracies[dataset_name] = dataset_test_accuracies\n\nprint(f\"all datasets accuracies : {all_datasets_accuracies}\")\naccuracies_df = pd.DataFrame(all_datasets_accuracies).transpose()\naccuracies_df = accuracies_df.style.background_gradient(cmap='tab20_r').set_table_styles([dict(selector=\"th\", props=[(\"text-align\", \"center\")])])\ndisplay(accuracies_df)\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":3089.267327,"end_time":"2024-04-22T16:08:28.665794","exception":false,"start_time":"2024-04-22T15:16:59.398467","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-04T08:57:01.604210Z","iopub.execute_input":"2024-05-04T08:57:01.604962Z","iopub.status.idle":"2024-05-04T09:32:52.306494Z","shell.execute_reply.started":"2024-05-04T08:57:01.604929Z","shell.execute_reply":"2024-05-04T09:32:52.305398Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"copying models to kaggle...\nmodel already exists at /kaggle/working/models/model_imagesPerEntity_1647_imgSize_16_dataPercentage_100_batchSize_32_epochs_100.keras\nmodel already exists at /kaggle/working/models/model_imagesPerEntity_1647_imgSize_32_dataPercentage_100_batchSize_32_epochs_100.keras\nmodel already exists at /kaggle/working/models/model_imagesPerEntity_1647_imgSize_64_dataPercentage_100_batchSize_32_epochs_100.keras\nmodel already exists at /kaggle/working/models/model_imagesPerEntity_1647_imgSize_128_dataPercentage_100_batchSize_32_epochs_100.keras\nmodel already exists at /kaggle/working/models/model_imagesPerEntity_1647_imgSize_256_dataPercentage_100_batchSize_32_epochs_100.keras\nmodel already exists at /kaggle/working/models/model_imagesPerEntity_1647_imgSize_300_dataPercentage_100_batchSize_32_epochs_100.keras\nmodel already exists at /kaggle/working/models/model_imagesPerEntity_2481_imgSize_16_dataPercentage_100_batchSize_32_epochs_100.keras\nmodel already exists at /kaggle/working/models/model_imagesPerEntity_2481_imgSize_32_dataPercentage_100_batchSize_32_epochs_100.keras\nmodel already exists at /kaggle/working/models/model_imagesPerEntity_2481_imgSize_64_dataPercentage_100_batchSize_32_epochs_100.keras\nmodel already exists at /kaggle/working/models/model_imagesPerEntity_2481_imgSize_128_dataPercentage_100_batchSize_32_epochs_100.keras\nmodel already exists at /kaggle/working/models/model_imagesPerEntity_2481_imgSize_256_dataPercentage_100_batchSize_32_epochs_100.keras\nmodel already exists at /kaggle/working/models/model_imagesPerEntity_2481_imgSize_300_dataPercentage_100_batchSize_32_epochs_100.keras\nloading models in RAM...\nloading model in : /kaggle/working/models/model_imagesPerEntity_1647_imgSize_16_dataPercentage_100_batchSize_32_epochs_100.keras ...\nloading model in : /kaggle/working/models/model_imagesPerEntity_1647_imgSize_32_dataPercentage_100_batchSize_32_epochs_100.keras ...\nloading model in : /kaggle/working/models/model_imagesPerEntity_1647_imgSize_64_dataPercentage_100_batchSize_32_epochs_100.keras ...\nloading model in : /kaggle/working/models/model_imagesPerEntity_1647_imgSize_128_dataPercentage_100_batchSize_32_epochs_100.keras ...\nloading model in : /kaggle/working/models/model_imagesPerEntity_1647_imgSize_256_dataPercentage_100_batchSize_32_epochs_100.keras ...\nloading model in : /kaggle/working/models/model_imagesPerEntity_1647_imgSize_300_dataPercentage_100_batchSize_32_epochs_100.keras ...\nloading model in : /kaggle/working/models/model_imagesPerEntity_2481_imgSize_16_dataPercentage_100_batchSize_32_epochs_100.keras ...\nloading model in : /kaggle/working/models/model_imagesPerEntity_2481_imgSize_32_dataPercentage_100_batchSize_32_epochs_100.keras ...\nloading model in : /kaggle/working/models/model_imagesPerEntity_2481_imgSize_64_dataPercentage_100_batchSize_32_epochs_100.keras ...\nloading model in : /kaggle/working/models/model_imagesPerEntity_2481_imgSize_128_dataPercentage_100_batchSize_32_epochs_100.keras ...\nloading model in : /kaggle/working/models/model_imagesPerEntity_2481_imgSize_256_dataPercentage_100_batchSize_32_epochs_100.keras ...\nloading model in : /kaggle/working/models/model_imagesPerEntity_2481_imgSize_300_dataPercentage_100_batchSize_32_epochs_100.keras ...\nTesting dataset : /kaggle/input/clean-2500-letters-only ...\ntrained_data_size : 1647, img_size : 16, model_name : 1647_dataset_16_img_size ...\nFound 69468 images belonging to 28 classes.\n\n\u001b[1m2171/2171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 85ms/step\nAccuracy of model 1647_dataset_16_img_size on dataset clean-2500-letters-only : 0.07\ntrained_data_size : 1647, img_size : 32, model_name : 1647_dataset_32_img_size ...\nFound 69468 images belonging to 28 classes.\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2171/2171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 31ms/step\nAccuracy of model 1647_dataset_32_img_size on dataset clean-2500-letters-only : 0.194\ntrained_data_size : 1647, img_size : 64, model_name : 1647_dataset_64_img_size ...\nFound 69468 images belonging to 28 classes.\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2171/2171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 28ms/step\nAccuracy of model 1647_dataset_64_img_size on dataset clean-2500-letters-only : 0.092\ntrained_data_size : 1647, img_size : 128, model_name : 1647_dataset_128_img_size ...\nFound 69468 images belonging to 28 classes.\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2171/2171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 36ms/step\nAccuracy of model 1647_dataset_128_img_size on dataset clean-2500-letters-only : 0.178\ntrained_data_size : 1647, img_size : 256, model_name : 1647_dataset_256_img_size ...\nFound 69468 images belonging to 28 classes.\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2171/2171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 42ms/step\nAccuracy of model 1647_dataset_256_img_size on dataset clean-2500-letters-only : 0.111\ntrained_data_size : 1647, img_size : 300, model_name : 1647_dataset_300_img_size ...\nFound 69468 images belonging to 28 classes.\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2171/2171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 49ms/step\nAccuracy of model 1647_dataset_300_img_size on dataset clean-2500-letters-only : 0.134\ntrained_data_size : 2481, img_size : 16, model_name : 2481_dataset_16_img_size ...\nFound 69468 images belonging to 28 classes.\n\n\u001b[1m   1/2171\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:54\u001b[0m 219ms/step","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2171/2171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 36ms/step\nAccuracy of model 2481_dataset_16_img_size on dataset clean-2500-letters-only : 0.954\ntrained_data_size : 2481, img_size : 32, model_name : 2481_dataset_32_img_size ...\nFound 69468 images belonging to 28 classes.\n\n\u001b[1m   1/2171\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:35\u001b[0m 210ms/step","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2171/2171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 28ms/step\nAccuracy of model 2481_dataset_32_img_size on dataset clean-2500-letters-only : 0.995\ntrained_data_size : 2481, img_size : 64, model_name : 2481_dataset_64_img_size ...\nFound 69468 images belonging to 28 classes.\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2171/2171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 28ms/step\nAccuracy of model 2481_dataset_64_img_size on dataset clean-2500-letters-only : 0.992\ntrained_data_size : 2481, img_size : 128, model_name : 2481_dataset_128_img_size ...\nFound 69468 images belonging to 28 classes.\n\n\u001b[1m   1/2171\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:34\u001b[0m 209ms/step","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2171/2171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 31ms/step\nAccuracy of model 2481_dataset_128_img_size on dataset clean-2500-letters-only : 0.991\ntrained_data_size : 2481, img_size : 256, model_name : 2481_dataset_256_img_size ...\nFound 69468 images belonging to 28 classes.\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2171/2171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 35ms/step\nAccuracy of model 2481_dataset_256_img_size on dataset clean-2500-letters-only : 0.936\ntrained_data_size : 2481, img_size : 300, model_name : 2481_dataset_300_img_size ...\nFound 69468 images belonging to 28 classes.\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2171/2171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 39ms/step\nAccuracy of model 2481_dataset_300_img_size on dataset clean-2500-letters-only : 0.973\nTesting dataset : /kaggle/input/clean-1800-letters-only ...\ntrained_data_size : 1647, img_size : 16, model_name : 1647_dataset_16_img_size ...\nFound 46130 images belonging to 28 classes.\n\n\u001b[1m   1/1442\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:20\u001b[0m 56ms/step","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1442/1442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 211ms/step\nAccuracy of model 1647_dataset_16_img_size on dataset clean-1800-letters-only : 0.141\ntrained_data_size : 1647, img_size : 32, model_name : 1647_dataset_32_img_size ...\nFound 46130 images belonging to 28 classes.\n\n\u001b[1m   5/1442\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 31ms/step","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1442/1442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 33ms/step\nAccuracy of model 1647_dataset_32_img_size on dataset clean-1800-letters-only : 0.549\ntrained_data_size : 1647, img_size : 64, model_name : 1647_dataset_64_img_size ...\nFound 46130 images belonging to 28 classes.\n\n\u001b[1m   5/1442\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 31ms/step","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1442/1442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 34ms/step\nAccuracy of model 1647_dataset_64_img_size on dataset clean-1800-letters-only : 0.898\ntrained_data_size : 1647, img_size : 128, model_name : 1647_dataset_128_img_size ...\nFound 46130 images belonging to 28 classes.\n\n\u001b[1m   5/1442\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m47s\u001b[0m 33ms/step","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1442/1442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 37ms/step\nAccuracy of model 1647_dataset_128_img_size on dataset clean-1800-letters-only : 0.631\ntrained_data_size : 1647, img_size : 256, model_name : 1647_dataset_256_img_size ...\nFound 46130 images belonging to 28 classes.\n\n\u001b[1m   3/1442\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09\u001b[0m 48ms/step","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1442/1442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 40ms/step\nAccuracy of model 1647_dataset_256_img_size on dataset clean-1800-letters-only : 0.533\ntrained_data_size : 1647, img_size : 300, model_name : 1647_dataset_300_img_size ...\nFound 46130 images belonging to 28 classes.\n\n\u001b[1m   3/1442\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10\u001b[0m 49ms/step","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1442/1442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 39ms/step\nAccuracy of model 1647_dataset_300_img_size on dataset clean-1800-letters-only : 0.67\ntrained_data_size : 2481, img_size : 16, model_name : 2481_dataset_16_img_size ...\nFound 46130 images belonging to 28 classes.\n\n\u001b[1m   5/1442\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 30ms/step","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1442/1442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 32ms/step\nAccuracy of model 2481_dataset_16_img_size on dataset clean-1800-letters-only : 0.087\ntrained_data_size : 2481, img_size : 32, model_name : 2481_dataset_32_img_size ...\nFound 46130 images belonging to 28 classes.\n\n\u001b[1m   5/1442\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 31ms/step","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1442/1442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step\nAccuracy of model 2481_dataset_32_img_size on dataset clean-1800-letters-only : 0.147\ntrained_data_size : 2481, img_size : 64, model_name : 2481_dataset_64_img_size ...\nFound 46130 images belonging to 28 classes.\n\n\u001b[1m   5/1442\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m47s\u001b[0m 33ms/step","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1442/1442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 35ms/step\nAccuracy of model 2481_dataset_64_img_size on dataset clean-1800-letters-only : 0.129\ntrained_data_size : 2481, img_size : 128, model_name : 2481_dataset_128_img_size ...\nFound 46130 images belonging to 28 classes.\n\n\u001b[1m   5/1442\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m55s\u001b[0m 39ms/step ","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1442/1442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 36ms/step\nAccuracy of model 2481_dataset_128_img_size on dataset clean-1800-letters-only : 0.152\ntrained_data_size : 2481, img_size : 256, model_name : 2481_dataset_256_img_size ...\nFound 46130 images belonging to 28 classes.\n\n\u001b[1m   4/1442\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:00\u001b[0m 42ms/step","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1442/1442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 40ms/step\nAccuracy of model 2481_dataset_256_img_size on dataset clean-1800-letters-only : 0.098\ntrained_data_size : 2481, img_size : 300, model_name : 2481_dataset_300_img_size ...\nFound 46130 images belonging to 28 classes.\n\n\u001b[1m   4/1442\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:03\u001b[0m 44ms/step","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1442/1442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 44ms/step\nAccuracy of model 2481_dataset_300_img_size on dataset clean-1800-letters-only : 0.149\nall datasets accuracies : {'clean-2500-letters-only': {'1647_dataset_16_img_size': 0.07, '1647_dataset_32_img_size': 0.194, '1647_dataset_64_img_size': 0.092, '1647_dataset_128_img_size': 0.178, '1647_dataset_256_img_size': 0.111, '1647_dataset_300_img_size': 0.134, '2481_dataset_16_img_size': 0.954, '2481_dataset_32_img_size': 0.995, '2481_dataset_64_img_size': 0.992, '2481_dataset_128_img_size': 0.991, '2481_dataset_256_img_size': 0.936, '2481_dataset_300_img_size': 0.973}, 'clean-1800-letters-only': {'1647_dataset_16_img_size': 0.141, '1647_dataset_32_img_size': 0.549, '1647_dataset_64_img_size': 0.898, '1647_dataset_128_img_size': 0.631, '1647_dataset_256_img_size': 0.533, '1647_dataset_300_img_size': 0.67, '2481_dataset_16_img_size': 0.087, '2481_dataset_32_img_size': 0.147, '2481_dataset_64_img_size': 0.129, '2481_dataset_128_img_size': 0.152, '2481_dataset_256_img_size': 0.098, '2481_dataset_300_img_size': 0.149}}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<pandas.io.formats.style.Styler at 0x7e8fee951de0>","text/html":"<style type=\"text/css\">\n#T_c78fe th {\n  text-align: center;\n}\n#T_c78fe_row0_col0, #T_c78fe_row0_col1, #T_c78fe_row0_col2, #T_c78fe_row0_col3, #T_c78fe_row0_col4, #T_c78fe_row0_col5, #T_c78fe_row1_col6, #T_c78fe_row1_col7, #T_c78fe_row1_col8, #T_c78fe_row1_col9, #T_c78fe_row1_col10, #T_c78fe_row1_col11 {\n  background-color: #9edae5;\n  color: #000000;\n}\n#T_c78fe_row0_col6, #T_c78fe_row0_col7, #T_c78fe_row0_col8, #T_c78fe_row0_col9, #T_c78fe_row0_col10, #T_c78fe_row0_col11, #T_c78fe_row1_col0, #T_c78fe_row1_col1, #T_c78fe_row1_col2, #T_c78fe_row1_col3, #T_c78fe_row1_col4, #T_c78fe_row1_col5 {\n  background-color: #1f77b4;\n  color: #f1f1f1;\n}\n</style>\n<table id=\"T_c78fe\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_c78fe_level0_col0\" class=\"col_heading level0 col0\" >1647_dataset_16_img_size</th>\n      <th id=\"T_c78fe_level0_col1\" class=\"col_heading level0 col1\" >1647_dataset_32_img_size</th>\n      <th id=\"T_c78fe_level0_col2\" class=\"col_heading level0 col2\" >1647_dataset_64_img_size</th>\n      <th id=\"T_c78fe_level0_col3\" class=\"col_heading level0 col3\" >1647_dataset_128_img_size</th>\n      <th id=\"T_c78fe_level0_col4\" class=\"col_heading level0 col4\" >1647_dataset_256_img_size</th>\n      <th id=\"T_c78fe_level0_col5\" class=\"col_heading level0 col5\" >1647_dataset_300_img_size</th>\n      <th id=\"T_c78fe_level0_col6\" class=\"col_heading level0 col6\" >2481_dataset_16_img_size</th>\n      <th id=\"T_c78fe_level0_col7\" class=\"col_heading level0 col7\" >2481_dataset_32_img_size</th>\n      <th id=\"T_c78fe_level0_col8\" class=\"col_heading level0 col8\" >2481_dataset_64_img_size</th>\n      <th id=\"T_c78fe_level0_col9\" class=\"col_heading level0 col9\" >2481_dataset_128_img_size</th>\n      <th id=\"T_c78fe_level0_col10\" class=\"col_heading level0 col10\" >2481_dataset_256_img_size</th>\n      <th id=\"T_c78fe_level0_col11\" class=\"col_heading level0 col11\" >2481_dataset_300_img_size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_c78fe_level0_row0\" class=\"row_heading level0 row0\" >clean-2500-letters-only</th>\n      <td id=\"T_c78fe_row0_col0\" class=\"data row0 col0\" >0.070000</td>\n      <td id=\"T_c78fe_row0_col1\" class=\"data row0 col1\" >0.194000</td>\n      <td id=\"T_c78fe_row0_col2\" class=\"data row0 col2\" >0.092000</td>\n      <td id=\"T_c78fe_row0_col3\" class=\"data row0 col3\" >0.178000</td>\n      <td id=\"T_c78fe_row0_col4\" class=\"data row0 col4\" >0.111000</td>\n      <td id=\"T_c78fe_row0_col5\" class=\"data row0 col5\" >0.134000</td>\n      <td id=\"T_c78fe_row0_col6\" class=\"data row0 col6\" >0.954000</td>\n      <td id=\"T_c78fe_row0_col7\" class=\"data row0 col7\" >0.995000</td>\n      <td id=\"T_c78fe_row0_col8\" class=\"data row0 col8\" >0.992000</td>\n      <td id=\"T_c78fe_row0_col9\" class=\"data row0 col9\" >0.991000</td>\n      <td id=\"T_c78fe_row0_col10\" class=\"data row0 col10\" >0.936000</td>\n      <td id=\"T_c78fe_row0_col11\" class=\"data row0 col11\" >0.973000</td>\n    </tr>\n    <tr>\n      <th id=\"T_c78fe_level0_row1\" class=\"row_heading level0 row1\" >clean-1800-letters-only</th>\n      <td id=\"T_c78fe_row1_col0\" class=\"data row1 col0\" >0.141000</td>\n      <td id=\"T_c78fe_row1_col1\" class=\"data row1 col1\" >0.549000</td>\n      <td id=\"T_c78fe_row1_col2\" class=\"data row1 col2\" >0.898000</td>\n      <td id=\"T_c78fe_row1_col3\" class=\"data row1 col3\" >0.631000</td>\n      <td id=\"T_c78fe_row1_col4\" class=\"data row1 col4\" >0.533000</td>\n      <td id=\"T_c78fe_row1_col5\" class=\"data row1 col5\" >0.670000</td>\n      <td id=\"T_c78fe_row1_col6\" class=\"data row1 col6\" >0.087000</td>\n      <td id=\"T_c78fe_row1_col7\" class=\"data row1 col7\" >0.147000</td>\n      <td id=\"T_c78fe_row1_col8\" class=\"data row1 col8\" >0.129000</td>\n      <td id=\"T_c78fe_row1_col9\" class=\"data row1 col9\" >0.152000</td>\n      <td id=\"T_c78fe_row1_col10\" class=\"data row1 col10\" >0.098000</td>\n      <td id=\"T_c78fe_row1_col11\" class=\"data row1 col11\" >0.149000</td>\n    </tr>\n  </tbody>\n</table>\n"},"metadata":{}}]}]}