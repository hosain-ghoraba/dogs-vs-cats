{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Choose an image to test the model </h1>"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
=======
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select an image to classify...\n",
      "loading model that was trained on a dataset of size :  128\n",
      "model loaded successfully.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAGhCAYAAADbf0s2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgNUlEQVR4nO3df2xV9f3H8ddtS28r0Ftb1nuptFAdGyjIkB+1om6RZuCI4mQ6SJ2VEYiuKD+SCZ2C2fxiETNlaIVpHGoGoiT8UCIaVhBGLC0UUBEtOBtowFtU1ntboD/o/Xz/WDzxaoUqt72fW56P5JOs55yevj8L6zO3Pbt1GWOMAACwUFy0BwAA4LsQKQCAtYgUAMBaRAoAYC0iBQCwFpECAFiLSAEArEWkAADWIlIAAGsRKQCAtaIWqdLSUg0YMEBJSUnKzc1VZWVltEYBAFgqKpF69dVXNXfuXD3yyCPau3evhg0bpnHjxunEiRPRGAcAYClXNN5gNjc3V6NGjdIzzzwjSQqFQsrKytL999+v+fPnn/fzQ6GQjh8/rt69e8vlcnX2uACACDPGqKGhQZmZmYqL++7XSwldOJMkqaWlRVVVVSouLnaOxcXFKT8/X+Xl5e1+TnNzs5qbm52Pjx07piuvvLLTZwUAdK7a2lr169fvO893+Y/7vvjiC7W1tcnr9YYd93q98vv97X5OSUmJPB6PswgUAHQPvXv3Puf5mHi6r7i4WIFAwFm1tbXRHgkAEAHn+5VNl/+4r0+fPoqPj1ddXV3Y8bq6Ovl8vnY/x+12y+12d8V4AACLdPkrqcTERI0YMUJlZWXOsVAopLKyMuXl5XX1OAAAi3X5KylJmjt3rgoLCzVy5EiNHj1aS5cu1alTpzR16tRojAMAsFRUIvXb3/5Wn3/+uRYuXCi/36+f/exneuutt771MAUA4OIWlf+f1IUKBoPyeDzRHgMAcIECgYBSUlK+83xMPN0HALg4ESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1kqI9gAAvs3lcik+Pl4ulyvaowCdwhijs2fPnvc6IgVYyOv1avTo0fL5fNEeBegULS0tevHFF897HZECLNS/f38VFhZq9OjR0R4F6BQNDQ1ECohViYmJ+tGPfqR+/fpFexSgUwSDwQ5dx4MTAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWhGPVElJiUaNGqXevXsrIyNDt912m6qrq8OuaWpqUlFRkdLT09WrVy9NmjRJdXV1kR4FABDjIh6p7du3q6ioSLt27dKWLVvU2tqqX/7ylzp16pRzzZw5c/TGG29o7dq12r59u44fP67bb7890qMAAGJcQqRv+NZbb4V9/OKLLyojI0NVVVW68cYbFQgE9MILL2j16tW66aabJEkrV67U4MGDtWvXLl177bWRHgkAEKM6/XdSgUBAkpSWliZJqqqqUmtrq/Lz851rBg0apOzsbJWXl7d7j+bmZgWDwbAFAOj+OjVSoVBIs2fP1pgxYzRkyBBJkt/vV2JiolJTU8Ou9Xq98vv97d6npKREHo/HWVlZWZ05NgDAEp0aqaKiIh04cEBr1qy5oPsUFxcrEAg4q7a2NkITAgBsFvHfSX1l5syZ2rRpk3bs2KF+/fo5x30+n1paWlRfXx/2aqqurk4+n6/de7ndbrnd7s4aFQBgqYi/kjLGaObMmVq/fr22bt2qnJycsPMjRoxQjx49VFZW5hyrrq7W0aNHlZeXF+lxAAAxLOKvpIqKirR69Wpt3LhRvXv3dn7P5PF4lJycLI/Ho2nTpmnu3LlKS0tTSkqK7r//fuXl5fFkHwAgTMQjtXz5cknSL37xi7DjK1eu1D333CNJeuqppxQXF6dJkyapublZ48aN07PPPhvpUQAAMS7ikTLGnPeapKQklZaWqrS0NNJfHgDQjfDefQAAaxEpAIC1iBQAwFpECgBgLSIFALAWkQIAWItIAQCsRaQAANYiUgAAaxEpAIC1iBQAwFpECgBgLSIFALAWkQIAWItIAQCsRaQAANYiUgAAaxEpAIC1iBQAwFpECgBgLSIFALAWkQIAWItIAQCsRaQAANYiUgAAaxEpAIC1iBQAwFpECgBgLSIFALAWkQIAWItIAQCsRaQAANYiUgAAaxEpAIC1iBQAwFpECgBgLSIFALAWkQIAWItIAQCsRaQAANYiUgAAaxEpAIC1iBQAwFpECgBgLSIFALAWkQIAWKvTI7V48WK5XC7Nnj3bOdbU1KSioiKlp6erV69emjRpkurq6jp7FABAjOnUSO3evVt///vfdfXVV4cdnzNnjt544w2tXbtW27dv1/Hjx3X77bd35igAgBjUaZFqbGxUQUGBnn/+eV166aXO8UAgoBdeeEFPPvmkbrrpJo0YMUIrV67Uu+++q127dnXWOACAGNRpkSoqKtKECROUn58fdryqqkqtra1hxwcNGqTs7GyVl5d31jgAgBiU0Bk3XbNmjfbu3avdu3d/65zf71diYqJSU1PDjnu9Xvn9/nbv19zcrObmZufjYDAY0XkBAHaK+Cup2tpazZo1S6tWrVJSUlJE7llSUiKPx+OsrKysiNwXAGC3iEeqqqpKJ06c0DXXXKOEhAQlJCRo+/btWrZsmRISEuT1etXS0qL6+vqwz6urq5PP52v3nsXFxQoEAs6qra2N9NgAAAtF/Md9Y8eO1QcffBB2bOrUqRo0aJDmzZunrKws9ejRQ2VlZZo0aZIkqbq6WkePHlVeXl6793S73XK73ZEeFQBguYhHqnfv3hoyZEjYsZ49eyo9Pd05Pm3aNM2dO1dpaWlKSUnR/fffr7y8PF177bWRHgcAEMM65cGJ83nqqacUFxenSZMmqbm5WePGjdOzzz4bjVEAABbrkki98847YR8nJSWptLRUpaWlXfHlAQAxivfuAwBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGCtTonUsWPHdNdddyk9PV3JyckaOnSo9uzZ45w3xmjhwoXq27evkpOTlZ+fr8OHD3fGKACAGBbxSP33v//VmDFj1KNHD23evFkHDx7UX//6V1166aXONUuWLNGyZcu0YsUKVVRUqGfPnho3bpyampoiPQ4AIIYlRPqGjz/+uLKysrRy5UrnWE5OjvOfjTFaunSpHn74YU2cOFGS9PLLL8vr9WrDhg2aPHlypEcCAMSoiL+Sev311zVy5EjdcccdysjI0PDhw/X8888752tqauT3+5Wfn+8c83g8ys3NVXl5ebv3bG5uVjAYDFsAgO4v4pH69NNPtXz5cg0cOFBvv/227rvvPj3wwAN66aWXJEl+v1+S5PV6wz7P6/U6576ppKREHo/HWVlZWZEeGwBgoYhHKhQK6ZprrtFjjz2m4cOHa8aMGZo+fbpWrFjxg+9ZXFysQCDgrNra2ghODACwVcQj1bdvX1155ZVhxwYPHqyjR49Kknw+nySprq4u7Jq6ujrn3De53W6lpKSELQBA9xfxSI0ZM0bV1dVhxw4dOqT+/ftL+t9DFD6fT2VlZc75YDCoiooK5eXlRXocAEAMi/jTfXPmzNF1112nxx57THfeeacqKyv13HPP6bnnnpMkuVwuzZ49W//3f/+ngQMHKicnRwsWLFBmZqZuu+22SI8DAIhhEY/UqFGjtH79ehUXF+svf/mLcnJytHTpUhUUFDjXPPjggzp16pRmzJih+vp6XX/99XrrrbeUlJQU6XEAADHMZYwx0R7i+woGg/J4PNEeA+g0N9xwgxYtWqQbbrgh2qMAneKr7+OBQOCczxnw3n0AAGsRKQCAtYgUAMBaRAoAYC0iBQCwFpECAFiLSAEArEWkAADWIlIAAGsRKQCAtYgUAMBaRAoAYC0iBQCwFpECAFiLSAEArEWkAADWIlIAAGsRKQCAtYgUAMBaRAoAYC0iBQCwFpECAFiLSAEArEWkAADWIlIAAGsRKQCAtYgUAMBaRAoAYC0iBQCwFpECAFiLSAEArEWkAADWIlIAAGsRKQCAtYgUAMBaRAoAYK2EaA8A4NuMMTp79qxaWlqiPcpFIz4+XnFxcXK5XNEeBV9DpAAL1dXV6c0339ShQ4eiPcpFITExUVdffbWGDh2qxMTEaI+DryFSgIWOHDmil156iW+YXSQlJUXTp0/XT37yE/47twyRAizU0tKizz//PNpjXDQaGxvV0NCgUCgU7VHwDTw4AQCwFpECAFiLSAEArEWkAADWIlIAAGsRKQCAtYgUAMBaEY9UW1ubFixYoJycHCUnJ+uKK67Qo48+KmOMc40xRgsXLlTfvn2VnJys/Px8HT58ONKjAABiXMQj9fjjj2v58uV65pln9NFHH+nxxx/XkiVL9PTTTzvXLFmyRMuWLdOKFStUUVGhnj17aty4cWpqaor0OACAGBbxd5x49913NXHiRE2YMEGSNGDAAL3yyiuqrKyU9L9XUUuXLtXDDz+siRMnSpJefvlleb1ebdiwQZMnT470SACAGBXxV1LXXXedysrKnDfGfO+997Rz507dfPPNkqSamhr5/X7l5+c7n+PxeJSbm6vy8vJ279nc3KxgMBi2AADdX8RfSc2fP1/BYFCDBg1SfHy82tratGjRIhUUFEiS/H6/JMnr9YZ9ntfrdc59U0lJif785z9HelQAkPS/36X7/X4dOHBAvXr1ivY4F4XGxsYOXRfxSL322mtatWqVVq9erauuukr79+/X7NmzlZmZqcLCwh90z+LiYs2dO9f5OBgMKisrK1IjA7jINTU1aevWraqpqVGPHj2iPc5FobW1tWMXmgjr16+feeaZZ8KOPfroo+anP/2pMcaY//znP0aS2bdvX9g1N954o3nggQc69DUCgYCRxGKxWKwYX4FA4Jzf7yP+O6nTp08rLi78tvHx8c5b4Ofk5Mjn86msrMw5HwwGVVFRoby8vEiPAwCIZR1/jdQxhYWF5rLLLjObNm0yNTU1Zt26daZPnz7mwQcfdK5ZvHixSU1NNRs3bjTvv/++mThxosnJyTFnzpzp0NfglRSLxWJ1j3W+V1IRj1QwGDSzZs0y2dnZJikpyVx++eXmoYceMs3Nzc41oVDILFiwwHi9XuN2u83YsWNNdXV1h78GkWKxWKzusc4XKZcxX3sriBgRDAbl8XiiPQYA4AIFAgGlpKR853neuw8AYC0iBQCwFpECAFiLSAEArEWkAADWIlIAAGsRKQCAtYgUAMBaRAoAYC0iBQCwFpECAFiLSAEArEWkAADWIlIAAGsRKQCAtYgUAMBaRAoAYC0iBQCwFpECAFiLSAEArEWkAADWIlIAAGsRKQCAtYgUAMBaRAoAYC0iBQCwFpECAFiLSAEArEWkAADWIlIAAGsRKQCAtYgUAMBaRAoAYC0iBQCwFpECAFiLSAEArEWkAADWIlIAAGsRKQCAtYgUAMBaRAoAYC0iBQCwFpECAFiLSAEArEWkAADWIlIAAGsRKQCAtb53pHbs2KFbbrlFmZmZcrlc2rBhQ9h5Y4wWLlyovn37Kjk5Wfn5+Tp8+HDYNSdPnlRBQYFSUlKUmpqqadOmqbGx8YI2AgDofr53pE6dOqVhw4aptLS03fNLlizRsmXLtGLFClVUVKhnz54aN26cmpqanGsKCgr04YcfasuWLdq0aZN27NihGTNm/PBdAAC6J3MBJJn169c7H4dCIePz+cwTTzzhHKuvrzdut9u88sorxhhjDh48aCSZ3bt3O9ds3rzZuFwuc+zYsQ593UAgYCSxWCwWK8ZXIBA45/f7iP5OqqamRn6/X/n5+c4xj8ej3NxclZeXS5LKy8uVmpqqkSNHOtfk5+crLi5OFRUV7d63ublZwWAwbAEAur+IRsrv90uSvF5v2HGv1+uc8/v9ysjICDufkJCgtLQ055pvKikpkcfjcVZWVlYkxwYAWComnu4rLi5WIBBwVm1tbbRHAgB0gYhGyufzSZLq6urCjtfV1TnnfD6fTpw4EXb+7NmzOnnypHPNN7ndbqWkpIQtAED3F9FI5eTkyOfzqayszDkWDAZVUVGhvLw8SVJeXp7q6+tVVVXlXLN161aFQiHl5uZGchwAQKz7Hg/zGWOMaWhoMPv27TP79u0zksyTTz5p9u3bZ44cOWKMMWbx4sUmNTXVbNy40bz//vtm4sSJJicnx5w5c8a5x/jx483w4cNNRUWF2blzpxk4cKCZMmVKh2fg6T4Wi8XqHut8T/d970ht27at3S9UWFhojPnfY+gLFiwwXq/XuN1uM3bsWFNdXR12jy+//NJMmTLF9OrVy6SkpJipU6eahoYGIsVisVgX2TpfpFzGGKMYEwwG5fF4oj0GAOACBQKBcz5nEBNP9wEALk5ECgBgLSIFALAWkQIAWItIAQCsRaQAANYiUgAAaxEpAIC1iBQAwFpECgBgLSIFALAWkQIAWItIAQCsRaQAANYiUgAAaxEpAIC1iBQAwFpECgBgLSIFALAWkQIAWItIAQCsRaQAANYiUgAAaxEpAIC1iBQAwFpECgBgLSIFALAWkQIAWItIAQCsRaQAANYiUgAAaxEpAIC1iBQAwFpECgBgLSIFALAWkQIAWItIAQCsRaQAANYiUgAAaxEpAIC1iBQAwFpECgBgLSIFALAWkQIAWItIAQCsRaQAANb63pHasWOHbrnlFmVmZsrlcmnDhg3OudbWVs2bN09Dhw5Vz549lZmZqbvvvlvHjx8Pu8fJkydVUFCglJQUpaamatq0aWpsbLzgzQAAupfvHalTp05p2LBhKi0t/da506dPa+/evVqwYIH27t2rdevWqbq6WrfeemvYdQUFBfrwww+1ZcsWbdq0STt27NCMGTN++C4AAN2TuQCSzPr16895TWVlpZFkjhw5Yowx5uDBg0aS2b17t3PN5s2bjcvlMseOHevQ1w0EAkYSi8VisWJ8BQKBc36/7/TfSQUCAblcLqWmpkqSysvLlZqaqpEjRzrX5OfnKy4uThUVFZ09DgAghiR05s2bmpo0b948TZkyRSkpKZIkv9+vjIyM8CESEpSWlia/39/ufZqbm9Xc3Ox8HAwGO29oAIA1Ou2VVGtrq+68804ZY7R8+fILuldJSYk8Ho+zsrKyIjQlAMBmnRKprwJ15MgRbdmyxXkVJUk+n08nTpwIu/7s2bM6efKkfD5fu/crLi5WIBBwVm1tbWeMDQCwTMR/3PdVoA4fPqxt27YpPT097HxeXp7q6+tVVVWlESNGSJK2bt2qUCik3Nzcdu/pdrvldrsjPSoAwHLfO1KNjY365JNPnI9ramq0f/9+paWlqW/fvvrNb36jvXv3atOmTWpra3N+z5SWlqbExEQNHjxY48eP1/Tp07VixQq1trZq5syZmjx5sjIzMyO3MwBA7OvQM99fs23btnYfIywsLDQ1NTXf+Zjhtm3bnHt8+eWXZsqUKaZXr14mJSXFTJ061TQ0NHR4Bh5BZ7FYrO6xzvcIussYYxRjgsGgPB5PtMcAAFygQCAQ9tzCN/HefQAAaxEpAIC1iBQAwFpECgBgLSIFALAWkQIAWItIAQCsRaQAANYiUgAAaxEpAIC1iBQAwFpECgBgLSIFALAWkQIAWCsmIxWDf10EANCO830/j8lINTQ0RHsEAEAEnO/7eUz+0cNQKKTjx4/LGKPs7GzV1tae849mxbJgMKisrKxuvUeJfXY3F8M+L4Y9Sp23T2OMGhoalJmZqbi47369lBCxr9iF4uLi1K9fPwWDQUlSSkpKt/5HIl0ce5TYZ3dzMezzYtij1Dn77MhfWI/JH/cBAC4ORAoAYK2YjpTb7dYjjzwit9sd7VE6zcWwR4l9djcXwz4vhj1K0d9nTD44AQC4OMT0KykAQPdGpAAA1iJSAABrESkAgLViNlKlpaUaMGCAkpKSlJubq8rKymiPdEFKSko0atQo9e7dWxkZGbrttttUXV0ddk1TU5OKioqUnp6uXr16adKkSaqrq4vSxBdu8eLFcrlcmj17tnOsu+zx2LFjuuuuu5Senq7k5GQNHTpUe/bscc4bY7Rw4UL17dtXycnJys/P1+HDh6M48ffX1tamBQsWKCcnR8nJybriiiv06KOPhr0XWyzuc8eOHbrllluUmZkpl8ulDRs2hJ3vyJ5OnjypgoICpaSkKDU1VdOmTVNjY2MX7uLczrXH1tZWzZs3T0OHDlXPnj2VmZmpu+++W8ePHw+7R5ft0cSgNWvWmMTERPOPf/zDfPjhh2b69OkmNTXV1NXVRXu0H2zcuHFm5cqV5sCBA2b//v3mV7/6lcnOzjaNjY3ONffee6/JysoyZWVlZs+ePebaa6811113XRSn/uEqKyvNgAEDzNVXX21mzZrlHO8Oezx58qTp37+/ueeee0xFRYX59NNPzdtvv20++eQT55rFixcbj8djNmzYYN577z1z6623mpycHHPmzJkoTv79LFq0yKSnp5tNmzaZmpoas3btWtOrVy/zt7/9zbkmFvf55ptvmoceesisW7fOSDLr168PO9+RPY0fP94MGzbM7Nq1y/z73/82P/7xj82UKVO6eCff7Vx7rK+vN/n5+ebVV181H3/8sSkvLzejR482I0aMCLtHV+0xJiM1evRoU1RU5Hzc1tZmMjMzTUlJSRSniqwTJ04YSWb79u3GmP/9w+nRo4dZu3atc81HH31kJJny8vJojfmDNDQ0mIEDB5otW7aYn//8506kusse582bZ66//vrvPB8KhYzP5zNPPPGEc6y+vt643W7zyiuvdMWIETFhwgTz+9//PuzY7bffbgoKCowx3WOf3/wG3pE9HTx40Egyu3fvdq7ZvHmzcblc5tixY102e0e1F+JvqqysNJLMkSNHjDFdu8eY+3FfS0uLqqqqlJ+f7xyLi4tTfn6+ysvLozhZZAUCAUlSWlqaJKmqqkqtra1h+x40aJCys7Njbt9FRUWaMGFC2F6k7rPH119/XSNHjtQdd9yhjIwMDR8+XM8//7xzvqamRn6/P2yfHo9Hubm5MbXP6667TmVlZTp06JAk6b333tPOnTt18803S+o++/y6juypvLxcqampGjlypHNNfn6+4uLiVFFR0eUzR0IgEJDL5VJqaqqkrt1jzL3B7BdffKG2tjZ5vd6w416vVx9//HGUpoqsUCik2bNna8yYMRoyZIgkye/3KzEx0flH8hWv1yu/3x+FKX+YNWvWaO/evdq9e/e3znWXPX766adavny55s6dqz/96U/avXu3HnjgASUmJqqwsNDZS3v/hmNpn/Pnz1cwGNSgQYMUHx+vtrY2LVq0SAUFBZLUbfb5dR3Zk9/vV0ZGRtj5hIQEpaWlxeS+m5qaNG/ePE2ZMsV5g9mu3GPMRepiUFRUpAMHDmjnzp3RHiWiamtrNWvWLG3ZskVJSUnRHqfThEIhjRw5Uo899pgkafjw4Tpw4IBWrFihwsLCKE8XOa+99ppWrVql1atX66qrrtL+/fs1e/ZsZWZmdqt9XsxaW1t15513yhij5cuXR2WGmPtxX58+fRQfH/+tJ77q6urk8/miNFXkzJw5U5s2bdK2bdvUr18/57jP51NLS4vq6+vDro+lfVdVVenEiRO65pprlJCQoISEBG3fvl3Lli1TQkKCvF5vzO9Rkvr27asrr7wy7NjgwYN19OhRSXL2Euv/hv/4xz9q/vz5mjx5soYOHarf/e53mjNnjkpKSiR1n31+XUf25PP5dOLEibDzZ8+e1cmTJ2Nq318F6siRI9qyZUvYn+noyj3GXKQSExM1YsQIlZWVOcdCoZDKysqUl5cXxckujDFGM2fO1Pr167V161bl5OSEnR8xYoR69OgRtu/q6modPXo0ZvY9duxYffDBB9q/f7+zRo4cqYKCAuc/x/oeJWnMmDHf+r8PHDp0SP3795ck5eTkyOfzhe0zGAyqoqIipvZ5+vTpb/2xuvj4eIVCIUndZ59f15E95eXlqb6+XlVVVc41W7duVSgUUm5ubpfP/EN8FajDhw/rX//6l9LT08POd+keI/oYRhdZs2aNcbvd5sUXXzQHDx40M2bMMKmpqcbv90d7tB/svvvuMx6Px7zzzjvms88+c9bp06eda+69916TnZ1ttm7davbs2WPy8vJMXl5eFKe+cF9/us+Y7rHHyspKk5CQYBYtWmQOHz5sVq1aZS655BLzz3/+07lm8eLFJjU11WzcuNG8//77ZuLEidY/mv1NhYWF5rLLLnMeQV+3bp3p06ePefDBB51rYnGfDQ0NZt++fWbfvn1GknnyySfNvn37nCfbOrKn8ePHm+HDh5uKigqzc+dOM3DgQKseQT/XHltaWsytt95q+vXrZ/bv3x/2/ai5udm5R1ftMSYjZYwxTz/9tMnOzjaJiYlm9OjRZteuXdEe6YJIanetXLnSuebMmTPmD3/4g7n00kvNJZdcYn7961+bzz77LHpDR8A3I9Vd9vjGG2+YIUOGGLfbbQYNGmSee+65sPOhUMgsWLDAeL1e43a7zdixY011dXWUpv1hgsGgmTVrlsnOzjZJSUnm8ssvNw899FDYN7JY3Oe2bdva/d9iYWGhMaZje/ryyy/NlClTTK9evUxKSoqZOnWqaWhoiMJu2neuPdbU1Hzn96Nt27Y59+iqPfKnOgAA1oq530kBAC4eRAoAYC0iBQCwFpECAFiLSAEArEWkAADWIlIAAGsRKQCAtYgUAMBaRAoAYC0iBQCwFpECAFjr/wHafkaZFd0e7gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
      "training data size :  128\n",
      "predictions :  (ا) :  1.0000 <---------------------------------------------------\n",
      "predictions :  (ل) :  0.0000\n",
      "predictions :  (ر) :  0.0000\n",
      "predictions :  (ب) :  0.0000\n",
      "predictions :  (ه) :  0.0000\n",
      "predictions :  (٦) :  0.0000\n",
      "predictions :  (٩) :  0.0000\n",
      "predictions :  (ف) :  0.0000\n",
      "predictions :  (لا) :  0.0000\n",
      "predictions :  (ن) :  0.0000\n",
      "predictions :  (ز) :  0.0000\n",
      "predictions :  (د) :  0.0000\n",
      "predictions :  (٢) :  0.0000\n",
      "predictions :  (ي) :  0.0000\n",
      "predictions :  (س) :  0.0000\n",
      "predictions :  (١) :  0.0000\n",
      "predictions :  (٨) :  0.0000\n",
      "predictions :  (٠) :  0.0000\n",
      "predictions :  (م) :  0.0000\n",
      "predictions :  (و) :  0.0000\n",
      "predictions :  (٤) :  0.0000\n",
      "predictions :  (٧) :  0.0000\n",
      "predictions :  (ح) :  0.0000\n",
      "predictions :  (٥) :  0.0000\n",
      "predictions :  (ك) :  0.0000\n",
      "predictions :  (ذ) :  0.0000\n",
      "predictions :  (ق) :  0.0000\n",
      "predictions :  (ط) :  0.0000\n",
      "predictions :  (خ) :  0.0000\n",
      "predictions :  (ت) :  0.0000\n",
      "predictions :  (ظ) :  0.0000\n",
      "predictions :  (ج) :  0.0000\n",
      "predictions :  (ع) :  0.0000\n",
      "predictions :  (٣) :  0.0000\n",
      "predictions :  (ض) :  0.0000\n",
      "predictions :  (ش) :  0.0000\n",
      "predictions :  (غ) :  0.0000\n",
      "predictions :  (ص) :  0.0000\n",
      "predictions :  (ث) :  0.0000\n"
     ]
    }
   ],
   "source": [
>>>>>>> 862da96667c17339cd91f027ba1f2d263cb47ba6
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
<<<<<<< HEAD
    "from PIL import Image\n",
    "import pandas as pd\n",
=======
    "from tensorflow.keras import backend as K\n",
    "from PIL import Image\n",
>>>>>>> 862da96667c17339cd91f027ba1f2d263cb47ba6
    "import numpy as np\n",
    "from tkinter import filedialog\n",
    "from tkinter import Tk\n",
    "import os\n",
    "\n",
<<<<<<< HEAD
    "models_paths = [\n",
    "    r\"C:\\Users\\Dell\\Desktop\\Bachelor\\image_classification\\misc\\runned\\2500 dataset\\16\\model img_size_16.keras\",\n",
    "    r\"C:\\Users\\Dell\\Desktop\\Bachelor\\image_classification\\misc\\runned\\2500 dataset\\32\\model img_size_32.keras\",\n",
    "    r\"C:\\Users\\Dell\\Desktop\\Bachelor\\image_classification\\misc\\runned\\2500 dataset\\64\\model img_size_64.keras\",\n",
    "    r\"C:\\Users\\Dell\\Desktop\\Bachelor\\image_classification\\misc\\runned\\2500 dataset\\128\\model img_size_128.keras\",\n",
    "    r\"C:\\Users\\Dell\\Desktop\\Bachelor\\image_classification\\misc\\runned\\2500 dataset\\256\\model img_size_256.keras\",\n",
    "    r\"C:\\Users\\Dell\\Desktop\\Bachelor\\image_classification\\misc\\runned\\2500 dataset\\300\\model img_size_300.keras\",\n",
    "\n",
    "    r\"C:\\Users\\Dell\\Desktop\\Bachelor\\image_classification\\misc\\runned\\1800 dataset\\16\\model img_size_16.keras\",\n",
    "    r\"C:\\Users\\Dell\\Desktop\\Bachelor\\image_classification\\misc\\runned\\1800 dataset\\32\\model img_size_32.keras\",\n",
    "    # r\"C:\\Users\\Dell\\Desktop\\Bachelor\\image_classification\\misc\\runned\\1800 dataset\\64\\model img_size_64.keras\",\n",
    "    # r\"C:\\Users\\Dell\\Desktop\\Bachelor\\image_classification\\misc\\runned\\1800 dataset\\128\\model img_size_128.keras\",\n",
    "    # r\"C:\\Users\\Dell\\Desktop\\Bachelor\\image_classification\\misc\\runned\\1800 dataset\\256\\model img_size_256.keras\",\n",
    "    # r\"C:\\Users\\Dell\\Desktop\\Bachelor\\image_classification\\misc\\runned\\1800 dataset\\300\\model img_size_300.keras\",\n",
    "\n",
    "                ]\n",
    "\n",
    "# Load the class labels\n",
    "index_to_label_path = r\"C:\\Users\\Dell\\Desktop\\Bachelor\\image_classification\\misc\\runned\\index_to_label.json\"\n",
=======
    "# Load the trained model\n",
    "\n",
    "models_paths = [\n",
    "                #  r\"C:\\Users\\Dell\\Desktop\\Bachelor\\image_classification\\misc\\runned\\16\\model img_size_16.keras\",\n",
    "                #  r\"C:\\Users\\Dell\\Desktop\\Bachelor\\image_classification\\misc\\runned\\32\\model img_size_32.keras\",\n",
    "                #  r\"C:\\Users\\Dell\\Desktop\\Bachelor\\image_classification\\misc\\runned\\64\\model img_size_64.keras\",\n",
    "                #  r\"C:\\Users\\Dell\\Desktop\\Bachelor\\image_classification\\misc\\runned\\128\\model img_size_128.keras\",\n",
    "                 r\"C:\\Users\\Dell\\Desktop\\Bachelor\\image_classification\\misc\\runned\\256\\model img_size_256.keras\"\n",
    "                ]\n",
    "\n",
    "# Load the class labels\n",
    "index_to_label_path = r\"C:\\Users\\Dell\\Desktop\\Bachelor\\image_classification\\misc\\runned\\128\\index_to_label.json\"\n",
>>>>>>> 862da96667c17339cd91f027ba1f2d263cb47ba6
    "with open(index_to_label_path, 'r', encoding='utf-8') as f:\n",
    "    class_labels = json.load(f)\n",
    "\n",
    "# Open a file chooser and get the image path\n",
    "print(\"Please select an image to classify...\")\n",
    "root = Tk()\n",
    "root.attributes('-topmost', True) # bring the window to the front\n",
    "root.withdraw() # we don't want a full GUI, so keep the root window from appearing\n",
    "root.update()\n",
    "image_path = filedialog.askopenfilename() # show an \"Open\" dialog box and return the path to the selected file\n",
<<<<<<< HEAD
    "# open the image in windows using pillow\n",
    "img = Image.open(image_path)\n",
    "img.show()\n",
    "\n",
    "root.destroy()\n",
    "\n",
    "table_headers = [model_path.split(\"\\\\\")[-3] + \" , \" + model_path.split(\"\\\\\")[-2] for model_path in models_paths]\n",
    "\n",
    "predictions_dict = {label: {} for label in class_labels.values()}\n",
    "printed_text = \"\"\n",
    "\n",
    "# Use the model to predict the class of the image\n",
    "for model_path in models_paths:\n",
    "    training_data_size = (model_path.split(\"\\\\\")[-3]).split(\" \")[0]\n",
    "    img_size = int(model_path.split(\"\\\\\")[-2]) \n",
    "    current_model_name = \"\" + training_data_size + \" ,\" + str(img_size)\n",
    "    print(\"\\nloading model that was trained on dataset : \", training_data_size , \", with image size : \", img_size , \" ...\")\n",
    "   \n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    img = image.load_img(image_path, target_size=(img_size, img_size))\n",
=======
    "root.destroy()\n",
    "\n",
    "# Use the model to predict the class of the image\n",
    "for model_path in models_paths:\n",
    "    training_data_size = int(model_path.split(\"\\\\\")[-2])   \n",
    "    print(\"loading model that was trained on a dataset of size : \", training_data_size)\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    print(f\"model loaded successfully.\")\n",
    "    img = image.load_img(image_path, target_size=(training_data_size, training_data_size))\n",
>>>>>>> 862da96667c17339cd91f027ba1f2d263cb47ba6
    "    # Preprocess the image\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = img.astype('float32')/255 \n",
<<<<<<< HEAD
    "\n",
    "    model_prediction = model.predict(img)\n",
    "    highest_probability_class_index = np.argmax(model_prediction)\n",
    "    sorted_predictions = sorted(enumerate(model_prediction[0]), key=lambda x: x[1], reverse=True)    \n",
    "    printed_text += f\"Predictions for model trained on dataset of size {training_data_size} and image size {img_size}:\\n\"\n",
    "    for i, probability in sorted_predictions:\n",
    "        entity_name = class_labels[str(i)]\n",
    "        predictions_dict[entity_name][current_model_name] = probability\n",
    "        printed_text += f'({class_labels[str(i)]}) :  {probability:.4f}'\n",
    "        if(i == highest_probability_class_index):\n",
    "            printed_text += ' <---------------------------------------------------'   \n",
    "        printed_text += '\\n'\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions_dict).transpose()\n",
    "predictions_table = predictions_df.style.background_gradient(cmap='tab20_r').set_table_styles(\n",
    "    [dict(selector=\"th\", props=[(\"text-align\", \"center\")])]\n",
    ")\n",
    "display(predictions_table)\n",
    "print(printed_text)"
=======
    "    # plot the image widh its dimensions\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    model_prediction = model.predict(img)\n",
    "    # The output will be the probabilities for each class. To get the class with the highest probability, use argmax\n",
    "    predicted_class_index = np.argmax(model_prediction)\n",
    "    sorted_predictions = sorted(enumerate(model_prediction[0]), key=lambda x: x[1], reverse=True)\n",
    "    print(\"training data size : \", training_data_size)\n",
    "    for i, probability in sorted_predictions:\n",
    "        predictions_text = f'({class_labels[str(i)]}) :  {probability:.4f}'\n",
    "        if(i == predicted_class_index):\n",
    "            predictions_text += ' <---------------------------------------------------'   \n",
    "        print(\"predictions : \", predictions_text)\n",
    "\n",
    "    # clear the model from memory\n",
    "    K.clear_session()\n",
    "    del model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Choose a zip file to extract the images </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "from tkinter import Button, ttk ,filedialog, Label, TclError, Frame\n",
    "from tkinterdnd2 import DND_FILES, TkinterDnD\n",
    "import tkinter.messagebox\n",
    "\n",
    "def extract_zip(source_path, destination_path, progressbar , drop_label):\n",
    "    drop_label.config(text=\"Extracting....\")\n",
    "    drop_label.update()\n",
    "    if os.path.exists(destination_path):\n",
    "        shutil.rmtree(destination_path)\n",
    "    with zipfile.ZipFile(source_path, 'r') as zip_ref:\n",
    "        files = zip_ref.infolist()\n",
    "        progressbar['maximum'] = len(files)\n",
    "        for i, file in enumerate(files):\n",
    "            zip_ref.extract(file, path=destination_path)\n",
    "            progressbar['value'] = i\n",
    "            progressbar.update()\n",
    "        progressbar['value'] = len(files)\n",
    "        \n",
    "        \n",
    "\n",
    "def drop(event):\n",
    "    file_path = event.data[1:-1]  # remove the curly braces\n",
    "    if file_path:\n",
    "        zip_file_name = os.path.basename(file_path)\n",
    "        destination_path = os.path.join(os.path.dirname(file_path), os.path.splitext(zip_file_name)[0])\n",
    "        extract_zip(file_path, destination_path, progressbar, drop_label)\n",
    "        os.startfile(os.path.dirname(destination_path))\n",
    "\n",
    "def choose_file_and_extract(root, progressbar, drop_label):\n",
    "    file_path = filedialog.askopenfilename(filetypes=[('Zip files', '*.zip')])\n",
    "    if file_path:\n",
    "        zip_file_name = os.path.basename(file_path)\n",
    "        destination_path = os.path.join(os.path.dirname(file_path), os.path.splitext(zip_file_name)[0])\n",
    "        extract_zip(file_path, destination_path, progressbar, drop_label)\n",
    "        os.startfile(os.path.dirname(destination_path))\n",
    "        root.destroy()  # Close the window after execution\n",
    "\n",
    "\n",
    "root = TkinterDnD.Tk()\n",
    "root.title(\"Zip Extractor\") \n",
    "# root.configure(bg='lightblue')\n",
    "root.geometry('990x540')  # Set the window size to half of your screen size\n",
    "\n",
    "progressbar = ttk.Progressbar(root, length=990, mode='determinate')\n",
    "progressbar.pack() \n",
    "\n",
    "drop_label = Label(root, text=\"Drop your file here\", font=(\"Arial\", 24))\n",
    "# drop_label.place(relx=0.5, rely=0.5, anchor='center')\n",
    "drop_label.pack(pady=100)\n",
    "\n",
    "choose_button = Button(root, text=\"Or Choose Manually\", command=lambda: choose_file_and_extract(root, progressbar, drop_label), height=2, width=20, font=(\"Arial\", 20), bg='green', fg='white', relief='raised', borderwidth=5)\n",
    "choose_button.pack()\n",
    "\n",
    "root.drop_target_register(DND_FILES)\n",
    "root.dnd_bind('<<Drop>>', drop)\n",
    "\n",
    "try:\n",
    "    root.mainloop()\n",
    "except TclError:\n",
    "    pass\n",
    "except Exception as e:\n",
    "    tkinter.messagebox.showerror(\"Error\", str(e))\n",
    "\n"
>>>>>>> 862da96667c17339cd91f027ba1f2d263cb47ba6
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Move images from one folder to another</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def move_files_with_rename(src_folder, dst_folder):\n",
    "    # Iterate over all files in the source folder\n",
    "    for filename in os.listdir(src_folder):\n",
    "        src_file = os.path.join(src_folder, filename)\n",
    "        dst_file = os.path.join(dst_folder, filename)\n",
    "\n",
    "        # If a file with the same name exists in the destination folder, rename the file being moved\n",
    "        if os.path.exists(dst_file):\n",
    "            base, extension = os.path.splitext(filename)\n",
    "            filename = f\"{base}_changed{extension}\"\n",
    "            dst_file = os.path.join(dst_folder, filename)\n",
    "\n",
    "        # Move the file\n",
    "        shutil.move(src_file, dst_file)\n",
    "\n",
    "# Use the function\n",
    "src_folder = \"C:/Users/Dell/Desktop/test/500/test\"\n",
    "dst_folder = \"C:/Users/Dell/Desktop/test/500/train\"\n",
    "move_files_with_rename(src_folder, dst_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Divide a dataset into train & test folders </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the source directory and the target directories\n",
    "source_dir = './data set/all/'\n",
    "train_dir = './data set/train/'\n",
    "test_dir = './data set/test/'\n",
    "\n",
    "# Create the target directories if they don't exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Get a list of all the dog and cat image filenames\n",
    "dog_images = [i for i in os.listdir(source_dir) if 'dog' in i]\n",
    "cat_images = [i for i in os.listdir(source_dir) if 'cat' in i]\n",
    "\n",
    "# Split the filenames into training and testing sets\n",
    "train_dogs, test_dogs = train_test_split(dog_images, test_size=0.25)\n",
    "train_cats, test_cats = train_test_split(cat_images, test_size=0.25)\n",
    "\n",
    "# Function to move files\n",
    "def move_files(files, target_dir):\n",
    "    for file in files:\n",
    "        shutil.move(source_dir + file, target_dir + file)\n",
    "\n",
    "# Move the corresponding files into the appropriate directories\n",
    "move_files(train_dogs, train_dir)\n",
    "move_files(test_dogs, test_dir)\n",
    "move_files(train_cats, train_dir)\n",
    "move_files(test_cats, test_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Join folders containing different letter positions into one folder </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "root_dir = r\"C:\\Users\\Dell\\Desktop\\datasets\\1500 (also contains paragraphs)\\1500 (also contains paragraphs)\\isolated_alphabets_per_alphabet\"\n",
    "# dest is beside the root directory\n",
    "dest_dir = os.path.join(os.path.dirname(root_dir), \"joined\")\n",
    "\n",
    "# Get a list of all subdirectories in the root directory\n",
    "subdirs = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
    "print(\"started\")\n",
    "if(os.path.exists(dest_dir)):\n",
    "    print(\"deleting existing root directory...\")\n",
    "    shutil.rmtree(dest_dir)\n",
    "for subdir in subdirs:\n",
    "    print(\"woring in \", subdir)\n",
    "    if '_' in subdir: # because some subdirectories (numbers) don't have an underscore in their naems and dont need joining\n",
    "        letter_name = subdir.split('_')[0]\n",
    "        new_dir = os.path.join(dest_dir, letter_name)\n",
    "        os.makedirs(new_dir, exist_ok=True)\n",
    "        files = [f for f in os.listdir(os.path.join(root_dir, subdir))]\n",
    "        for file in files:\n",
    "            shutil.copy(os.path.join(root_dir, subdir, file), os.path.join(new_dir, file))\n",
    "    else:\n",
    "        shutil.copytree(os.path.join(root_dir, subdir), os.path.join(dest_dir, subdir))\n",
    "print(\"done\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> same as above code but copy folders only not the files they contain </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "root_dir = r\"C:\\Users\\Dell\\Desktop\\datasets\\1800 - position categorized\\1800 - position categorized\\HMBD-v1-master\\Dataset\"\n",
    "# dest is beside the root directory\n",
    "dest_dir = os.path.join(os.path.dirname(root_dir), \"joined\")\n",
    "\n",
    "# Get a list of all subdirectories in the root directory\n",
    "subdirs = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
    "print(\"started\")\n",
    "if(os.path.exists(dest_dir)):\n",
    "    print(\"deleting existing root directory...\")\n",
    "    shutil.rmtree(dest_dir)\n",
    "for subdir in subdirs:\n",
    "    print(\"woring in \", subdir)\n",
    "    if '_' in subdir: # because some subdirectories (numbers) don't have an underscore in their naems and dont need joining\n",
    "        letter_name = subdir.split('_')[0]\n",
    "    else :\n",
    "        letter_name = subdir    \n",
    "    new_dir = os.path.join(dest_dir, letter_name)\n",
    "    os.makedirs(new_dir, exist_ok=True)\n",
    "    shutil.copytree(os.path.join(root_dir, subdir), os.path.join(new_dir, subdir))\n",
    "print(\"done\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "<h1> move all files from directory to its parent directory , for all subdirectories in the dataset </h1>"
=======
    "<h1> extract all files from directory to its parent directory , for all subdirectories in the dataset </h1>"
>>>>>>> 862da96667c17339cd91f027ba1f2d263cb47ba6
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <h1> extract all files from directory to its parent directory , for all subdirectories in the dataset </h1>\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "def join_files_in_subdirs(dest,current_dir):\n",
    "    if(not os.path.isdir(current_dir)):\n",
    "        shutil.copy(current_dir, dest)\n",
    "    else:\n",
    "        for subdir in os.listdir(current_dir):\n",
    "            join_files_in_subdirs(dest, os.path.join(current_dir, subdir))\n",
    "        contains_files_only = all(os.path.isfile(os.path.join(current_dir, child_dir)) for child_dir in os.listdir(current_dir))\n",
    "        if contains_files_only:\n",
    "           print (\"done with \", current_dir)\n",
    "           \n",
    "\n",
    "    \n",
    "root_dir = r\"C:\\Users\\Dell\\Desktop\\datasets\\1800 - position categorized\\joined\"\n",
    "dest_dir = os.path.join(os.path.dirname(root_dir), \"joined & merged\")\n",
    "if(os.path.exists(dest_dir)):\n",
    "    print(\"deleting existing root directory...\")\n",
    "    shutil.rmtree(dest_dir)\n",
    "os.makedirs(dest_dir, exist_ok=True)\n",
    "\n",
    "for subdir in os.listdir(root_dir):\n",
    "    merging_dest = os.path.join(dest_dir, subdir)\n",
    "    os.makedirs(merging_dest, exist_ok=True)\n",
    "    join_files_in_subdirs(merging_dest, os.path.join(root_dir, subdir))\n",
    "print(\"done merging \")\n",
    "# open the parent directory of the root directory upon finishing\n",
    "os.startfile(os.path.dirname(dest_dir))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Clear kaggle output folder </h1>"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal sorting :  ['1 - Alf', '10 - Raa', '11 - Zin', '12 - Sin', '13 - Shen', '14 - Saad', '15 - Daad', '16 - Tah', '17 - Zah', '18 - Ain', '19 - Gen', '2 - Baa', '20 - Faa', '21 - Qaf', '22 - Kaf', '23 - Lam', '24 - Mem', '25 - Non', '26 - Ha', '27 - Waw', '28 - Yaa', '29 - AlfHamzaAbove', '3 - Taa', '30 - AlfHamzaUnder', '31 - Hamza', '32 - LamAlf', '33 - LamAlfHamza', '34 - LamAlfMad', '35 - zero', '36 - one', '37 - two', '38 - three', '39 - four', '4 - Thaa', '40 - five', '41 - six', '42 - seven', '43 - eight', '44 - nine', '5 - Gem', '6 - Haa', '7 - Khaa', '8 - Dal', '9 - Zal']\n",
      "sorted by number :  ['1 - Alf', '2 - Baa', '3 - Taa', '4 - Thaa', '5 - Gem', '6 - Haa', '7 - Khaa', '8 - Dal', '9 - Zal', '10 - Raa', '11 - Zin', '12 - Sin', '13 - Shen', '14 - Saad', '15 - Daad', '16 - Tah', '17 - Zah', '18 - Ain', '19 - Gen', '20 - Faa', '21 - Qaf', '22 - Kaf', '23 - Lam', '24 - Mem', '25 - Non', '26 - Ha', '27 - Waw', '28 - Yaa', '29 - AlfHamzaAbove', '30 - AlfHamzaUnder', '31 - Hamza', '32 - LamAlf', '33 - LamAlfHamza', '34 - LamAlfMad', '35 - zero', '36 - one', '37 - two', '38 - three', '39 - four', '40 - five', '41 - six', '42 - seven', '43 - eight', '44 - nine']\n"
     ]
    }
   ],
>>>>>>> 862da96667c17339cd91f027ba1f2d263cb47ba6
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def clear_directory(dir_path):\n",
    "    for filename in os.listdir(dir_path):\n",
    "        file_path = os.path.join(dir_path, filename)\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)  # remove file or symlink\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)  # remove directory\n",
    "\n",
    "# Usage:\n",
    "dir_path = \"/kaggle/working/\"\n",
    "clear_directory(dir_path)"
   ]
<<<<<<< HEAD
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Delete corrupted images </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import warnings\n",
    "from PIL import Image\n",
    "\n",
    "def image_is_ok(image_path):\n",
    "    with warnings.catch_warnings(record=True) as w:\n",
    "        try:\n",
    "            img = Image.open(image_path)\n",
    "            img.verify()\n",
    "            if len(w) > 0:  # if any warnings were issued\n",
    "                return False\n",
    "            return True\n",
    "        except (IOError, SyntaxError):\n",
    "            return False\n",
    "        \n",
    "dirty_dataset_path = r\"C:\\Users\\Dell\\Desktop\\Bachelor\\datasets\\26 letters\\2500\\2500 letters only\"\n",
    "\n",
    "print(\"Cleaning the dataset in : \", dirty_dataset_path)\n",
    "for entity_name in os.listdir(dirty_dataset_path):\n",
    "    print(f\"Cleaning entity: {entity_name}\")\n",
    "    entity_path = os.path.join(dirty_dataset_path, entity_name)\n",
    "    for img_name in os.listdir(entity_path):\n",
    "        img_path = os.path.join(entity_path, img_name)\n",
    "        if not image_is_ok(img_path):\n",
    "            os.remove(img_path)\n",
    "            print(f\"file: {img_path} in folder: {entity_name} is corrupted and has been deleted.\")\n",
    "print(\"Dataset cleaned successfully!\")    "
   ]
=======
>>>>>>> 862da96667c17339cd91f027ba1f2d263cb47ba6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
