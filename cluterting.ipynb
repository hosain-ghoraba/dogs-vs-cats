{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> Global Variables & Paths <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "img size:  128\n",
            "Global Variables & Paths are set successfully.\n"
          ]
        }
      ],
      "source": [
        "# --------------------------------------------------------- Global Variables & Paths\n",
        "# region\n",
        "# @title Global Variables & Paths { display-mode: \"form\" }\n",
        "import os\n",
        "\n",
        "# --------------- vscode\n",
        "VS_CODE_RAW_DATA_SET_PATH = r\"C:\\Users\\Dell\\Desktop\\Bachelor\\datasets\\26 letters\\1800\\1800 letters only\" # modify per data set\n",
        "VS_CODE_CLEAN_DATA_SET_PATH = '../image_classification/data/clean_data'\n",
        "\n",
        "# --------------- kaggle\n",
        "KAGGLE_RAW_DATA_SET_PATH = '/kaggle/input/clean-1800-letters-only' # put (dataset name immediately after /input), and any extra folders modify per data set\n",
        "KAGGLE_CLEAN_DATA_SET_PATH = '/kaggle/working/clean_data'\n",
        "\n",
        "\n",
        "# --------------- colab\n",
        "KAGGLE_CRED_PATH = '/content/gdrive/MyDrive/Bachelor/kaggle'\n",
        "KAGGLE_DATA_SET_NAME = 'mahmoudreda55/arabic-letters-numbers-ocr'  # username/dataset name..t modify per data set\n",
        "COLAB_RAW_DATA_SET_PATH = '/content/kaggle_data/Dataset' # put (dataset_name) after (kaggle_data) , then put any extra folders... modify the part after (kaggle_data) per data set\n",
        "COLAB_CLAEN_DATA_SET_PATH = '/content/clean_data'\n",
        "\n",
        "# ----------------- global variables\n",
        "EPOCHS = 100\n",
        "DATA_PERCENTAGE_TO_USE = 20\n",
        "image_size = 128\n",
        "USE_RAW_DATA = True\n",
        "RENAME_CLEAN_DATA = False\n",
        "# ----------------- for clustering\n",
        "CLUSTERS_COUNT = 4\n",
        "CLUSTERS_IMAGES_DEST = os.path.join(os.getcwd(), 'clusters_images')\n",
        "ESTIMATE_OPTIMAL_NO_OF_CLUSTERS = False\n",
        "\n",
        "print(\"img size: \", image_size)\n",
        "print('Global Variables & Paths are set successfully.')\n",
        "# endregion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> time calculation function <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time calculation function is set successfully.\n"
          ]
        }
      ],
      "source": [
        "# --------------------------------------------------------- time calculation function\n",
        "# region\n",
        "# @title time calculation function { display-mode: \"form\" }\n",
        "\n",
        "\n",
        "import time\n",
        "\n",
        "global_start_time = time.time() # to calculate time taken for the whole notebook to run\n",
        "def calculate_and_print_time(start_time , section_name):\n",
        "    end_time = time.time()\n",
        "    time_taken = end_time - start_time\n",
        "    hours = int(time_taken // 3600)\n",
        "    minutes = int((time_taken % 3600) // 60)\n",
        "    seconds = int((time_taken % 3600) % 60)\n",
        "    print(f'\\n{section_name} done in : {hours} h, {minutes} m, {seconds} s')\n",
        "\n",
        "print('time calculation function is set successfully.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> install libraries <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "seaborn (0.13.2) is installed\n",
            "tensorflow (2.16.1) is installed\n",
            "natsort (8.4.0) is installed\n",
            "\n",
            "installing required packages done in : 0 h, 0 m, 0 s\n"
          ]
        }
      ],
      "source": [
        "# --------------------------------------------------------- install libraries\n",
        "# region\n",
        "# @title install libraries { display-mode: \"form\" }\n",
        "\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "import pkg_resources\n",
        "REQUIRED_PACKAGES = ['seaborn', 'tensorflow','natsort']\n",
        "\n",
        "for package in REQUIRED_PACKAGES:\n",
        "    try:\n",
        "        dist = pkg_resources.get_distribution(package)\n",
        "        print('{} ({}) is installed'.format(dist.key, dist.version))\n",
        "    except pkg_resources.DistributionNotFound:\n",
        "        print('{} is NOT installed'.format(package))\n",
        "        %pip install {package} \n",
        "# uninstall the standalone keras package to force using the one installed with tensorflow\n",
        "# %pip uninstall keras -y\n",
        "\n",
        "\n",
        "calculate_and_print_time(start_time, 'installing required packages')\n",
        "# print(\"installing required packages done\")\n",
        "# endregion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> imports <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "imports done in : 0 h, 0 m, 0 s\n"
          ]
        }
      ],
      "source": [
        "# --------------------------------------------------------- imports\n",
        "# region\n",
        "# @title imports { display-mode: \"form\" }\n",
        "start_time = time.time()\n",
        "\n",
        "import os\n",
        "\n",
        "import uuid\n",
        "import time\n",
        "import json\n",
        "import random\n",
        "import warnings\n",
        "import shutil\n",
        "import zipfile\n",
        "from natsort import natsorted\n",
        "from os import makedirs\n",
        "from os import listdir\n",
        "from tqdm import tqdm\n",
        "from shutil import copyfile\n",
        "from random import seed\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,confusion_matrix,ConfusionMatrixDisplay\n",
        "import tensorflow as tf\n",
        "# import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense,MaxPooling2D,Dropout,Flatten,BatchNormalization,Conv2D\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping\n",
        "from keras.preprocessing import image\n",
        "from sklearn.cluster import KMeans\n",
        "import cProfile\n",
        "\n",
        "\n",
        "calculate_and_print_time(start_time, 'imports')\n",
        "# print(\"imports done\")\n",
        "\n",
        "# endregion\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> detect Hardware <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on CPU\n",
            "REPLICAS:  1\n",
            "\n",
            "detecting hardware done in : 0 h, 0 m, 0 s\n"
          ]
        }
      ],
      "source": [
        "# --------------------------------------------------------- detect Hardware\n",
        "# region\n",
        "# @title detect Hardware {display-mode: \"form\"}\n",
        "start_time = time.time()\n",
        "\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "    print(\"Running on TPU\")\n",
        "    print('TPU details: ', tpu.cluster_spec().as_dict())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    if(gpus):\n",
        "        print(\"Running on \", len(gpus), \" GPU(s) \")\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        strategy = tf.distribute.MirroredStrategy(devices=[\"GPU:{}\".format(i) for i in range(len(gpus))])\n",
        "    else:        \n",
        "        print(\"Running on CPU\")\n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
        "calculate_and_print_time(start_time,'detecting hardware')\n",
        "# extra\n",
        "# endregion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> functions <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "functions done in : 0 h, 0 m, 0 s\n"
          ]
        }
      ],
      "source": [
        "# --------------------------------------------------------- functions\n",
        "# region\n",
        "# @title functions {display-mode: \"form\"}\n",
        "start_time = time.time()\n",
        "\n",
        "raw_data_path = None\n",
        "clean_data_path = None\n",
        "\n",
        "def get_environment():\n",
        "    if 'COLAB_GPU' in os.environ:\n",
        "        return 'Google Colab'\n",
        "    elif 'KAGGLE_URL_BASE' in os.environ:\n",
        "        return 'Kaggle'\n",
        "    elif 'VSCODE_PID' in os.environ:\n",
        "        return 'VS Code'\n",
        "    else:\n",
        "        return 'Unknown environment'\n",
        "\n",
        "def do_colab_staff():\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "\n",
        "    # storing kaggle credentials\n",
        "    os.environ['KAGGLE_CONFIG_DIR'] = KAGGLE_CRED_PATH\n",
        "\n",
        "    !kaggle datasets download -d {KAGGLE_DATA_SET_NAME}\n",
        "    print(\"downloaded dataset\" ,KAGGLE_DATA_SET_NAME )\n",
        "    \n",
        "    \n",
        "    ! mkdir kaggle_data\n",
        "    downloaded_zip_name = f\"{KAGGLE_DATA_SET_NAME.split('/')[-1]}.zip\" # the !kaggle datasets download command will download the zip file with the same name as the dataset name\n",
        "    extract_folder_path = 'kaggle_data'\n",
        "    extract_zip(downloaded_zip_name, extract_folder_path)\n",
        "\n",
        "    global raw_data_path\n",
        "    raw_data_path = COLAB_RAW_DATA_SET_PATH\n",
        "    global clean_data_path\n",
        "    clean_data_path = COLAB_CLAEN_DATA_SET_PATH\n",
        "\n",
        "\n",
        "def do_kaggle_staff():\n",
        "    global raw_data_path\n",
        "    raw_data_path = KAGGLE_RAW_DATA_SET_PATH\n",
        "    global clean_data_path\n",
        "    clean_data_path = KAGGLE_CLEAN_DATA_SET_PATH\n",
        "    \n",
        "def do_vscode_staff():\n",
        "    global raw_data_path\n",
        "    raw_data_path = VS_CODE_RAW_DATA_SET_PATH\n",
        "    global clean_data_path\n",
        "    clean_data_path = VS_CODE_CLEAN_DATA_SET_PATH\n",
        "\n",
        "def do_unknown_environment_staff():\n",
        "    print(\"This is an unknown environment, please enter the path to the data set folder:\")\n",
        "    global raw_data_path\n",
        "    raw_data_path = input()     \n",
        "\n",
        "def image_is_ok(image_path):\n",
        "    with warnings.catch_warnings(record=True) as w:\n",
        "        try:\n",
        "            img = Image.open(image_path)\n",
        "            img.verify()\n",
        "            if len(w) > 0:  # if any warnings were issued\n",
        "                return False\n",
        "            return True\n",
        "        except (IOError, SyntaxError):\n",
        "            return False\n",
        "\n",
        "def copy_clean_files(dirty_dataset_path, destination_folder_path):\n",
        "    print(\"copying clean files...\")\n",
        "    # If the destination directory already exists, remove it and all its contents\n",
        "    if os.path.exists(destination_folder_path):\n",
        "        print(f\"removing {destination_folder_path} directory to create a new one...\")\n",
        "        shutil.rmtree(destination_folder_path)\n",
        "        print(f\"removed {destination_folder_path} directory to create a new one...\")\n",
        "    os.makedirs(destination_folder_path)\n",
        "    \n",
        "    # Get the total number of files for the progress bar\n",
        "    total_files = sum([len(files) for r, d, files in os.walk(dirty_dataset_path)])\n",
        "    \n",
        "    progress_bar = tqdm(total=total_files, desc=\"Copying files\", unit=\"file\")\n",
        "    \n",
        "    for root, dirs, files in os.walk(dirty_dataset_path):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            if image_is_ok(file_path):\n",
        "                new_file_path = os.path.join(destination_folder_path, os.path.relpath(file_path, dirty_dataset_path))\n",
        "                os.makedirs(os.path.dirname(new_file_path) , exist_ok=True)\n",
        "                shutil.copyfile(file_path, new_file_path)\n",
        "            else:\n",
        "                print(f\"file: {os.path.relpath(file_path, dirty_dataset_path)} is corrupted & skipped from dataset while copying \")\n",
        "            \n",
        "            progress_bar.update(1)\n",
        "    \n",
        "    progress_bar.close()\n",
        "    print(f\"copied files from {dirty_dataset_path} to {destination_folder_path} successfully\") \n",
        "\n",
        "def rename_files(data_set_path):\n",
        "    all_entities_names = natsorted(os.listdir(data_set_path))\n",
        "    print(\"giving temporary unique names...\")\n",
        "    for entity_name in all_entities_names:\n",
        "        entity_path = os.path.join(data_set_path, entity_name)\n",
        "        for filename in os.listdir(entity_path):\n",
        "            temp_filename = str(uuid.uuid4()) + \".jpg\"  # generate a unique filename\n",
        "            source = os.path.join(entity_path, filename)\n",
        "            destination = os.path.join(entity_path, temp_filename)\n",
        "            os.rename(source, destination)\n",
        "    # ----------------------------------------------------------------------------------------------------\n",
        "    print(\"renaming...\")\n",
        "    # then rename every file in every folder in the given path\n",
        "\n",
        "    for entity_name in all_entities_names:\n",
        "        entity_path = os.path.join(data_set_path, entity_name)\n",
        "        i = 1\n",
        "        for filename in os.listdir(entity_path):\n",
        "            entity_name = os.fsdecode(entity_name.lower())\n",
        "            new_filename = entity_name + '.' + str(i) + \".jpg\"\n",
        "            source = os.path.join(entity_path, filename)\n",
        "            destination = os.path.join(entity_path, new_filename)\n",
        "            os.rename(source, destination)\n",
        "            i += 1\n",
        "    print(\"done renaming !\")\n",
        "\n",
        "def find_image_folder_after_extracting_zip(extracted_folder_path):\n",
        "    for root, dirs, files in os.walk(extracted_folder_path):\n",
        "        # check if the current directory contains image files\n",
        "        if any(fname.lower().endswith(('.png', '.jpg', '.jpeg')) for fname in files):\n",
        "            return os.path.dirname(root)\n",
        "    return None\n",
        "\n",
        "def extract_zip(source_path, destination_path):\n",
        "    # delete the destination folder if it exists\n",
        "    if os.path.exists(destination_path):\n",
        "        print('Deleting the existing destination folder...')\n",
        "        shutil.rmtree(destination_path)\n",
        "\n",
        "    print(\"Extracting files...\") \n",
        "    with zipfile.ZipFile(source_path, 'r') as zip_ref:\n",
        "        files = zip_ref.infolist()\n",
        "        for file in tqdm(files, desc=\"Extracting files\", unit=\"file\"):\n",
        "            try:\n",
        "                file.filename = file.filename.encode('cp437').decode('utf-8')  # try 'cp437' encoding first\n",
        "            except UnicodeDecodeError:\n",
        "                file.filename = file.filename.encode('utf-8').decode('utf-8')  # fallback to 'utf-8' if 'cp437' fails\n",
        "            zip_ref.extract(file, path=destination_path)\n",
        "\n",
        "    print(\"Extraction complete.\")\n",
        "\n",
        "\n",
        "calculate_and_print_time(start_time, 'functions')\n",
        "# print(\"functions done\")\n",
        "# endregion\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> doing specific-environment things <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment: VS Code\n",
            "tensowflow version: 2.16.1\n",
            "raw data set path: C:\\Users\\Dell\\Desktop\\Bachelor\\datasets\\26 letters\\1800\\1800 letters only\n",
            "clean data set path: ../image_classification/data/clean_data\n",
            "\n",
            "doing specific-environment things done in : 0 h, 0 m, 0 s\n"
          ]
        }
      ],
      "source": [
        "# --------------------------------------------------------- doing specific-environment things\n",
        "# region\n",
        "# @title doing specific-environment things {display-mode: \"form\"}\n",
        "start_time = time.time()\n",
        "\n",
        "# test if the tpu & GPU is available\n",
        "\n",
        "raw_data_path = None    \n",
        "environment_type = get_environment() \n",
        "print(f'Environment: {environment_type}')     \n",
        "\n",
        "print(\"tensowflow version:\", tf.__version__)\n",
        "if environment_type == 'Google Colab':\n",
        "    do_colab_staff()\n",
        "elif environment_type == 'Kaggle':\n",
        "    do_kaggle_staff()\n",
        "elif environment_type == 'VS Code':\n",
        "    do_vscode_staff()\n",
        "else:\n",
        "    do_unknown_environment_staff()\n",
        "\n",
        "print(\"raw data set path:\", raw_data_path)\n",
        "assert os.path.exists(raw_data_path), ' wrong path for data set !' \n",
        "print(\"clean data set path:\", clean_data_path)\n",
        "  \n",
        "calculate_and_print_time(start_time, 'doing specific-environment things')\n",
        "# print(\"doing specific-environment things done\")\n",
        "\n",
        "# endregion\n",
        "\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> data preparation <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "raw data path: C:\\Users\\Dell\\Desktop\\Bachelor\\datasets\\26 letters\\1800\\1800 letters only\n",
            "we will use raw data directly\n",
            "we will use  20 % of the data\n",
            "\n",
            "data preparation done in : 0 h, 0 m, 0 s\n"
          ]
        }
      ],
      "source": [
        "# --------------------------------------------------------- data preparation\n",
        "# region\n",
        "# @title data preparation {display-mode: \"form\"}\n",
        "start_time = time.time()\n",
        "\n",
        "print(\"raw data path:\", raw_data_path)\n",
        "if USE_RAW_DATA:\n",
        "    ready_data_path = raw_data_path\n",
        "    print(\"we will use raw data directly\")\n",
        "else :\n",
        "    copy_clean_files(raw_data_path, clean_data_path)\n",
        "    if RENAME_CLEAN_DATA:\n",
        "        rename_files(clean_data_path)\n",
        "    ready_data_path = clean_data_path        \n",
        "\n",
        "# ----------------------------\n",
        "\n",
        "print(\"we will use \", DATA_PERCENTAGE_TO_USE, \"% of the data\")\n",
        "calculate_and_print_time(start_time, 'data preparation')\n",
        "\n",
        "# endregion\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1 > 1 - Loading Images in a Dataframe <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "E9g1mXLiOBTX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "all entities names: ['أ', 'ب', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ي']\n",
            "working in entity name: أ\n",
            "working in entity name: ب\n",
            "working in entity name: ت\n",
            "working in entity name: ث\n",
            "working in entity name: ج\n",
            "working in entity name: ح\n",
            "working in entity name: خ\n",
            "working in entity name: د\n",
            "working in entity name: ذ\n",
            "working in entity name: ر\n",
            "working in entity name: ز\n",
            "working in entity name: س\n",
            "working in entity name: ش\n",
            "working in entity name: ص\n",
            "working in entity name: ض\n",
            "working in entity name: ط\n",
            "working in entity name: ظ\n",
            "working in entity name: ع\n",
            "working in entity name: غ\n",
            "working in entity name: ف\n",
            "working in entity name: ق\n",
            "working in entity name: ك\n",
            "working in entity name: ل\n",
            "working in entity name: م\n",
            "working in entity name: ن\n",
            "working in entity name: ه\n",
            "working in entity name: و\n",
            "working in entity name: ي\n",
            "selected data set size = 0.2 * 46130 = 9215\n",
            "data head :        filename label\n",
            "0  أ\\أ.1881.jpg     أ\n",
            "1  أ\\أ.1479.jpg     أ\n",
            "2   أ\\أ.989.jpg     أ\n",
            "3    أ\\أ.57.jpg     أ\n",
            "4   أ\\أ.326.jpg     أ\n",
            "data tail :           filename label\n",
            "9210  ي\\ي.1387.jpg     ي\n",
            "9211   ي\\ي.472.jpg     ي\n",
            "9212  ي\\ي.2127.jpg     ي\n",
            "9213  ي\\ي.2744.jpg     ي\n",
            "9214     ي\\ي.1.jpg     ي\n",
            "Flattening images...\n",
            "Elbow Method to find the optimal number of clusters...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[36], line 48\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m11\u001b[39m):  \u001b[38;5;66;03m# change the range according to your needs\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     kmeans \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39mi, init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk-means++\u001b[39m\u001b[38;5;124m'\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m, n_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 48\u001b[0m     \u001b[43mkmeans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflattened_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m     wcss\u001b[38;5;241m.\u001b[39mappend(kmeans\u001b[38;5;241m.\u001b[39minertia_)\n\u001b[0;32m     50\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m11\u001b[39m), wcss)\n",
            "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\Bachelor\\image-classification\\venv\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\Bachelor\\image-classification\\venv\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1536\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1533\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitialization complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1535\u001b[0m \u001b[38;5;66;03m# run a k-means once\u001b[39;00m\n\u001b[1;32m-> 1536\u001b[0m labels, inertia, centers, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43mkmeans_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcenters_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_n_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1544\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;66;03m# determine if these results are the best so far\u001b[39;00m\n\u001b[0;32m   1547\u001b[0m \u001b[38;5;66;03m# we chose a new run if it has a better inertia and the clustering is\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m \u001b[38;5;66;03m# different from the best so far (it's possible that the inertia is\u001b[39;00m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;66;03m# slightly better even if the clustering is the same with potentially\u001b[39;00m\n\u001b[0;32m   1550\u001b[0m \u001b[38;5;66;03m# permuted labels, due to rounding errors)\u001b[39;00m\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_inertia \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1552\u001b[0m     inertia \u001b[38;5;241m<\u001b[39m best_inertia\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_same_clustering(labels, best_labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters)\n\u001b[0;32m   1554\u001b[0m ):\n",
            "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\Bachelor\\image-classification\\venv\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:704\u001b[0m, in \u001b[0;36m_kmeans_single_lloyd\u001b[1;34m(X, sample_weight, centers_init, max_iter, verbose, tol, n_threads)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m threadpool_limits(limits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, user_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblas\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iter):\n\u001b[1;32m--> 704\u001b[0m         \u001b[43mlloyd_iter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m            \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcenters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcenters_new\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m            \u001b[49m\u001b[43mweight_in_clusters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcenter_shift\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    712\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    715\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[0;32m    716\u001b[0m             inertia \u001b[38;5;241m=\u001b[39m _inertia(X, sample_weight, centers, labels, n_threads)\n",
            "File \u001b[1;32msklearn\\\\cluster\\\\_k_means_lloyd.pyx:160\u001b[0m, in \u001b[0;36msklearn.cluster._k_means_lloyd.lloyd_iter_chunked_dense\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32msklearn\\\\cluster\\\\_k_means_common.pyx:180\u001b[0m, in \u001b[0;36msklearn.cluster._k_means_common._relocate_empty_clusters_dense\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\Bachelor\\image-classification\\venv\\Lib\\site-packages\\numpy\\core\\multiarray.py:346\u001b[0m, in \u001b[0;36mwhere\u001b[1;34m(condition, x, y)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;124;03m    inner(a, b, /)\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    341\u001b[0m \n\u001b[0;32m    342\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, b)\n\u001b[1;32m--> 346\u001b[0m \u001b[38;5;129m@array_function_from_c_func_and_dispatcher\u001b[39m(_multiarray_umath\u001b[38;5;241m.\u001b[39mwhere)\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwhere\u001b[39m(condition, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    348\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;124;03m    where(condition, [x, y], /)\u001b[39;00m\n\u001b[0;32m    350\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;124;03m           [ 0,  3, -1]])\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (condition, x, y)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 1 --------------------------------------------------------- Loading Images in a Dataframe\n",
        "# region\n",
        "# @title 1 - Loading Images in a Dataframe { display-mode: \"form\" }\n",
        "start_time = time.time()\n",
        "\n",
        "all_entities_names = natsorted(os.listdir(ready_data_path))\n",
        "print(\"all entities names:\", all_entities_names)\n",
        "filenames = []\n",
        "original_data_set_size = 0\n",
        "images = []  # for clustring part\n",
        "for entity_name in all_entities_names:\n",
        "    print(\"working in entity name:\", entity_name)\n",
        "    entity_path = os.path.join(ready_data_path, entity_name)\n",
        "    entity_filenames = [file_name for file_name in os.listdir(entity_path)]\n",
        "    original_data_set_size += len(entity_filenames)\n",
        "    random.shuffle(entity_filenames)\n",
        "    entity_filenames = entity_filenames[:int(len(entity_filenames) * (DATA_PERCENTAGE_TO_USE / 100))]\n",
        "    filenames.extend([os.path.join(entity_name, file_name) for file_name in entity_filenames])\n",
        "\n",
        "    # ----------------for clustring part\n",
        "    for file_name in entity_filenames:\n",
        "        img_path = os.path.join(entity_path, file_name)\n",
        "        img = image.load_img(img_path, target_size=(image_size, image_size))\n",
        "        img = image.img_to_array(img)\n",
        "        images.append(img)\n",
        " \n",
        "\n",
        "print(f\"selected data set size = {DATA_PERCENTAGE_TO_USE / 100} * {original_data_set_size} = {len(filenames)}\") \n",
        "file_labels = [x.split(os.sep)[0] for x in filenames] \n",
        "data = pd.DataFrame({\"filename\": filenames, \"label\": file_labels})\n",
        "# sort the data frame by the labels using natsort\n",
        "data = data.iloc[natsorted(data.index.values)] \n",
        "# data = data.sort_values('label', kind='mergesort')\n",
        "print(\"data head :\", data.head())\n",
        "print(\"data tail :\", data.tail())        \n",
        "\n",
        "# clustering part ------------------------------------------------------------\n",
        "\n",
        "# Flatten your images into 1D arrays\n",
        "print(\"Flattening images...\")\n",
        "flattened_images = np.array(images).reshape(len(images), -1)\n",
        "\n",
        "# -------------------- Elbow Method to find the optimal number of clusters\n",
        "if ESTIMATE_OPTIMAL_NO_OF_CLUSTERS:\n",
        "    print(\"Elbow Method to find the optimal number of clusters...\")\n",
        "    wcss = []\n",
        "    for i in range(1, 11):  # change the range according to your needs\n",
        "        kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
        "        kmeans.fit(flattened_images)\n",
        "        wcss.append(kmeans.inertia_)\n",
        "    plt.plot(range(1, 11), wcss)\n",
        "    plt.title('Elbow Method')\n",
        "    plt.xlabel('Number of clusters')\n",
        "    plt.ylabel('WCSS')\n",
        "    plt.show()\n",
        "# -------------------------------------\n",
        "\n",
        "\n",
        "# Perform KMeans clustering\n",
        "print(\"performing KMeans clustering...\")\n",
        "kmeans = KMeans(n_clusters= CLUSTERS_COUNT, random_state=0).fit(flattened_images)\n",
        "# Get the cluster labels for each image\n",
        "labels = kmeans.labels_\n",
        "# Add the cluster labels to the DataFrame\n",
        "data['cluster'] = labels\n",
        "\n",
        "calculate_and_print_time(start_time, 'Loading Images in a Dataframe')\n",
        "# print(\"Loading Images in a Dataframe done\")\n",
        "# endregion\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> 2 - Train Test Split <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1t3k6egONtP",
        "outputId": "9150b61f-6e5e-4321-dcba-c16b3430fab5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ...\n",
        "\n",
        "# Split data for each cluster\n",
        "clusters = natsorted(data['cluster'].unique())\n",
        "train_data = {}\n",
        "test_data = {}\n",
        "val_data = {}\n",
        "\n",
        "print(\"we have \", len(clusters), \"clusters\")\n",
        "for cluster in clusters:\n",
        "    cluster_data = data[data['cluster'] == cluster]\n",
        "    labels = cluster_data['label']\n",
        "    print(f\"number of classes in cluster {cluster}:\", len(labels.unique()))\n",
        "    print(\"total images in the current cluster:\", len(cluster_data))\n",
        "    # print(f\"Cluster {cluster} class distribution:\")\n",
        "    # print(labels.value_counts())\n",
        "    # Check if all classes have at least two instances\n",
        "    if all(labels.value_counts() > 1):\n",
        "        # If yes, use stratified sampling\n",
        "        X_train, X_temp = train_test_split(cluster_data, test_size=0.2, stratify=labels, random_state=42)\n",
        "        label_test_val = X_temp['label']\n",
        "        if all(label_test_val.value_counts() > 1):\n",
        "            # If yes, use stratified sampling\n",
        "            X_test, X_val = train_test_split(X_temp, test_size=0.5, stratify=label_test_val, random_state=42)\n",
        "        else:\n",
        "            # If not, use regular train-test split without stratification\n",
        "            X_test, X_val = train_test_split(X_temp, test_size=0.5, random_state=42)\n",
        "    else:\n",
        "        # If not, use regular train-test split without stratification\n",
        "        X_train, X_temp = train_test_split(cluster_data, test_size=0.2, random_state=42)\n",
        "        X_test, X_val = train_test_split(X_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "    train_data[cluster] = X_train\n",
        "    test_data[cluster] = X_test\n",
        "    val_data[cluster] = X_val\n",
        "\n",
        "    print('The shape of train data', X_train.shape)\n",
        "    print('The shape of test data', X_test.shape)\n",
        "    print('The shape of validation data', X_val.shape)\n",
        "    print(\" \")\n",
        "\n",
        "calculate_and_print_time(start_time, 'split the data for each cluster')\n",
        "\n",
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> 3 - Creating Image Data Generator <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96TshXPJOSrV",
        "outputId": "e82d25d8-db39-45be-d2b4-771d5d644a6c"
      },
      "outputs": [],
      "source": [
        "# 3 --------------------------------------------------------- Creating Image Data Generator\n",
        "# region\n",
        "# @title 3 - Creating Image Data Generator  { display-mode: \"form\" }\n",
        "start_time = time.time()\n",
        "\n",
        "image_channel = 3\n",
        "if tpu:\n",
        "    bat_size = 128 * strategy.num_replicas_in_sync\n",
        "else:    \n",
        "    bat_size = 32\n",
        "\n",
        "# Creating image data generator\n",
        "# Creating image data generator\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                    rotation_range = 15,\n",
        "                                    horizontal_flip = True,\n",
        "                                    zoom_range = 0.2,\n",
        "                                    shear_range = 0.1,\n",
        "                                    fill_mode = 'reflect',\n",
        "                                    width_shift_range = 0.1,\n",
        "                                    height_shift_range = 0.1)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = {}\n",
        "val_generator = {}\n",
        "test_generator = {}\n",
        "\n",
        "for cluster in clusters:\n",
        "    X_train = train_data[cluster]\n",
        "    X_val = val_data[cluster]\n",
        "    X_test = test_data[cluster]\n",
        "\n",
        "    train_generator[cluster] = train_datagen.flow_from_dataframe(X_train,\n",
        "                                                    directory = ready_data_path ,\n",
        "                                                    x_col= 'filename',\n",
        "                                                    y_col= 'label',\n",
        "                                                    batch_size = bat_size,\n",
        "                                                    target_size = (image_size,image_size),\n",
        "                                                    class_mode='categorical')\n",
        "\n",
        "    val_generator[cluster] = test_datagen.flow_from_dataframe(X_val,\n",
        "                                                    directory = ready_data_path ,\n",
        "                                                    x_col= 'filename',\n",
        "                                                    y_col= 'label',\n",
        "                                                    batch_size = bat_size,\n",
        "                                                    target_size = (image_size,image_size),\n",
        "                                                    shuffle=False,\n",
        "                                                    class_mode='categorical')\n",
        "\n",
        "    test_generator[cluster] = test_datagen.flow_from_dataframe(X_test,\n",
        "                                                    directory = ready_data_path ,\n",
        "                                                    x_col= 'filename',\n",
        "                                                    y_col= 'label',\n",
        "                                                    batch_size = bat_size,\n",
        "                                                    target_size = (image_size,image_size),\n",
        "                                                    shuffle=False,\n",
        "                                                    class_mode='categorical')\n",
        "\n",
        "calculate_and_print_time(start_time, 'Creating Image Data Generator')\n",
        "\n",
        "# endregion\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> 4 - Deep Learning Model <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fm1hLn5HOZt_"
      },
      "outputs": [],
      "source": [
        "# 4 --------------------------------------------------------- Deep Learning Model\n",
        "# region\n",
        "# @title 4 - Deep Learning Model { display-mode: \"form\" }\n",
        "start_time = time.time()\n",
        "\n",
        "def create_model(num_classes):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input Layer\n",
        "    model.add(Conv2D(32,(3,3),activation='relu', padding='same', input_shape = (image_size,image_size,image_channel)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # Block 1\n",
        "    model.add(Conv2D(64,(3,3),activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # Block 2\n",
        "    model.add(Conv2D(128,(3,3),activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # Block 3\n",
        "    model.add(Conv2D(256,(3,3),activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # Fully Connected layers\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512,activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(num_classes,activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "models = {}\n",
        "\n",
        "for cluster in clusters:\n",
        "    with strategy.scope():\n",
        "        num_classes = len(train_generator[cluster].class_indices)\n",
        "        print(f\"we are creading model with {num_classes} classes for cluster {cluster}\")\n",
        "        models[cluster] = create_model(num_classes)\n",
        "# model.summary()\n",
        "\n",
        "calculate_and_print_time(start_time, 'Deep Learning Model')\n",
        "# print(\"Deep Learning Model done\")\n",
        "\n",
        "# endregion\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> 5 - Callbacks <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyQcgdqMOguE"
      },
      "outputs": [],
      "source": [
        "# 5 --------------------------------------------------------- Callbacks\n",
        "# region\n",
        "# @title 5 - Callbacks { display-mode: \"form\" }\n",
        "from gc import callbacks\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
        "                                            patience=2,\n",
        "                                            factor=0.5,\n",
        "                                            min_lr = 0.00001,\n",
        "                                            verbose = 1)\n",
        "\n",
        "early_stoping = EarlyStopping(monitor='val_loss',patience= 3,restore_best_weights=True,verbose=0)\n",
        " \n",
        "callbacks = [learning_rate_reduction,early_stoping]\n",
        " \n",
        "calculate_and_print_time(start_time, 'Callbacks')\n",
        "# print(\"Callbacks done\")\n",
        "\n",
        "# endregion\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> 6 - Model Compilation <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAPVKdDFOiAM"
      },
      "outputs": [],
      "source": [
        "# 6 --------------------------------------------------------- Model Compilation\n",
        "# region\n",
        "# @title 6 - Model Compilation { display-mode: \"form\" }\n",
        "start_time = time.time()\n",
        "\n",
        "for cluster in clusters:\n",
        "    with strategy.scope():\n",
        "        model = models[cluster]\n",
        "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "calculate_and_print_time(start_time, 'Model Compilation')\n",
        "# print(\"Model Compilation done\")\n",
        "\n",
        "# endregion\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> 7 - Model Fitting <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDbqrio3OjWh",
        "outputId": "7b04d037-eeb6-44a3-f65b-73c7bfb4d85c"
      },
      "outputs": [],
      "source": [
        "# 7 --------------------------------------------------------- Model Fitting\n",
        "# region\n",
        "# @title 7 - Model Fitting { display-mode: \"form\" }\n",
        "start_time = time.time()\n",
        "\n",
        "training_histories = {}\n",
        "\n",
        "for cluster in clusters:\n",
        "    print(f\"Fitting model for cluster {cluster}\")\n",
        "    model = models[cluster]\n",
        "    train_gen = train_generator[cluster]\n",
        "    val_gen = val_generator[cluster]\n",
        "\n",
        "    steps_per_epoch = train_gen.samples // train_gen.batch_size\n",
        "    validation_steps = val_gen.samples // val_gen.batch_size\n",
        "    # -------------------  for testing no classes in target data and number of neurons in output layer of model\n",
        "\n",
        "    print(f\"Checking model for cluster {cluster}\")\n",
        "    model = models[cluster]\n",
        "    train_gen = train_generator[cluster]\n",
        "\n",
        "    # Check number of unique classes in target data\n",
        "    num_classes_target = len(train_gen.class_indices)\n",
        "    print(f\"Number of unique classes in target data: {num_classes_target}\")\n",
        "\n",
        "    # Check number of neurons in output layer of model\n",
        "    num_neurons_output_layer = model.layers[-1].units\n",
        "    print(f\"Number of neurons in output layer of model: {num_neurons_output_layer}\")\n",
        "    # \n",
        "\n",
        "\n",
        "    # ----------------------------------------- for testing generator \n",
        "    print(f\"Checking generator for cluster {cluster}\")\n",
        "    train_gen = train_generator[cluster]\n",
        "\n",
        "    # Get a batch from the generator\n",
        "    batch_images, batch_labels = next(train_gen)\n",
        "\n",
        "    # Check shapes of batch\n",
        "    print(f\"Shape of batch images: {batch_images.shape}\")\n",
        "    print(f\"Shape of batch labels: {batch_labels.shape}\")\n",
        "\n",
        "    # ---------------------------------------\n",
        "\n",
        "    with strategy.scope():\n",
        "        training_history = model.fit(train_gen,\n",
        "                        validation_data = val_gen,\n",
        "                        callbacks=callbacks,\n",
        "                        epochs = EPOCHS,\n",
        "                        steps_per_epoch = steps_per_epoch,\n",
        "                        validation_steps = validation_steps,\n",
        "                       )\n",
        "    training_histories[cluster] = training_history\n",
        "\n",
        "calculate_and_print_time(start_time, 'Model Fitting')\n",
        "# print(\"Model Fitting done\")\n",
        "# endregion\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> 8 - Plot the results <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9VvirSWOk0v"
      },
      "outputs": [],
      "source": [
        "# plots for accuracy and Loss with epochs\n",
        "start_time = time.time()\n",
        "\n",
        "for cluster in clusters:\n",
        "    print(f\"Plotting training history for cluster {cluster}\")\n",
        "    training_history = training_histories[cluster]\n",
        "    error = pd.DataFrame(training_history.history)\n",
        "\n",
        "    plt.figure(figsize=(18,5),dpi=200)\n",
        "    sns.set_style('darkgrid')\n",
        "\n",
        "    plt.subplot(121)\n",
        "    plt.title(f'Cross Entropy Loss for Cluster {cluster}',fontsize=15)\n",
        "    plt.xlabel('Epochs',fontsize=12)\n",
        "    plt.ylabel('Loss',fontsize=12)\n",
        "    plt.plot(error['loss'], label='Training Loss')\n",
        "    plt.plot(error['val_loss'], label='Validation Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(122)\n",
        "    plt.title(f'Classification Accuracy for Cluster {cluster}',fontsize=15)\n",
        "    plt.xlabel('Epochs',fontsize=12)\n",
        "    plt.ylabel('Accuracy',fontsize=12)\n",
        "    plt.plot(error['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(error['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show(block=False)  # hosain : prevent the popup\n",
        "\n",
        "calculate_and_print_time(start_time, 'Plot the results')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> 9 - Evaluation <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VV3c2l1ROmpD"
      },
      "outputs": [],
      "source": [
        "# 9 --------------------------------------------------------- Evaluation\n",
        "# region\n",
        "# @title 9 - Evaluation { display-mode: \"form\" }\n",
        "# Evaluvate for train generator\n",
        "start_time = time.time()\n",
        "\n",
        "for cluster in clusters:\n",
        "    print(f\"Evaluating model for cluster {cluster}\")\n",
        "    model = models[cluster]\n",
        "    train_gen = train_generator[cluster]\n",
        "    val_gen = val_generator[cluster]\n",
        "\n",
        "    loss,acc = model.evaluate(train_gen, batch_size = bat_size, verbose = 0)\n",
        "\n",
        "    print(f'The accuracy of the model for training data in cluster {cluster} is:',acc*100)\n",
        "    print(f'The Loss of the model for training data in cluster {cluster} is:',loss)\n",
        "\n",
        "    loss,acc = model.evaluate(val_gen, batch_size = bat_size, verbose = 0)\n",
        "\n",
        "    print(f'The accuracy of the model for validation data in cluster {cluster} is:',acc*100)\n",
        "    print(f'The Loss of the model for validation data in cluster {cluster} is:',loss)\n",
        "\n",
        "calculate_and_print_time(start_time, 'Evaluation')\n",
        "# print(\"Evaluation done\")\n",
        "\n",
        "#  endregion\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> 10 - save the model <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRWnjhtoOoVd"
      },
      "outputs": [],
      "source": [
        "# 10 --------------------------------------------------------- save the model\n",
        "# region\n",
        "# @title 10 - save the model { display-mode: \"form\" }\n",
        "start_time = time.time()\n",
        "\n",
        "original_images_per_entity = original_data_set_size / len(all_entities_names)\n",
        "\n",
        "for cluster in clusters:\n",
        "    print(f\"Saving model for cluster {cluster}\")\n",
        "    model = models[cluster]\n",
        "    model_name = f\"model_imagesPerEntity_{original_images_per_entity}_imgSize_{image_size}_percentage_{DATA_PERCENTAGE_TO_USE}_cluster_{cluster}\"\n",
        "    model.save(f\"{model_name}.keras\")\n",
        "\n",
        "    class_indices = train_gen.class_indices\n",
        "    index_to_label = {index: label for label, index in class_indices.items()}\n",
        "    created_json_file_name = f\"{model_name}.json\"\n",
        "    with open(created_json_file_name, 'w', encoding='utf-8') as f:\n",
        "            json_data = {\n",
        "                  'cluster' : cluster,\n",
        "                  'index_to_label': index_to_label,\n",
        "                  'model_name': model_name , \n",
        "                  'image_size': image_size,\n",
        "                  'used_dataset': raw_data_path\n",
        "                  }\n",
        "            json.dump(json_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "\n",
        "calculate_and_print_time(start_time, 'saving the model')\n",
        "# print(\"Model saved\")\n",
        "# endregion\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> 11 - Prediction <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlpmx-GlOp3M"
      },
      "outputs": [],
      "source": [
        "# 11 --------------------------------------------------------- Prediction\n",
        "# region\n",
        "# @title 11 - Prediction { display-mode: \"form\" }\n",
        "start_time = time.time()\n",
        "for cluster in clusters:\n",
        "    print(f\"Making predictions for cluster {cluster}\")\n",
        "    model = models[cluster]\n",
        "    train_gen = train_generator[cluster]\n",
        "    test_gen = test_generator[cluster]\n",
        "    result = model.predict(test_gen, batch_size = bat_size, verbose = 0)\n",
        "    y_pred = np.argmax(result, axis = 1)\n",
        "    y_true = test_gen.labels\n",
        "    loss,acc = model.evaluate(test_gen, batch_size = bat_size, verbose = 0)\n",
        "\n",
        "    print(f'The accuracy of the model for testing data in cluster {cluster} is:',acc*100)\n",
        "    print(f'The Loss of the model for testing data in cluster {cluster} is:',loss)\n",
        "\n",
        "calculate_and_print_time(start_time, 'Prediction')\n",
        "# print(\"Prediction done\")\n",
        "\n",
        "# endregion\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> 12 - Classification Report <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSFPmSxjOrNe"
      },
      "outputs": [],
      "source": [
        "# 12 --------------------------------------------------------- Classification Report\n",
        "# region\n",
        "# @title 12 - Classification Report { display-mode: \"form\" }\n",
        "start_time = time.time()\n",
        "\n",
        "for cluster in clusters:\n",
        "    print(f\"Generating classification report for cluster {cluster}\")\n",
        "    model = models[cluster]\n",
        "    test_gen = test_generator[cluster]\n",
        "    result = model.predict(test_gen, batch_size = bat_size, verbose = 0)\n",
        "    y_pred = np.argmax(result, axis = 1)\n",
        "    y_true = test_gen.labels\n",
        "\n",
        "    print(classification_report(y_true, y_pred, target_names=all_entities_names))\n",
        "\n",
        "calculate_and_print_time(start_time , 'Classification Report')\n",
        "# print(\"Classification Report done\")\n",
        "\n",
        "# endregion\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> 13 - Confusion Matrix <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4g02--rOspL"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 13 --------------------------------------------------------- Confusion Matrix\n",
        "# Normalize the confusion matrix\n",
        "# region\n",
        "# @title 13 - Confusion Matrix { display-mode: \"form\" }\n",
        "start_time = time.time()\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "for cluster in clusters:\n",
        "    print(f\"Generating confusion matrix for cluster {cluster}\")\n",
        "    model = models[cluster]\n",
        "    test_gen = test_generator[cluster]\n",
        "    result = model.predict(test_gen, batch_size = bat_size, verbose = 0)\n",
        "    y_pred = np.argmax(result, axis = 1)\n",
        "    y_true = test_gen.labels\n",
        "    confusion_mtx = confusion_matrix(y_true, y_pred)\n",
        "    confusion_mtx = confusion_mtx.astype('float') / confusion_mtx.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    num_classes = confusion_mtx.shape[0]\n",
        "    figsize = 40  # adjust as needed\n",
        "\n",
        "    f, ax = plt.subplots(figsize=(figsize, figsize), dpi=200)\n",
        "    sns.heatmap(confusion_mtx, annot=True, linewidths=0.1, cmap=\"gist_yarg_r\", linecolor=\"black\", fmt='.2%', ax=ax, cbar=False, xticklabels=all_entities_names, yticklabels=all_entities_names)\n",
        "\n",
        "    plt.xlabel(\"Predicted Label\", fontsize=10)\n",
        "    plt.ylabel(\"True Label\", fontsize=10)\n",
        "    plt.title(f\"Confusion Matrix for Cluster {cluster}\", fontsize=13)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    # Print accuracy for each class in each cluster\n",
        "    for i in range(num_classes):\n",
        "        true_positives = confusion_mtx[i, i]\n",
        "        accuracy = true_positives * 100  # convert to percentage\n",
        "        print(f\"Accuracy for class ( {all_entities_names[i]} ) in cluster {cluster} : {accuracy:.2f}%\")\n",
        "\n",
        "        # Print confusion with other classes\n",
        "        for j in range(num_classes):\n",
        "            if i != j and confusion_mtx[i, j] > 0:\n",
        "                confusion = confusion_mtx[i, j] * 100  # convert to percentage\n",
        "                print(f\"Class ({all_entities_names[i]}) was wrongly seen as class ({all_entities_names[j]}) in cluster {cluster} in {confusion:.2f}% of cases\")\n",
        "        print()\n",
        "  \n",
        "\n",
        "calculate_and_print_time(start_time , 'Confusion Matrix')\n",
        "# print(\"Confusion Matrix done\")\n",
        "\n",
        "# endregion "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> 14 - Copying the images of each cluster to a new folder <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 14 --------------------------------------------------------- Execution Time\n",
        "# region\n",
        "# @title 14 - copying cluster images  { display-mode: \"form\" }\n",
        "\n",
        "import shutil\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "if os.path.exists(CLUSTERS_IMAGES_DEST):\n",
        "    print('Deleting the existing destination folder...')\n",
        "    shutil.rmtree(CLUSTERS_IMAGES_DEST)\n",
        "for index, row in data.iterrows():\n",
        "    # Get the cluster label for the current image\n",
        "    cluster_label = row['cluster']\n",
        "\n",
        "    # Define the directory for this cluster\n",
        "    cluster_dir = os.path.join(CLUSTERS_IMAGES_DEST, f'cluster_{cluster_label}')\n",
        "\n",
        "    # Create the directory if it doesn't exist\n",
        "    os.makedirs(cluster_dir, exist_ok=True)\n",
        "\n",
        "    # Define the source path of the image file\n",
        "    src_path = os.path.join(ready_data_path, row['filename'])\n",
        "\n",
        "    # Define the destination path of the image file\n",
        "    dst_path = os.path.join(cluster_dir, row['filename'].split(os.sep)[-1])\n",
        "\n",
        "    # Copy the image file to the cluster directory\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "calculate_and_print_time(start_time, 'copying cluster images')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> 15 - Execution Time <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 15 --------------------------------------------------------- Execution Time\n",
        "# region\n",
        "# @title 15 - Execution time  { display-mode: \"form\" }\n",
        "\n",
        "calculate_and_print_time(global_start_time , 'Whole notebook execution time')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> 15 - reference codes <h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --------------------------------------------------------- reference codes\n",
        "# region\n",
        "#  @title  reference codes { display-mode: \"form\" }\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "\n",
        "# import zipfile\n",
        "# import os\n",
        "# extract_source = \"/content/gdrive/My Drive/GUC Bachelor : Arabic Image-to-Letters Script Recognition/data set/data set 2.zip\"\n",
        "# extract_destination = \"/content/extracted_from_drive\"\n",
        "# zip_ref = zipfile.ZipFile(extract_source, 'r')\n",
        "# print(\"extracting...\")\n",
        "# zip_ref.extractall(extract_destination)\n",
        "# extracted_folder_name = os.listdir(extract_destination)[0]\n",
        "# zip_ref.close()\n",
        "# print(\"extracted files from drive to colab successfully !\")\n",
        "# all_entities_path = os.path.join(extract_destination, extracted_folder_name)\n",
        "\n",
        "\n",
        "# def get_corrupted_files_paths(all_entities_path):\n",
        "#     all_entities_names = os.listdir(all_entities_path)\n",
        "#     corrupted_file_paths = set()\n",
        "#     print(\"\\nVerifying all files are non-corrupted images...\")\n",
        "#     for entity_name in all_entities_names:\n",
        "#         entity_path = os.path.join(all_entities_path, entity_name)\n",
        "#         for filename in os.listdir(entity_path):\n",
        "#             file_path = os.path.join(entity_path, filename)\n",
        "#             if not image_is_ok(file_path):\n",
        "#                 print(f\"File {file_path} is corrupted and will be skipped.\")\n",
        "#                 corrupted_file_paths.add(file_path)\n",
        "#     print(\"Your data is ok.\" if not corrupted_file_paths else \"Done reporting error files.\")\n",
        "#     return corrupted_file_paths\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
